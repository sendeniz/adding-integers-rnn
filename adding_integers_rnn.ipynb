{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3a.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHPNJzm5ONkd",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning and Neural Networks: Assignment 3A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFVPxJu_QdgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from six.moves import range"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIwUgpEOiCFY",
        "colab_type": "code",
        "outputId": "fd10aee3-919e-4598-ca44-fe2705896b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "model_path = \"/content/gdrive/My Drive/DLNN/A3/Models/\"\n",
        "history_path = \"/content/gdrive/My Drive/DLNN/A3/Histories/\"\n",
        "plot_path = \"/content/gdrive/My Drive/DLNN/A3/Plots/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XWkF_Knb2cU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create Character Table Class\n",
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCUuzLoKeF1l",
        "colab_type": "text"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6_7WPYkcmo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(N, digits, as_pairs = False, reverse = False):\n",
        "    TRAINING_SIZE = N\n",
        "    DIGITS = digits\n",
        "    REVERSE = reverse\n",
        "\n",
        "    if as_pairs: # calculate integer sequence of pairs\n",
        "        MAXLEN = DIGITS + DIGITS\n",
        "        chars = '0123456789 '\n",
        "        ctable = CharacterTable(chars)\n",
        "        questions = []\n",
        "        expected = []\n",
        "        seen = set()\n",
        "        print('Generating data...')\n",
        "        while len(questions) < TRAINING_SIZE:\n",
        "            f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                            for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "            a, b = f(), f()\n",
        "            key = tuple(sorted((a, b)))\n",
        "            if key in seen:\n",
        "                continue\n",
        "            seen.add(key)   \n",
        "            ans = str(a + b) # calculate answer\n",
        "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "            a,b = str(a),str(b)  # transform to string and concatenate as pairs\n",
        "            a = (DIGITS - len(a)) * \"0\" + a\n",
        "            b = (DIGITS - len(b)) * \"0\" + b\n",
        "            query = ''.join([a[i] + b[i] for i in range(len(a))])\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            expected.append(ans)\n",
        "        print('Total addition questions:', len(questions))\n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(expected):\n",
        "            y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "        indices = np.arange(len(y)) # create random indices and shuffle data\n",
        "        np.random.shuffle(indices)\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "        split_at = len(x) - len(x) // 10 # split data into train/val set \n",
        "        (x_train, x_val) = x[:split_at], x[split_at:]\n",
        "        (y_train, y_val) = y[:split_at], y[split_at:]\n",
        "        return x_train, x_val, y_train, y_val\n",
        "\n",
        "    else: # calculate integer sequence\n",
        "        MAXLEN = DIGITS + 1 + DIGITS\n",
        "        chars = '0123456789+ '\n",
        "        ctable = CharacterTable(chars)\n",
        "        questions = []\n",
        "        expected = []\n",
        "        seen = set()\n",
        "        print('Generating data...')\n",
        "        while len(questions) < TRAINING_SIZE:\n",
        "            f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                            for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "            a, b = f(), f()\n",
        "            key = tuple(sorted((a, b)))\n",
        "            if key in seen:\n",
        "                continue\n",
        "            seen.add(key)\n",
        "            q = '{}+{}'.format(a, b)\n",
        "            query = q + ' ' * (MAXLEN - len(q))\n",
        "            ans = str(a + b)\n",
        "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            expected.append(ans)\n",
        "        print('Total addition questions:', len(questions))\n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(expected):\n",
        "            y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "        indices = np.arange(len(y))\n",
        "        np.random.shuffle(indices)\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "        split_at = len(x) - len(x) // 10\n",
        "        (x_train, x_val) = x[:split_at], x[split_at:]\n",
        "        (y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "        return x_train, x_val, y_train, y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfqWJrWvsfkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate data in bit representation\n",
        "def generate_bit_data(N, digits, bits, as_pairs = False, reverse = False):\n",
        "    TRAINING_SIZE = N\n",
        "    DIGITS = digits\n",
        "    BITS = bits\n",
        "    REVERSE = reverse\n",
        "\n",
        "    if as_pairs: # calculate pairs of bits\n",
        "        chars = '01'\n",
        "        ctable = CharacterTable(chars)\n",
        "        MAXLEN = BITS + BITS\n",
        "        questions = []\n",
        "        expected = []\n",
        "        seen = set()\n",
        "        print('Generating data...')\n",
        "        while len(questions) < TRAINING_SIZE:\n",
        "            f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                            for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "            a, b = f(), f()\n",
        "            key = tuple(sorted((a, b)))\n",
        "            if key in seen:\n",
        "                continue\n",
        "            seen.add(key)\n",
        "            ans = int(a + b) # compute answer\n",
        "            ans = '{:011b}'.format(ans)\n",
        "            a = '{:010b}'.format(a) # convert integer to bit representation\n",
        "            b = '{:010b}'.format(b)\n",
        "            query = ''.join([a[i] + b[i] for i in range(len(a))])\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            expected.append(ans)\n",
        "        print('Total addition questions:', len(questions))     \n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), BITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(expected):\n",
        "            y[i] = ctable.encode(sentence, BITS + 1)\n",
        "        indices = np.arange(len(y))\n",
        "        np.random.shuffle(indices)\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "        split_at = len(x) - len(x) // 10\n",
        "        (x_train, x_val) = x[:split_at], x[split_at:]\n",
        "        (y_train, y_val) = y[:split_at], y[split_at:]\n",
        "        return x_train, x_val, y_train, y_val\n",
        "    \n",
        "    else:  # calculate bits \n",
        "        chars = '01+'\n",
        "        ctable = CharacterTable(chars)\n",
        "        MAXLEN = BITS + 1 + BITS       \n",
        "        questions = []\n",
        "        expected = []\n",
        "        seen = set()\n",
        "        print('Generating data...')\n",
        "        while len(questions) < TRAINING_SIZE:\n",
        "            f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                            for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "            a, b = f(), f()\n",
        "            key = tuple(sorted((a, b)))\n",
        "            if key in seen:\n",
        "                continue\n",
        "            seen.add(key)\n",
        "            ans = int(a + b) # compute answer\n",
        "            ans = '{:011b}'.format(ans) # convert integer to bit representation\n",
        "            a = '{:010b}'.format(a)\n",
        "            b = '{:010b}'.format(b)\n",
        "            query = '{}+{}'.format(a, b)\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            expected.append(ans)\n",
        "        print('Total addition questions:', len(questions))     \n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), BITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(expected):\n",
        "            y[i] = ctable.encode(sentence, BITS + 1)\n",
        "        indices = np.arange(len(y))\n",
        "        np.random.shuffle(indices)\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "        split_at = len(x) - len(x) // 10\n",
        "        (x_train, x_val) = x[:split_at], x[split_at:]\n",
        "        (y_train, y_val) = y[:split_at], y[split_at:]\n",
        "        return x_train, x_val, y_train, y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK0EeD9JPq3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create complete set \n",
        "def generate_complete_set(as_type = (\"integer\", \"bit\", \"pairs\", \"bitpairs\"), reverse = False):\n",
        "    REVERSE = reverse\n",
        "    BITS = 10\n",
        "    DIGITS = 3\n",
        "    if as_type == \"bit\": # calculate complete set as bit representation\n",
        "        MAXLEN = BITS + 1 + BITS\n",
        "        chars = \"01+\"\n",
        "        ctable = CharacterTable(chars)\n",
        "        allcomb = list(itertools.product(range(1023), range(1023)))\n",
        "        questions = []\n",
        "        answers = []\n",
        "        for i in range(len(allcomb)):\n",
        "            a, b = allcomb[i]\n",
        "            ans = int(a + b)\n",
        "            ans = '{:011b}'.format(ans)\n",
        "            a = '{:010b}'.format(a)\n",
        "            b = '{:010b}'.format(b)\n",
        "            query = '{}+{}'.format(a, b)\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            answers.append(ans)\n",
        "        print('Total addition questions:', len(questions)) \n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), BITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(answers):\n",
        "            y[i] = ctable.encode(sentence, BITS + 1)  \n",
        "\n",
        "    elif as_type == \"integer\": # calculate complete set as integer representation\n",
        "        MAXLEN = DIGITS + 1 + DIGITS\n",
        "        chars = '0123456789+ '\n",
        "        ctable = CharacterTable(chars)\n",
        "        allcomb = list(itertools.product(range(1000), range(1000)))\n",
        "        questions = []\n",
        "        answers = []\n",
        "        for i in range(len(allcomb)):\n",
        "            a, b = allcomb[i]\n",
        "            q = '{}+{}'.format(a, b)\n",
        "            query = q + ' ' * (MAXLEN - len(q))\n",
        "            ans = str(a+b)\n",
        "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            answers.append(ans)  \n",
        "        print('Total addition questions:', len(questions)) \n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(answers):\n",
        "            y[i] = ctable.encode(sentence, DIGITS + 1)  \n",
        "\n",
        "    elif as_type == \"pairs\":    # calculate complete set as pairs of digits\n",
        "        MAXLEN = DIGITS + DIGITS\n",
        "        chars = '0123456789 '\n",
        "        ctable = CharacterTable(chars)\n",
        "        allcomb = list(itertools.product(range(1000), range(1000)))\n",
        "        questions = []\n",
        "        answers = []\n",
        "        for i in range(len(allcomb)):\n",
        "            a,b = allcomb[i]  \n",
        "            ans = str(a + b) # calculate answer\n",
        "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "            a,b = str(a),str(b) # transform to string and concatenate as pairs\n",
        "            a = (DIGITS - len(a)) * \"0\" + a # concatenate zeros \n",
        "            b = (DIGITS - len(b)) * \"0\" + b\n",
        "            query = ''.join([a[i] + b[i] for i in range(len(a))]) # create pairs\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            answers.append(ans)\n",
        "        print('Total addition questions:', len(questions)) \n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(answers):\n",
        "            y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "    elif as_type == \"bitpairs\": # calculate pairs of bits\n",
        "        MAXLEN = BITS + BITS\n",
        "        chars = \"01\"\n",
        "        ctable = CharacterTable(chars)\n",
        "        allcomb = list(itertools.product(range(1023), range(1023)))\n",
        "        questions = []\n",
        "        answers = []\n",
        "        for i in range(len(allcomb)):\n",
        "            a, b = allcomb[i]\n",
        "            ans = int(a + b)\n",
        "            ans = '{:011b}'.format(ans)\n",
        "            a = '{:010b}'.format(a)\n",
        "            b = '{:010b}'.format(b)\n",
        "            query = ''.join([a[i] + b[i] for i in range(len(a))])\n",
        "            if REVERSE:\n",
        "                query = query[::-1]\n",
        "            questions.append(query)\n",
        "            answers.append(ans)\n",
        "        print('Total addition questions:', len(questions))  \n",
        "        x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "        y = np.zeros((len(questions), BITS + 1, len(chars)), dtype=np.bool)\n",
        "        for i, sentence in enumerate(questions):\n",
        "            x[i] = ctable.encode(sentence, MAXLEN)\n",
        "        for i, sentence in enumerate(answers):\n",
        "            y[i] = ctable.encode(sentence, BITS + 1)  \n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z91M3syheKfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ultimate_errors(model, x_tst, y_tst, as_bit = False):\n",
        "    # get predicitions and decode\n",
        "    preds_enc = np.argmax(model.predict(x_tst), axis = -1)\n",
        "    preds_dec = [ctable.decode(preds_enc[i], calc_argmax=False) for i in range(len(y_tst))]\n",
        "\n",
        "    true = [ctable.decode(y_tst[i]) for i in range(len(y_tst))]\n",
        "    \n",
        "    if as_bit: # decode true values and convert bit to int\n",
        "        true_int = [int(true[i], 2) for i in range(len(true))]\n",
        "        pred_int = [int(preds_dec[i], 2) for i in range(len(preds_dec))]\n",
        "\n",
        "    else: # decode true values and convert str to integer\n",
        "        true_int = [int(i.replace(\" \", \"\")) for i in true]\n",
        "        pred_int = [int(i.replace(\" \", \"\")) for i in preds_dec]\n",
        "\n",
        "    # accuracy\n",
        "    correct = 0\n",
        "    for i in range(len(y_tst)):\n",
        "        if true_int[i] == pred_int[i]:\n",
        "            correct += 1\n",
        "    accuracy = correct / len(y_tst)\n",
        "\n",
        "    # mse\n",
        "    mse = np.sum(np.square(np.subtract(true_int, pred_int))) / len(y_tst)\n",
        "\n",
        "    # mae\n",
        "    mae = np.sum(np.absolute(np.subtract(true_int, pred_int))) / len(y_tst)\n",
        "\n",
        "    return accuracy, mse, mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IloWJzn4oYmM",
        "colab_type": "text"
      },
      "source": [
        "# Task 1: Integer representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMq8H8tv56DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set Data Parameters\n",
        "TRAINING_SIZE = 5e4\n",
        "DIGITS = 3\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n",
        "chars = '0123456789+ '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "#Set Model Parameters\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "histories_dict, results_dict = {}, {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyencgFbvxQ9",
        "colab_type": "code",
        "outputId": "56662e74-e147-429f-baa5-5b2081ac504e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# generate data\n",
        "# generate plain data\n",
        "x_train_plain, x_val_plain, y_train_plain, y_val_plain = generate_data(TRAINING_SIZE, DIGITS, as_pairs = False, reverse = False)\n",
        "\n",
        "# generate reverse data\n",
        "x_train_rev, x_val_rev, y_train_rev, y_val_rev = generate_data(TRAINING_SIZE, DIGITS, as_pairs = False, reverse = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n",
            "Generating data...\n",
            "Total addition questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKDbJLTBu12G",
        "colab_type": "text"
      },
      "source": [
        "### Model: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sSvic_hQ0Bj",
        "colab_type": "code",
        "outputId": "ddf67adb-4251-4940-b0f7-c82b258901b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Try replacing GRU, or SimpleRNN.\n",
        "RNN = layers.LSTM\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_LSTM\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GplVJodcpAT-",
        "colab_type": "text"
      },
      "source": [
        "#### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87FUrc9BQ4PR",
        "colab_type": "code",
        "outputId": "1f90386a-8774-46d5-a6b6-b7671f62a178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "\n",
        "histories_dict[\"LSTM_plain\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.8963 - accuracy: 0.3211 - val_loss: 1.8067 - val_accuracy: 0.3371\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.7657 - accuracy: 0.3502 - val_loss: 1.7027 - val_accuracy: 0.3758\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.6143 - accuracy: 0.3983 - val_loss: 1.5396 - val_accuracy: 0.4254\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.4669 - accuracy: 0.4518 - val_loss: 1.3992 - val_accuracy: 0.4781\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.3373 - accuracy: 0.5017 - val_loss: 1.2719 - val_accuracy: 0.5253\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 1.2224 - accuracy: 0.5448 - val_loss: 1.1715 - val_accuracy: 0.5624\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.1290 - accuracy: 0.5778 - val_loss: 1.0916 - val_accuracy: 0.5908\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.0516 - accuracy: 0.6047 - val_loss: 1.0182 - val_accuracy: 0.6179\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.9896 - accuracy: 0.6291 - val_loss: 0.9780 - val_accuracy: 0.6295\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.9391 - accuracy: 0.6492 - val_loss: 0.9162 - val_accuracy: 0.6561\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8824 - accuracy: 0.6713 - val_loss: 0.8682 - val_accuracy: 0.6686\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8035 - accuracy: 0.7001 - val_loss: 0.7621 - val_accuracy: 0.7101\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7025 - accuracy: 0.7376 - val_loss: 0.6513 - val_accuracy: 0.7502\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.5785 - accuracy: 0.7923 - val_loss: 0.5621 - val_accuracy: 0.7866\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.4678 - accuracy: 0.8453 - val_loss: 0.4215 - val_accuracy: 0.8661\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3738 - accuracy: 0.8877 - val_loss: 0.3459 - val_accuracy: 0.8945\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3003 - accuracy: 0.9186 - val_loss: 0.2849 - val_accuracy: 0.9180\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2455 - accuracy: 0.9361 - val_loss: 0.2302 - val_accuracy: 0.9379\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2039 - accuracy: 0.9490 - val_loss: 0.1848 - val_accuracy: 0.9543\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1731 - accuracy: 0.9583 - val_loss: 0.1671 - val_accuracy: 0.9561\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.1433 - accuracy: 0.9674 - val_loss: 0.1376 - val_accuracy: 0.9664\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.1287 - accuracy: 0.9702 - val_loss: 0.1331 - val_accuracy: 0.9640\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.1053 - accuracy: 0.9783 - val_loss: 0.0981 - val_accuracy: 0.9782\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0911 - accuracy: 0.9814 - val_loss: 0.1588 - val_accuracy: 0.9485\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0787 - accuracy: 0.9845 - val_loss: 0.0784 - val_accuracy: 0.9815\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0782 - accuracy: 0.9826 - val_loss: 0.0682 - val_accuracy: 0.9844\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0552 - accuracy: 0.9904 - val_loss: 0.0744 - val_accuracy: 0.9815\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0678 - accuracy: 0.9832 - val_loss: 0.0592 - val_accuracy: 0.9861\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0460 - accuracy: 0.9918 - val_loss: 0.0521 - val_accuracy: 0.9870\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9943 - val_loss: 0.0527 - val_accuracy: 0.9857\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0448 - accuracy: 0.9903 - val_loss: 0.0609 - val_accuracy: 0.9820\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0423 - accuracy: 0.9907 - val_loss: 0.0510 - val_accuracy: 0.9858\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0304 - accuracy: 0.9943 - val_loss: 0.0381 - val_accuracy: 0.9897\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0463 - accuracy: 0.9881 - val_loss: 0.0359 - val_accuracy: 0.9905\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0203 - accuracy: 0.9971 - val_loss: 0.0278 - val_accuracy: 0.9929\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0189 - accuracy: 0.9971 - val_loss: 0.0327 - val_accuracy: 0.9913\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0330 - val_accuracy: 0.9920\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0157 - accuracy: 0.9978 - val_loss: 0.0218 - val_accuracy: 0.9944\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0144 - accuracy: 0.9978 - val_loss: 0.0230 - val_accuracy: 0.9938\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0398 - accuracy: 0.9882 - val_loss: 0.0993 - val_accuracy: 0.9634\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0756 - val_accuracy: 0.9722\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.0186 - val_accuracy: 0.9952\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0765 - val_accuracy: 0.9742\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0382 - accuracy: 0.9883 - val_loss: 0.0160 - val_accuracy: 0.9960\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.0154 - val_accuracy: 0.9962\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.0172 - val_accuracy: 0.9958\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 0.0153 - val_accuracy: 0.9961\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.0131 - val_accuracy: 0.9965\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0124 - val_accuracy: 0.9969\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0133 - val_accuracy: 0.9967\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0431 - accuracy: 0.9873 - val_loss: 0.0138 - val_accuracy: 0.9966\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0118 - val_accuracy: 0.9969\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0104 - val_accuracy: 0.9973\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0176 - val_accuracy: 0.9949\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.0772 - val_accuracy: 0.9727\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.0167 - val_accuracy: 0.9949\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0117 - val_accuracy: 0.9967\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.1019 - val_accuracy: 0.9659\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0379 - accuracy: 0.9886 - val_loss: 0.0106 - val_accuracy: 0.9968\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.0132 - val_accuracy: 0.9962\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 0.9974\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0739 - val_accuracy: 0.9765\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.0256 - val_accuracy: 0.9920\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.0449 - val_accuracy: 0.9836\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0083 - val_accuracy: 0.9978\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9983\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0156 - val_accuracy: 0.9954\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0462 - accuracy: 0.9863 - val_loss: 0.0172 - val_accuracy: 0.9949\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0064 - val_accuracy: 0.9982\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9972\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0132 - val_accuracy: 0.9963\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0136 - val_accuracy: 0.9955\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0427 - accuracy: 0.9874 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0563 - val_accuracy: 0.9834\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0354 - accuracy: 0.9888 - val_loss: 0.0088 - val_accuracy: 0.9973\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0237 - val_accuracy: 0.9924\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0353 - accuracy: 0.9891 - val_loss: 0.0099 - val_accuracy: 0.9966\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0342 - val_accuracy: 0.9879\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.0060 - val_accuracy: 0.9982\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0226 - val_accuracy: 0.9923\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0131 - val_accuracy: 0.9960\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0384 - accuracy: 0.9894 - val_loss: 0.0289 - val_accuracy: 0.9913\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.1984e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 8.4992e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0415 - val_accuracy: 0.9856\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 9.9802e-04 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 7.8592e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.9288e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.0277 - val_accuracy: 0.9910\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.4244e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 7.0714e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.2028e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.0124 - val_accuracy: 0.9966\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.2091e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 6.9312e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.1662e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.5928e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0644 - val_accuracy: 0.9790\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0137 - val_accuracy: 0.9947\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.3206e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.7565e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.2997e-04 - accuracy: 0.9999 - val_loss: 0.0118 - val_accuracy: 0.9957\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0335 - accuracy: 0.9895 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.3772e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.2934e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.5253e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.1224e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.0195 - val_accuracy: 0.9934\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.6569e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.5366e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 4.6819e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.8921e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1760 - val_accuracy: 0.9464\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0075 - val_accuracy: 0.9974\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.8174e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.5442e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.9387e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 4.7683e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.0841e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.0395 - val_accuracy: 0.9874\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.0898e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.4298e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.3681e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.0149 - val_accuracy: 0.9955\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.0540e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.8001e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.1066e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9988\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.7207e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9988\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.6082e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.1601 - val_accuracy: 0.9538\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.1645e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.2939e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.2617e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.6599e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 3.2711e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0357 - val_accuracy: 0.9893\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.6930e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 3.8468e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.3372e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.9645e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.2069 - val_accuracy: 0.9437\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.7485e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7398e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.9046e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9986\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.4389e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.1385e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9986\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.9866e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.5946e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0376 - accuracy: 0.9897 - val_loss: 0.0159 - val_accuracy: 0.9949\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.5324e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.4780e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.6914e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.3370e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PYGYp4KXSV6",
        "colab_type": "code",
        "outputId": "f8a5bb6b-eddc-4678-c0b3-1add7ddd0469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"integer\", reverse = False)\n",
        "score_lstm_plain = ultimate_errors(model, x_tst, y_tst)\n",
        "results_dict[\"LSTM_plain\"] = score_lstm_plain\n",
        "print(\"Accuracy:\", score_lstm_plain[0])\n",
        "print(\"MSE:     \", score_lstm_plain[1])\n",
        "print(\"MAE:     \", score_lstm_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.991339\n",
            "MSE:      18914.242756\n",
            "MAE:      3.07431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOXpOYjOpmfG",
        "colab_type": "text"
      },
      "source": [
        "#### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycy3ZFNkJlOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# built the model again to start with new weights\n",
        "model = Sequential(name = \"model_LSTM\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jc1GT6VopsBN",
        "outputId": "ea60d26b-54f0-4d87-bce0-92b55e6a7d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_dict[\"LSTM_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 1.8746 - accuracy: 0.3244 - val_loss: 1.7861 - val_accuracy: 0.3429\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.7220 - accuracy: 0.3638 - val_loss: 1.6543 - val_accuracy: 0.3869\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.5744 - accuracy: 0.4099 - val_loss: 1.5057 - val_accuracy: 0.4354\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.4304 - accuracy: 0.4639 - val_loss: 1.3541 - val_accuracy: 0.4924\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.2837 - accuracy: 0.5210 - val_loss: 1.2251 - val_accuracy: 0.5463\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.1733 - accuracy: 0.5646 - val_loss: 1.1316 - val_accuracy: 0.5818\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.0804 - accuracy: 0.6016 - val_loss: 1.0497 - val_accuracy: 0.6150\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.9976 - accuracy: 0.6351 - val_loss: 0.9687 - val_accuracy: 0.6482\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.9272 - accuracy: 0.6634 - val_loss: 0.8949 - val_accuracy: 0.6801\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8655 - accuracy: 0.6872 - val_loss: 0.8450 - val_accuracy: 0.6937\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8226 - accuracy: 0.7023 - val_loss: 0.8044 - val_accuracy: 0.7111\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7823 - accuracy: 0.7197 - val_loss: 0.7759 - val_accuracy: 0.7168\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7546 - accuracy: 0.7293 - val_loss: 0.7512 - val_accuracy: 0.7258\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7240 - accuracy: 0.7418 - val_loss: 0.7268 - val_accuracy: 0.7348\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6974 - accuracy: 0.7496 - val_loss: 0.6946 - val_accuracy: 0.7505\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6695 - accuracy: 0.7598 - val_loss: 0.6737 - val_accuracy: 0.7517\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6387 - accuracy: 0.7710 - val_loss: 0.6228 - val_accuracy: 0.7720\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.5686 - accuracy: 0.7952 - val_loss: 0.5270 - val_accuracy: 0.8080\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.4413 - accuracy: 0.8450 - val_loss: 0.3817 - val_accuracy: 0.8722\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3054 - accuracy: 0.9087 - val_loss: 0.2685 - val_accuracy: 0.9208\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2161 - accuracy: 0.9482 - val_loss: 0.2005 - val_accuracy: 0.9481\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1632 - accuracy: 0.9643 - val_loss: 0.1525 - val_accuracy: 0.9644\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1194 - accuracy: 0.9768 - val_loss: 0.1191 - val_accuracy: 0.9742\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0913 - accuracy: 0.9835 - val_loss: 0.0895 - val_accuracy: 0.9819\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0720 - accuracy: 0.9877 - val_loss: 0.0917 - val_accuracy: 0.9772\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0575 - accuracy: 0.9911 - val_loss: 0.0597 - val_accuracy: 0.9893\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0606 - accuracy: 0.9874 - val_loss: 0.0498 - val_accuracy: 0.9914\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0568 - accuracy: 0.9883 - val_loss: 0.1293 - val_accuracy: 0.9590\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0377 - accuracy: 0.9943 - val_loss: 0.0364 - val_accuracy: 0.9944\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0293 - accuracy: 0.9964 - val_loss: 0.0991 - val_accuracy: 0.9759\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.0272 - val_accuracy: 0.9957\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0189 - accuracy: 0.9984 - val_loss: 0.0226 - val_accuracy: 0.9962\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0157 - accuracy: 0.9989 - val_loss: 0.0195 - val_accuracy: 0.9969\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.0624 - val_accuracy: 0.9801\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0448 - accuracy: 0.9879 - val_loss: 0.0191 - val_accuracy: 0.9973\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0111 - accuracy: 0.9994 - val_loss: 0.0133 - val_accuracy: 0.9983\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0095 - accuracy: 0.9994 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.0697 - val_accuracy: 0.9762\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0325 - accuracy: 0.9910 - val_loss: 0.0129 - val_accuracy: 0.9980\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.0097 - val_accuracy: 0.9988\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0360 - accuracy: 0.9898 - val_loss: 0.0954 - val_accuracy: 0.9671\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.0088 - val_accuracy: 0.9989\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9991\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9988\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0275 - accuracy: 0.9938 - val_loss: 0.2696 - val_accuracy: 0.9161\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.0080 - val_accuracy: 0.9988\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0060 - val_accuracy: 0.9994\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9989\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0052 - val_accuracy: 0.9993\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.1107 - val_accuracy: 0.9600\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9995\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9995\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0231 - val_accuracy: 0.9934\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.0056 - val_accuracy: 0.9993\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9995\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0392 - accuracy: 0.9885 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9996\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.7394e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0426 - accuracy: 0.9879 - val_loss: 0.0184 - val_accuracy: 0.9938\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.9833e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 8.4577e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 9.3397e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.3417e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.1020e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.2123e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.3213e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.7641e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.4525e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 6.6860e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.0879e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.0356e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.0719e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.2983e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.7196e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0337 - accuracy: 0.9910 - val_loss: 0.0843 - val_accuracy: 0.9697\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.6380e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.4337e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 5.8175e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.4407e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0153 - val_accuracy: 0.9953\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.1547e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.9753e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 5.2389e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7261e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.2927e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.2505 - val_accuracy: 0.9406\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.8270e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.1313e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.1841e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.6207e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.2070e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 3.6977e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 3.6586e-04 - accuracy: 1.0000 - val_loss: 9.8962e-04 - val_accuracy: 0.9998\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0258 - accuracy: 0.9925 - val_loss: 0.0241 - val_accuracy: 0.9926\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.7200e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.9641e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.2286e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.8086e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.4297e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.2004e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.0517e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 0.0165 - val_accuracy: 0.9952\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.6664e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.4961e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 3.9063e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.4845e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.1334e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.9038e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0117 - val_accuracy: 0.9962\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.7769e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.2653e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.6594e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 3.2273e-04 - accuracy: 1.0000 - val_loss: 9.8112e-04 - val_accuracy: 0.9997\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.8902e-04 - accuracy: 1.0000 - val_loss: 9.2446e-04 - val_accuracy: 0.9998\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.6232e-04 - accuracy: 1.0000 - val_loss: 8.8201e-04 - val_accuracy: 0.9998\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.4576e-04 - accuracy: 1.0000 - val_loss: 8.2269e-04 - val_accuracy: 0.9998\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.6690e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.1391e-04 - accuracy: 1.0000 - val_loss: 9.8893e-04 - val_accuracy: 0.9998\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.5464e-04 - accuracy: 1.0000 - val_loss: 8.9034e-04 - val_accuracy: 0.9998\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.1209e-04 - accuracy: 1.0000 - val_loss: 8.7333e-04 - val_accuracy: 0.9998\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 2.7795e-04 - accuracy: 1.0000 - val_loss: 8.1662e-04 - val_accuracy: 0.9998\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.5671e-04 - accuracy: 1.0000 - val_loss: 7.8123e-04 - val_accuracy: 0.9998\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.2763e-04 - accuracy: 1.0000 - val_loss: 7.0584e-04 - val_accuracy: 0.9998\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.1429e-04 - accuracy: 1.0000 - val_loss: 7.1231e-04 - val_accuracy: 0.9998\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0301 - accuracy: 0.9917 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.6886e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7907e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.8267e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.2509e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.8649e-04 - accuracy: 1.0000 - val_loss: 9.4721e-04 - val_accuracy: 0.9997\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.5208e-04 - accuracy: 1.0000 - val_loss: 9.0183e-04 - val_accuracy: 0.9998\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.3047e-04 - accuracy: 1.0000 - val_loss: 9.5819e-04 - val_accuracy: 0.9997\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 2.0929e-04 - accuracy: 1.0000 - val_loss: 7.8264e-04 - val_accuracy: 0.9998\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 1.8607e-04 - accuracy: 1.0000 - val_loss: 7.4384e-04 - val_accuracy: 0.9998\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.6792e-04 - accuracy: 1.0000 - val_loss: 8.2974e-04 - val_accuracy: 0.9997\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 9.9624e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7719e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.4461e-04 - accuracy: 1.0000 - val_loss: 9.4192e-04 - val_accuracy: 0.9998\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.8532e-04 - accuracy: 1.0000 - val_loss: 8.2963e-04 - val_accuracy: 0.9998\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.4713e-04 - accuracy: 1.0000 - val_loss: 7.6807e-04 - val_accuracy: 0.9998\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.1915e-04 - accuracy: 1.0000 - val_loss: 7.1993e-04 - val_accuracy: 0.9998\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.9621e-04 - accuracy: 1.0000 - val_loss: 7.4548e-04 - val_accuracy: 0.9998\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.7993e-04 - accuracy: 1.0000 - val_loss: 7.0368e-04 - val_accuracy: 0.9998\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.7005e-04 - accuracy: 1.0000 - val_loss: 5.9737e-04 - val_accuracy: 0.9998\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.6822e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 3.2275e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.7063e-04 - accuracy: 1.0000 - val_loss: 9.5253e-04 - val_accuracy: 0.9998\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.3556e-04 - accuracy: 1.0000 - val_loss: 8.5971e-04 - val_accuracy: 0.9998\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 2.0782e-04 - accuracy: 1.0000 - val_loss: 8.0923e-04 - val_accuracy: 0.9998\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.8674e-04 - accuracy: 1.0000 - val_loss: 7.4982e-04 - val_accuracy: 0.9998\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.6771e-04 - accuracy: 1.0000 - val_loss: 7.2724e-04 - val_accuracy: 0.9998\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.5574e-04 - accuracy: 1.0000 - val_loss: 8.2037e-04 - val_accuracy: 0.9998\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.3860e-04 - accuracy: 1.0000 - val_loss: 6.4309e-04 - val_accuracy: 0.9998\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.2790e-04 - accuracy: 1.0000 - val_loss: 6.9818e-04 - val_accuracy: 0.9998\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0192 - val_accuracy: 0.9937\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.0892e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.7900e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.3379e-04 - accuracy: 1.0000 - val_loss: 9.4723e-04 - val_accuracy: 0.9998\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.0242e-04 - accuracy: 1.0000 - val_loss: 9.2853e-04 - val_accuracy: 0.9998\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.7904e-04 - accuracy: 1.0000 - val_loss: 8.5994e-04 - val_accuracy: 0.9998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UoP1lMhQpsBS",
        "outputId": "41801b77-5ff0-42a5-b1db-ed6973288bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"integer\", reverse = True)\n",
        "score_lstm_reverse = ultimate_errors(model, x_tst, y_tst)\n",
        "results_dict[\"LSTM_rev\"] = score_lstm_reverse\n",
        "print(\"Accuracy:\", score_lstm_reverse[0])\n",
        "print(\"MSE:     \", score_lstm_reverse[1])\n",
        "print(\"MAE:     \", score_lstm_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.998803\n",
            "MSE:      2600.610196\n",
            "MAE:      0.391244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rGoMx_2vEKZ",
        "colab_type": "text"
      },
      "source": [
        "### Model: SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "509vgKD8vM91",
        "outputId": "8bc44c46-1dad-4b27-f5b5-ad5de09ae794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.SimpleRNN \n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_SimpleRNN\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_SimpleRNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               18048     \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 4, 128)            32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 52,492\n",
            "Trainable params: 52,492\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YeZ_lQpEvM-C"
      },
      "source": [
        "#### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9va4i1ASvM-F",
        "outputId": "85586697-d6e3-48ed-ce50-64e58a997e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_dict[\"SimpleRNN_plain\"] = history\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.6695 - accuracy: 0.3919 - val_loss: 1.5398 - val_accuracy: 0.4365\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.4471 - accuracy: 0.4659 - val_loss: 1.3372 - val_accuracy: 0.5056\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.2359 - accuracy: 0.5397 - val_loss: 1.1333 - val_accuracy: 0.5695\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.0232 - accuracy: 0.6125 - val_loss: 0.9286 - val_accuracy: 0.6447\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.8340 - accuracy: 0.6806 - val_loss: 0.7634 - val_accuracy: 0.7068\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.6893 - accuracy: 0.7392 - val_loss: 0.6459 - val_accuracy: 0.7524\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.5860 - accuracy: 0.7836 - val_loss: 0.5635 - val_accuracy: 0.7891\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.5135 - accuracy: 0.8141 - val_loss: 0.5251 - val_accuracy: 0.8027\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4562 - accuracy: 0.8371 - val_loss: 0.4498 - val_accuracy: 0.8363\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.4050 - accuracy: 0.8579 - val_loss: 0.4033 - val_accuracy: 0.8523\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.3697 - accuracy: 0.8715 - val_loss: 0.4241 - val_accuracy: 0.8339\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.3395 - accuracy: 0.8822 - val_loss: 0.3369 - val_accuracy: 0.8820\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.3137 - accuracy: 0.8917 - val_loss: 0.3251 - val_accuracy: 0.8875\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.2908 - accuracy: 0.8998 - val_loss: 0.3041 - val_accuracy: 0.8880\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.2678 - accuracy: 0.9092 - val_loss: 0.2769 - val_accuracy: 0.9011\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.2572 - accuracy: 0.9113 - val_loss: 0.2650 - val_accuracy: 0.9061\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.2471 - accuracy: 0.9150 - val_loss: 0.2548 - val_accuracy: 0.9070\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.2186 - accuracy: 0.9264 - val_loss: 0.2315 - val_accuracy: 0.9188\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.2122 - accuracy: 0.9285 - val_loss: 0.2738 - val_accuracy: 0.9006\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.2081 - accuracy: 0.9298 - val_loss: 0.2107 - val_accuracy: 0.9269\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1910 - accuracy: 0.9353 - val_loss: 0.2298 - val_accuracy: 0.9165\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1884 - accuracy: 0.9358 - val_loss: 0.1928 - val_accuracy: 0.9340\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1758 - accuracy: 0.9405 - val_loss: 0.1981 - val_accuracy: 0.9292\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1757 - accuracy: 0.9398 - val_loss: 0.2511 - val_accuracy: 0.9091\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1651 - accuracy: 0.9435 - val_loss: 0.1869 - val_accuracy: 0.9319\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1591 - accuracy: 0.9457 - val_loss: 0.1847 - val_accuracy: 0.9331\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1529 - accuracy: 0.9480 - val_loss: 0.1940 - val_accuracy: 0.9265\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1493 - accuracy: 0.9491 - val_loss: 0.1800 - val_accuracy: 0.9345\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1551 - accuracy: 0.9459 - val_loss: 0.1967 - val_accuracy: 0.9283\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1394 - accuracy: 0.9528 - val_loss: 0.1745 - val_accuracy: 0.9352\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1429 - accuracy: 0.9505 - val_loss: 0.1616 - val_accuracy: 0.9420\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1241 - accuracy: 0.9585 - val_loss: 0.1620 - val_accuracy: 0.9398\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1336 - accuracy: 0.9542 - val_loss: 0.2221 - val_accuracy: 0.9192\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1286 - accuracy: 0.9561 - val_loss: 0.1604 - val_accuracy: 0.9414\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1210 - accuracy: 0.9590 - val_loss: 0.2151 - val_accuracy: 0.9265\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1321 - accuracy: 0.9540 - val_loss: 0.1875 - val_accuracy: 0.9338\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1143 - accuracy: 0.9611 - val_loss: 0.1594 - val_accuracy: 0.9424\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 0.1020 - accuracy: 0.9668 - val_loss: 0.1383 - val_accuracy: 0.9509\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1304 - accuracy: 0.9545 - val_loss: 0.1313 - val_accuracy: 0.9536\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1116 - accuracy: 0.9626 - val_loss: 0.1307 - val_accuracy: 0.9542\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1027 - accuracy: 0.9659 - val_loss: 0.1481 - val_accuracy: 0.9459\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1122 - accuracy: 0.9617 - val_loss: 0.2092 - val_accuracy: 0.9272\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.1266 - accuracy: 0.9568 - val_loss: 0.1290 - val_accuracy: 0.9525\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1009 - accuracy: 0.9661 - val_loss: 0.1680 - val_accuracy: 0.9392\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0958 - accuracy: 0.9686 - val_loss: 0.1309 - val_accuracy: 0.9531\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.1205 - accuracy: 0.9588 - val_loss: 0.1243 - val_accuracy: 0.9552\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0759 - accuracy: 0.9760 - val_loss: 0.1157 - val_accuracy: 0.9580\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0856 - accuracy: 0.9721 - val_loss: 0.1281 - val_accuracy: 0.9546\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1123 - accuracy: 0.9613 - val_loss: 0.2611 - val_accuracy: 0.9076\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1011 - accuracy: 0.9659 - val_loss: 0.1357 - val_accuracy: 0.9500\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0747 - accuracy: 0.9763 - val_loss: 0.1260 - val_accuracy: 0.9535\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.1079 - accuracy: 0.9629 - val_loss: 0.2398 - val_accuracy: 0.9166\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0874 - accuracy: 0.9708 - val_loss: 0.1059 - val_accuracy: 0.9632\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0808 - accuracy: 0.9733 - val_loss: 0.1648 - val_accuracy: 0.9419\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1161 - accuracy: 0.9599 - val_loss: 0.1290 - val_accuracy: 0.9537\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0790 - accuracy: 0.9742 - val_loss: 0.1058 - val_accuracy: 0.9638\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0677 - accuracy: 0.9784 - val_loss: 0.1158 - val_accuracy: 0.9589\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0871 - accuracy: 0.9702 - val_loss: 0.1948 - val_accuracy: 0.9334\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0941 - accuracy: 0.9679 - val_loss: 0.1571 - val_accuracy: 0.9453\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0840 - accuracy: 0.9711 - val_loss: 0.1322 - val_accuracy: 0.9526\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0849 - accuracy: 0.9708 - val_loss: 0.1242 - val_accuracy: 0.9556\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0618 - accuracy: 0.9805 - val_loss: 0.1189 - val_accuracy: 0.9590\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0899 - accuracy: 0.9687 - val_loss: 0.1491 - val_accuracy: 0.9463\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1052 - accuracy: 0.9638 - val_loss: 0.1762 - val_accuracy: 0.9372\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0763 - accuracy: 0.9743 - val_loss: 0.1053 - val_accuracy: 0.9622\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0580 - accuracy: 0.9814 - val_loss: 0.1165 - val_accuracy: 0.9591\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0748 - accuracy: 0.9745 - val_loss: 0.2346 - val_accuracy: 0.9223\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1183 - accuracy: 0.9584 - val_loss: 0.1564 - val_accuracy: 0.9431\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0592 - accuracy: 0.9812 - val_loss: 0.0989 - val_accuracy: 0.9637\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.1197 - val_accuracy: 0.9574\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1062 - accuracy: 0.9635 - val_loss: 0.1216 - val_accuracy: 0.9542\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0919 - accuracy: 0.9682 - val_loss: 0.1071 - val_accuracy: 0.9615\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.0957 - val_accuracy: 0.9658\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 0.1081 - val_accuracy: 0.9615\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0605 - accuracy: 0.9801 - val_loss: 0.1436 - val_accuracy: 0.9503\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 0.1345 - val_accuracy: 0.9531\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0715 - accuracy: 0.9757 - val_loss: 0.1276 - val_accuracy: 0.9559\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0846 - accuracy: 0.9719 - val_loss: 0.0998 - val_accuracy: 0.9660\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0507 - accuracy: 0.9848 - val_loss: 0.1459 - val_accuracy: 0.9474\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0916 - accuracy: 0.9678 - val_loss: 0.1673 - val_accuracy: 0.9419\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0569 - accuracy: 0.9816 - val_loss: 0.0990 - val_accuracy: 0.9658\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.1226 - val_accuracy: 0.9574\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.1219 - accuracy: 0.9580 - val_loss: 0.1711 - val_accuracy: 0.9431\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.0980 - val_accuracy: 0.9661\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0368 - accuracy: 0.9900 - val_loss: 0.1484 - val_accuracy: 0.9492\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1159 - accuracy: 0.9609 - val_loss: 0.1055 - val_accuracy: 0.9630\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0379 - accuracy: 0.9894 - val_loss: 0.0803 - val_accuracy: 0.9716\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.1081 - val_accuracy: 0.9622\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1122 - accuracy: 0.9619 - val_loss: 0.1098 - val_accuracy: 0.9604\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0387 - accuracy: 0.9891 - val_loss: 0.0827 - val_accuracy: 0.9708\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0860 - val_accuracy: 0.9701\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0734 - accuracy: 0.9754 - val_loss: 0.1805 - val_accuracy: 0.9400\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0835 - accuracy: 0.9723 - val_loss: 0.0901 - val_accuracy: 0.9683\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.0797 - val_accuracy: 0.9726\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 0.3422 - val_accuracy: 0.9090\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1246 - accuracy: 0.9578 - val_loss: 0.1036 - val_accuracy: 0.9645\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 0.0784 - val_accuracy: 0.9733\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 0.1041 - val_accuracy: 0.9621\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0713 - accuracy: 0.9757 - val_loss: 0.1320 - val_accuracy: 0.9546\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 0.1002 - val_accuracy: 0.9639\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1051 - accuracy: 0.9654 - val_loss: 0.1538 - val_accuracy: 0.9470\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0616 - accuracy: 0.9800 - val_loss: 0.1203 - val_accuracy: 0.9595\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0343 - accuracy: 0.9905 - val_loss: 0.0817 - val_accuracy: 0.9710\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0575 - accuracy: 0.9811 - val_loss: 0.1247 - val_accuracy: 0.9564\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0787 - accuracy: 0.9736 - val_loss: 0.1278 - val_accuracy: 0.9563\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0543 - accuracy: 0.9826 - val_loss: 0.1486 - val_accuracy: 0.9502\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0481 - accuracy: 0.9850 - val_loss: 0.0801 - val_accuracy: 0.9719\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0686 - accuracy: 0.9791 - val_loss: 0.2592 - val_accuracy: 0.9158\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.0938 - val_accuracy: 0.9662\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.0924 - val_accuracy: 0.9668\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0744 - accuracy: 0.9748 - val_loss: 0.1781 - val_accuracy: 0.9399\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0640 - accuracy: 0.9785 - val_loss: 0.1025 - val_accuracy: 0.9652\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0328 - accuracy: 0.9907 - val_loss: 0.0862 - val_accuracy: 0.9679\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0823 - accuracy: 0.9734 - val_loss: 0.2018 - val_accuracy: 0.9326\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0976 - accuracy: 0.9682 - val_loss: 0.0964 - val_accuracy: 0.9660\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0306 - accuracy: 0.9917 - val_loss: 0.1019 - val_accuracy: 0.9662\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.0887 - val_accuracy: 0.9695\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0882 - val_accuracy: 0.9675\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1084 - accuracy: 0.9657 - val_loss: 0.2581 - val_accuracy: 0.9180\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0746 - accuracy: 0.9746 - val_loss: 0.1281 - val_accuracy: 0.9550\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0288 - accuracy: 0.9922 - val_loss: 0.0814 - val_accuracy: 0.9692\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.1612 - val_accuracy: 0.9451\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 0.0979 - val_accuracy: 0.9657\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0464 - accuracy: 0.9845 - val_loss: 0.1075 - val_accuracy: 0.9642\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0863 - accuracy: 0.9710 - val_loss: 0.1110 - val_accuracy: 0.9628\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0968 - accuracy: 0.9694 - val_loss: 0.1081 - val_accuracy: 0.9626\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0706 - val_accuracy: 0.9751\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.0996 - val_accuracy: 0.9667\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0875 - accuracy: 0.9713 - val_loss: 0.1756 - val_accuracy: 0.9423\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0694 - accuracy: 0.9762 - val_loss: 0.1191 - val_accuracy: 0.9614\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0301 - accuracy: 0.9916 - val_loss: 0.0666 - val_accuracy: 0.9766\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 0.0726 - val_accuracy: 0.9742\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0562 - accuracy: 0.9811 - val_loss: 0.1850 - val_accuracy: 0.9405\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0665 - accuracy: 0.9771 - val_loss: 0.1124 - val_accuracy: 0.9608\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.1658 - val_accuracy: 0.9467\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1110 - accuracy: 0.9634 - val_loss: 0.1071 - val_accuracy: 0.9628\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 8s 23ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.0781 - val_accuracy: 0.9735\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0845 - accuracy: 0.9720 - val_loss: 0.1160 - val_accuracy: 0.9589\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0746 - val_accuracy: 0.9736\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 0.1116 - val_accuracy: 0.9617\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1284 - accuracy: 0.9583 - val_loss: 0.1109 - val_accuracy: 0.9619\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 0.0677 - val_accuracy: 0.9781\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 0.0821 - val_accuracy: 0.9703\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.0812 - val_accuracy: 0.9711\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0826 - accuracy: 0.9739 - val_loss: 0.3217 - val_accuracy: 0.9072\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0988 - accuracy: 0.9673 - val_loss: 0.0940 - val_accuracy: 0.9688\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0852 - val_accuracy: 0.9715\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0719 - val_accuracy: 0.9759\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.0863 - val_accuracy: 0.9707\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1017 - accuracy: 0.9665 - val_loss: 0.2551 - val_accuracy: 0.9252\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0500 - accuracy: 0.9835 - val_loss: 0.0810 - val_accuracy: 0.9704\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.0701 - val_accuracy: 0.9755\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.1653 - val_accuracy: 0.9444\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0902 - accuracy: 0.9692 - val_loss: 0.1459 - val_accuracy: 0.9528\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0608 - accuracy: 0.9802 - val_loss: 0.0872 - val_accuracy: 0.9692\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0361 - accuracy: 0.9903 - val_loss: 0.3711 - val_accuracy: 0.9071\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0669 - accuracy: 0.9776 - val_loss: 0.0828 - val_accuracy: 0.9701\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.0712 - val_accuracy: 0.9747\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0609 - accuracy: 0.9796 - val_loss: 0.1257 - val_accuracy: 0.9574\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.1092 - val_accuracy: 0.9647\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0783 - accuracy: 0.9749 - val_loss: 0.3195 - val_accuracy: 0.9089\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0712 - accuracy: 0.9763 - val_loss: 0.0768 - val_accuracy: 0.9740\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.0725 - val_accuracy: 0.9749\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.0827 - val_accuracy: 0.9716\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1126 - accuracy: 0.9639 - val_loss: 0.1509 - val_accuracy: 0.9508\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.0703 - val_accuracy: 0.9743\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 0.0608 - val_accuracy: 0.9796\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.0628 - val_accuracy: 0.9778\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0784 - accuracy: 0.9757 - val_loss: 0.3568 - val_accuracy: 0.9019\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0736 - accuracy: 0.9759 - val_loss: 0.0784 - val_accuracy: 0.9728\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0216 - accuracy: 0.9943 - val_loss: 0.0739 - val_accuracy: 0.9732\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0976 - accuracy: 0.9695 - val_loss: 0.1191 - val_accuracy: 0.9598\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.2199 - val_accuracy: 0.9336\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.0756 - val_accuracy: 0.9736\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.0770 - val_accuracy: 0.9736\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.1578 - val_accuracy: 0.9500\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0890 - accuracy: 0.9700 - val_loss: 0.1167 - val_accuracy: 0.9599\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0770 - val_accuracy: 0.9719\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.0700 - val_accuracy: 0.9760\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0368 - accuracy: 0.9883 - val_loss: 0.1672 - val_accuracy: 0.9461\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1163 - accuracy: 0.9612 - val_loss: 0.0852 - val_accuracy: 0.9700\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0756 - val_accuracy: 0.9746\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.0600 - val_accuracy: 0.9799\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.1103 - val_accuracy: 0.9622\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1158 - accuracy: 0.9622 - val_loss: 0.2048 - val_accuracy: 0.9370\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0768 - accuracy: 0.9748 - val_loss: 0.0829 - val_accuracy: 0.9704\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 0.0527 - val_accuracy: 0.9815\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.0563 - val_accuracy: 0.9795\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.4286 - val_accuracy: 0.8898\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1370 - accuracy: 0.9580 - val_loss: 0.0852 - val_accuracy: 0.9699\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0186 - accuracy: 0.9956 - val_loss: 0.0665 - val_accuracy: 0.9772\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 0.0796 - val_accuracy: 0.9728\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0987 - accuracy: 0.9688 - val_loss: 0.1585 - val_accuracy: 0.9482\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0624 - accuracy: 0.9804 - val_loss: 0.0704 - val_accuracy: 0.9767\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.0952 - val_accuracy: 0.9732\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 0.0721 - val_accuracy: 0.9753\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0879 - accuracy: 0.9758 - val_loss: 0.4384 - val_accuracy: 0.8795\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0737 - accuracy: 0.9758 - val_loss: 0.0834 - val_accuracy: 0.9712\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.0700 - val_accuracy: 0.9764\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0713 - val_accuracy: 0.9747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q0lSqeYgvM-K",
        "outputId": "2e0902b3-a2f6-4eaf-dd58-703e7fc534f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"integer\", reverse = False)\n",
        "score_simplernn_plain = ultimate_errors(model, x_tst, y_tst)\n",
        "results_dict[\"SimpleRNN_plain\"] = score_simplernn_plain\n",
        "print(\"Accuracy:\", score_simplernn_plain[0])\n",
        "print(\"MSE:     \", score_simplernn_plain[1])\n",
        "print(\"MAE:     \", score_simplernn_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.839604\n",
            "MSE:      82362.182305\n",
            "MAE:      16.622965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hs7q-gvKvM-N"
      },
      "source": [
        "#### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj6dg2_sKEj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# built the model to initialize new weights\n",
        "model = Sequential(name = \"model_SimpleRNN\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eAc1gK25vM-P",
        "outputId": "f04bdacd-2637-44f7-9022-57a4b5bf75fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_dict[\"SimpleRNN_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 1.6766 - accuracy: 0.3927 - val_loss: 1.5605 - val_accuracy: 0.4245\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.4627 - accuracy: 0.4564 - val_loss: 1.3694 - val_accuracy: 0.4843\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.2207 - accuracy: 0.5321 - val_loss: 1.0942 - val_accuracy: 0.5759\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.9455 - accuracy: 0.6345 - val_loss: 0.8464 - val_accuracy: 0.6791\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.7436 - accuracy: 0.7162 - val_loss: 0.6727 - val_accuracy: 0.7487\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.6076 - accuracy: 0.7755 - val_loss: 0.5892 - val_accuracy: 0.7764\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.5106 - accuracy: 0.8187 - val_loss: 0.4900 - val_accuracy: 0.8257\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.4367 - accuracy: 0.8497 - val_loss: 0.4270 - val_accuracy: 0.8499\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.3885 - accuracy: 0.8685 - val_loss: 0.4014 - val_accuracy: 0.8511\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.3331 - accuracy: 0.8917 - val_loss: 0.3537 - val_accuracy: 0.8816\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.3021 - accuracy: 0.9010 - val_loss: 0.3148 - val_accuracy: 0.8928\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.2761 - accuracy: 0.9100 - val_loss: 0.2947 - val_accuracy: 0.9017\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.2437 - accuracy: 0.9227 - val_loss: 0.2554 - val_accuracy: 0.9149\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.2294 - accuracy: 0.9269 - val_loss: 0.2827 - val_accuracy: 0.9018\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.2056 - accuracy: 0.9354 - val_loss: 0.2562 - val_accuracy: 0.9168\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1920 - accuracy: 0.9396 - val_loss: 0.2197 - val_accuracy: 0.9269\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1692 - accuracy: 0.9484 - val_loss: 0.2106 - val_accuracy: 0.9295\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1728 - accuracy: 0.9449 - val_loss: 0.1860 - val_accuracy: 0.9372\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1472 - accuracy: 0.9547 - val_loss: 0.1752 - val_accuracy: 0.9414\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1537 - accuracy: 0.9511 - val_loss: 0.1589 - val_accuracy: 0.9490\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1353 - accuracy: 0.9588 - val_loss: 0.1984 - val_accuracy: 0.9317\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1321 - accuracy: 0.9581 - val_loss: 0.2334 - val_accuracy: 0.9204\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1220 - accuracy: 0.9627 - val_loss: 0.1640 - val_accuracy: 0.9452\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.1168 - accuracy: 0.9635 - val_loss: 0.1312 - val_accuracy: 0.9557\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.1291 - val_accuracy: 0.9569\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1152 - accuracy: 0.9635 - val_loss: 0.1268 - val_accuracy: 0.9594\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0921 - accuracy: 0.9723 - val_loss: 0.1228 - val_accuracy: 0.9584\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0943 - accuracy: 0.9709 - val_loss: 0.1199 - val_accuracy: 0.9596\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0801 - accuracy: 0.9762 - val_loss: 0.1076 - val_accuracy: 0.9674\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1219 - accuracy: 0.9594 - val_loss: 0.1335 - val_accuracy: 0.9524\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1071 - accuracy: 0.9662 - val_loss: 0.1044 - val_accuracy: 0.9661\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0651 - accuracy: 0.9823 - val_loss: 0.1093 - val_accuracy: 0.9640\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0840 - accuracy: 0.9732 - val_loss: 0.2259 - val_accuracy: 0.9223\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0832 - accuracy: 0.9735 - val_loss: 0.1084 - val_accuracy: 0.9641\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0676 - accuracy: 0.9798 - val_loss: 0.1177 - val_accuracy: 0.9599\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 9s 25ms/step - loss: 0.0811 - accuracy: 0.9738 - val_loss: 0.1762 - val_accuracy: 0.9387\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0910 - accuracy: 0.9704 - val_loss: 0.0772 - val_accuracy: 0.9754\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0579 - accuracy: 0.9836 - val_loss: 0.1105 - val_accuracy: 0.9630\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.0718 - val_accuracy: 0.9783\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0844 - accuracy: 0.9728 - val_loss: 0.0766 - val_accuracy: 0.9751\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.0980 - val_accuracy: 0.9665\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 0.0808 - val_accuracy: 0.9734\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0568 - accuracy: 0.9831 - val_loss: 0.1394 - val_accuracy: 0.9541\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0655 - accuracy: 0.9793 - val_loss: 0.0785 - val_accuracy: 0.9733\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0430 - accuracy: 0.9883 - val_loss: 0.0890 - val_accuracy: 0.9693\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0892 - accuracy: 0.9699 - val_loss: 0.1574 - val_accuracy: 0.9446\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0656 - accuracy: 0.9791 - val_loss: 0.0798 - val_accuracy: 0.9733\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0321 - accuracy: 0.9924 - val_loss: 0.0615 - val_accuracy: 0.9793\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.1743 - val_accuracy: 0.9431\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0712 - accuracy: 0.9773 - val_loss: 0.0574 - val_accuracy: 0.9816\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.0675 - val_accuracy: 0.9785\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0793 - accuracy: 0.9734 - val_loss: 0.0825 - val_accuracy: 0.9722\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.0583 - val_accuracy: 0.9805\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 0.1660 - val_accuracy: 0.9452\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0833 - accuracy: 0.9721 - val_loss: 0.0944 - val_accuracy: 0.9674\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0445 - accuracy: 0.9865 - val_loss: 0.0631 - val_accuracy: 0.9793\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0560 - val_accuracy: 0.9816\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0729 - accuracy: 0.9762 - val_loss: 0.0846 - val_accuracy: 0.9725\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0299 - accuracy: 0.9922 - val_loss: 0.0493 - val_accuracy: 0.9845\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.1258 - val_accuracy: 0.9567\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0947 - accuracy: 0.9693 - val_loss: 0.0666 - val_accuracy: 0.9777\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0240 - accuracy: 0.9945 - val_loss: 0.0422 - val_accuracy: 0.9870\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 0.0466 - val_accuracy: 0.9848\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0619 - accuracy: 0.9808 - val_loss: 0.1870 - val_accuracy: 0.9371\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0516 - accuracy: 0.9839 - val_loss: 0.0432 - val_accuracy: 0.9863\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0190 - accuracy: 0.9963 - val_loss: 0.0458 - val_accuracy: 0.9851\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.1771 - val_accuracy: 0.9424\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0860 - accuracy: 0.9716 - val_loss: 0.0523 - val_accuracy: 0.9829\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0487 - val_accuracy: 0.9851\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0544 - accuracy: 0.9849 - val_loss: 0.2908 - val_accuracy: 0.9154\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.0440 - val_accuracy: 0.9862\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.0437 - val_accuracy: 0.9869\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0603 - val_accuracy: 0.9794\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.1077 - accuracy: 0.9643 - val_loss: 0.0912 - val_accuracy: 0.9698\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 0.0358 - val_accuracy: 0.9890\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.0301 - val_accuracy: 0.9913\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.0519 - val_accuracy: 0.9833\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.1006 - accuracy: 0.9684 - val_loss: 0.0480 - val_accuracy: 0.9845\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.0404 - val_accuracy: 0.9885\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.1166 - val_accuracy: 0.9627\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0933 - accuracy: 0.9689 - val_loss: 0.0746 - val_accuracy: 0.9751\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.0349 - val_accuracy: 0.9891\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.0417 - val_accuracy: 0.9865\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0596 - accuracy: 0.9813 - val_loss: 0.1047 - val_accuracy: 0.9637\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0581 - accuracy: 0.9811 - val_loss: 0.1024 - val_accuracy: 0.9653\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0220 - accuracy: 0.9943 - val_loss: 0.0305 - val_accuracy: 0.9913\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0384 - val_accuracy: 0.9883\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 0.0658 - val_accuracy: 0.9774\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0555 - accuracy: 0.9818 - val_loss: 0.0416 - val_accuracy: 0.9863\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.0263 - val_accuracy: 0.9926\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0225 - val_accuracy: 0.9941\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0263 - val_accuracy: 0.9921\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1029 - accuracy: 0.9707 - val_loss: 0.1510 - val_accuracy: 0.9492\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 0.0367 - val_accuracy: 0.9892\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 0.0270 - val_accuracy: 0.9924\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0242 - val_accuracy: 0.9934\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0455 - val_accuracy: 0.9854\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1064 - accuracy: 0.9663 - val_loss: 0.0547 - val_accuracy: 0.9824\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.0330 - val_accuracy: 0.9895\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.0381 - val_accuracy: 0.9877\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0956 - accuracy: 0.9695 - val_loss: 0.0590 - val_accuracy: 0.9794\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0358 - val_accuracy: 0.9898\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.0266 - val_accuracy: 0.9919\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.0200 - val_accuracy: 0.9948\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0882 - val_accuracy: 0.9718\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0961 - accuracy: 0.9685 - val_loss: 0.0539 - val_accuracy: 0.9833\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.0302 - val_accuracy: 0.9908\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0277 - val_accuracy: 0.9925\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.1569 - val_accuracy: 0.9543\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0887 - accuracy: 0.9714 - val_loss: 0.0664 - val_accuracy: 0.9775\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0293 - val_accuracy: 0.9911\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0229 - val_accuracy: 0.9939\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0857 - val_accuracy: 0.9711\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0796 - accuracy: 0.9752 - val_loss: 0.0370 - val_accuracy: 0.9888\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 0.0245 - val_accuracy: 0.9930\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0188 - val_accuracy: 0.9948\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0754 - val_accuracy: 0.9772\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1229 - accuracy: 0.9613 - val_loss: 0.0638 - val_accuracy: 0.9794\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0267 - val_accuracy: 0.9919\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.0204 - val_accuracy: 0.9948\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.0195 - val_accuracy: 0.9948\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0224 - val_accuracy: 0.9933\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1324 - accuracy: 0.9612 - val_loss: 0.1116 - val_accuracy: 0.9636\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.0305 - val_accuracy: 0.9908\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.0258 - val_accuracy: 0.9919\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.0269 - val_accuracy: 0.9918\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.0557 - val_accuracy: 0.9826\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0329 - val_accuracy: 0.9897\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.0258 - val_accuracy: 0.9926\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0235 - accuracy: 0.9934 - val_loss: 0.1258 - val_accuracy: 0.9602\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0896 - accuracy: 0.9718 - val_loss: 0.1044 - val_accuracy: 0.9685\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.0268 - val_accuracy: 0.9920\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 7s 18ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.0205 - val_accuracy: 0.9942\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0164 - val_accuracy: 0.9953\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0710 - accuracy: 0.9779 - val_loss: 0.1962 - val_accuracy: 0.9507\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0301 - val_accuracy: 0.9901\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.0269 - val_accuracy: 0.9922\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0191 - val_accuracy: 0.9948\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 0.3091 - val_accuracy: 0.9144\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0669 - accuracy: 0.9790 - val_loss: 0.0320 - val_accuracy: 0.9902\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0291 - val_accuracy: 0.9902\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.0212 - val_accuracy: 0.9936\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0195 - val_accuracy: 0.9941\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.1865 - val_accuracy: 0.9439\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1060 - accuracy: 0.9668 - val_loss: 0.0420 - val_accuracy: 0.9869\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0258 - val_accuracy: 0.9928\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.0192 - val_accuracy: 0.9948\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0406 - val_accuracy: 0.9863\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0947 - accuracy: 0.9705 - val_loss: 0.0404 - val_accuracy: 0.9868\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.0303 - val_accuracy: 0.9909\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0198 - val_accuracy: 0.9944\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0173 - val_accuracy: 0.9954\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0167 - val_accuracy: 0.9953\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0165 - val_accuracy: 0.9954\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0208 - val_accuracy: 0.9940\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.1475 - accuracy: 0.9584 - val_loss: 0.0547 - val_accuracy: 0.9830\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.0272 - val_accuracy: 0.9919\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0231 - val_accuracy: 0.9932\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0454 - val_accuracy: 0.9859\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0652 - accuracy: 0.9791 - val_loss: 0.1282 - val_accuracy: 0.9626\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.0319 - val_accuracy: 0.9900\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0242 - val_accuracy: 0.9925\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.0372 - val_accuracy: 0.9882\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0469 - val_accuracy: 0.9847\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.1847 - val_accuracy: 0.9469\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0305 - accuracy: 0.9907 - val_loss: 0.0276 - val_accuracy: 0.9919\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0353 - val_accuracy: 0.9894\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.0428 - val_accuracy: 0.9862\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0423 - accuracy: 0.9867 - val_loss: 0.1227 - val_accuracy: 0.9605\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0226 - val_accuracy: 0.9937\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.0290 - val_accuracy: 0.9909\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0460 - accuracy: 0.9868 - val_loss: 0.2103 - val_accuracy: 0.9419\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.0291 - val_accuracy: 0.9912\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.0258 - val_accuracy: 0.9925\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0176 - val_accuracy: 0.9952\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0152 - val_accuracy: 0.9961\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9963\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0140 - val_accuracy: 0.9962\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0912 - accuracy: 0.9769 - val_loss: 0.2987 - val_accuracy: 0.9130\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0725 - accuracy: 0.9771 - val_loss: 0.0297 - val_accuracy: 0.9903\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.0226 - val_accuracy: 0.9934\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0160 - val_accuracy: 0.9958\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0159 - val_accuracy: 0.9954\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0670 - accuracy: 0.9816 - val_loss: 0.1592 - val_accuracy: 0.9476\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0386 - accuracy: 0.9876 - val_loss: 0.0287 - val_accuracy: 0.9913\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.0200 - val_accuracy: 0.9941\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0190 - val_accuracy: 0.9948\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.1525 - val_accuracy: 0.9524\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0284 - val_accuracy: 0.9914\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0189 - val_accuracy: 0.9949\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0154 - val_accuracy: 0.9956\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9959\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9962\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9959\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.1694 - val_accuracy: 0.9584\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1423 - accuracy: 0.9574 - val_loss: 0.1658 - val_accuracy: 0.9535\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.0287 - val_accuracy: 0.9907\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.0203 - val_accuracy: 0.9937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EGTZA7o6vM-S",
        "outputId": "8ac7028c-60a5-447a-ddb0-cf9b194ce702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"integer\", reverse = True)\n",
        "score_simplernn_reverse = ultimate_errors(model, x_tst, y_tst)\n",
        "results_dict[\"SimpleRNN_rev\"] = score_simplernn_reverse\n",
        "print(\"Accuracy:\", score_simplernn_reverse[0])\n",
        "print(\"MSE:     \", score_simplernn_reverse[1])\n",
        "print(\"MAE:     \", score_simplernn_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.957931\n",
            "MSE:      15667.299186\n",
            "MAE:      3.393186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l1nwToDnUcrb"
      },
      "source": [
        "### Model: GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eisMS5kRUcrc",
        "outputId": "a400ddcc-cc88-4c59-f449-6df385bb2415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.GRU\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_GRU\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 128)               54528     \n",
            "_________________________________________________________________\n",
            "repeat_vector_4 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 4, 128)            99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 155,148\n",
            "Trainable params: 155,148\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FXyowEk6Ucrf"
      },
      "source": [
        "#### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "glHJMoEHUcrg",
        "outputId": "1eb6309f-48ef-44e6-b9aa-3d544bd5573e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_dict[\"GRU_plain\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 4s 12ms/step - loss: 1.8582 - accuracy: 0.3281 - val_loss: 1.7544 - val_accuracy: 0.3478\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.6388 - accuracy: 0.3853 - val_loss: 1.5176 - val_accuracy: 0.4279\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.4163 - accuracy: 0.4674 - val_loss: 1.3284 - val_accuracy: 0.5046\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.2854 - accuracy: 0.5190 - val_loss: 1.2547 - val_accuracy: 0.5301\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.2163 - accuracy: 0.5438 - val_loss: 1.1985 - val_accuracy: 0.5494\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.1685 - accuracy: 0.5588 - val_loss: 1.1364 - val_accuracy: 0.5723\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.1070 - accuracy: 0.5827 - val_loss: 1.0676 - val_accuracy: 0.5980\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.0402 - accuracy: 0.6059 - val_loss: 1.0040 - val_accuracy: 0.6188\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.9728 - accuracy: 0.6328 - val_loss: 0.9679 - val_accuracy: 0.6292\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.9262 - accuracy: 0.6508 - val_loss: 0.9035 - val_accuracy: 0.6586\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8807 - accuracy: 0.6680 - val_loss: 0.8759 - val_accuracy: 0.6665\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8447 - accuracy: 0.6819 - val_loss: 0.8384 - val_accuracy: 0.6810\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8061 - accuracy: 0.6981 - val_loss: 0.7998 - val_accuracy: 0.6971\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7769 - accuracy: 0.7066 - val_loss: 0.7807 - val_accuracy: 0.7003\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7527 - accuracy: 0.7160 - val_loss: 0.7589 - val_accuracy: 0.7115\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7304 - accuracy: 0.7248 - val_loss: 0.7347 - val_accuracy: 0.7220\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.7091 - accuracy: 0.7324 - val_loss: 0.7048 - val_accuracy: 0.7314\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6843 - accuracy: 0.7431 - val_loss: 0.7548 - val_accuracy: 0.7077\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6544 - accuracy: 0.7530 - val_loss: 0.6609 - val_accuracy: 0.7459\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6107 - accuracy: 0.7695 - val_loss: 0.5981 - val_accuracy: 0.7717\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.5548 - accuracy: 0.7912 - val_loss: 0.5427 - val_accuracy: 0.7915\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.4941 - accuracy: 0.8149 - val_loss: 0.4785 - val_accuracy: 0.8231\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.4255 - accuracy: 0.8438 - val_loss: 0.4083 - val_accuracy: 0.8494\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3616 - accuracy: 0.8714 - val_loss: 0.3522 - val_accuracy: 0.8723\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3028 - accuracy: 0.8963 - val_loss: 0.2832 - val_accuracy: 0.9035\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2527 - accuracy: 0.9158 - val_loss: 0.2493 - val_accuracy: 0.9161\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2096 - accuracy: 0.9330 - val_loss: 0.2020 - val_accuracy: 0.9356\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1785 - accuracy: 0.9450 - val_loss: 0.1795 - val_accuracy: 0.9409\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1473 - accuracy: 0.9568 - val_loss: 0.1522 - val_accuracy: 0.9520\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1277 - accuracy: 0.9637 - val_loss: 0.1296 - val_accuracy: 0.9602\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1162 - accuracy: 0.9670 - val_loss: 0.1256 - val_accuracy: 0.9596\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0945 - accuracy: 0.9746 - val_loss: 0.1027 - val_accuracy: 0.9706\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0919 - accuracy: 0.9746 - val_loss: 0.0972 - val_accuracy: 0.9717\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0718 - accuracy: 0.9820 - val_loss: 0.0865 - val_accuracy: 0.9741\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0831 - accuracy: 0.9763 - val_loss: 0.0791 - val_accuracy: 0.9754\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0613 - accuracy: 0.9843 - val_loss: 0.1074 - val_accuracy: 0.9655\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0660 - accuracy: 0.9815 - val_loss: 0.0626 - val_accuracy: 0.9808\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0425 - accuracy: 0.9907 - val_loss: 0.0687 - val_accuracy: 0.9769\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0615 - accuracy: 0.9830 - val_loss: 0.0943 - val_accuracy: 0.9682\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.0533 - val_accuracy: 0.9830\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0521 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9779\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0320 - accuracy: 0.9927 - val_loss: 0.0452 - val_accuracy: 0.9862\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.1229 - val_accuracy: 0.9581\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0458 - accuracy: 0.9865 - val_loss: 0.0591 - val_accuracy: 0.9816\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.0453 - val_accuracy: 0.9859\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0372 - accuracy: 0.9891 - val_loss: 0.0482 - val_accuracy: 0.9826\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.0585 - val_accuracy: 0.9809\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.0786 - val_accuracy: 0.9723\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9893 - val_loss: 0.0646 - val_accuracy: 0.9782\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0440 - accuracy: 0.9872 - val_loss: 0.0379 - val_accuracy: 0.9881\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 0.0626 - val_accuracy: 0.9794\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0356 - val_accuracy: 0.9883\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0445 - val_accuracy: 0.9847\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0380 - accuracy: 0.9883 - val_loss: 0.0382 - val_accuracy: 0.9865\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0431 - val_accuracy: 0.9869\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.0275 - val_accuracy: 0.9920\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.0227 - val_accuracy: 0.9935\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.0339 - val_accuracy: 0.9891\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.0540 - val_accuracy: 0.9817\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0617 - val_accuracy: 0.9791\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.0411 - val_accuracy: 0.9865\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 0.0784 - val_accuracy: 0.9717\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.0260 - val_accuracy: 0.9916\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0201 - val_accuracy: 0.9940\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0399 - val_accuracy: 0.9864\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.0846 - val_accuracy: 0.9752\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.0807 - val_accuracy: 0.9722\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.0215 - val_accuracy: 0.9930\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0152 - val_accuracy: 0.9954\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0416 - val_accuracy: 0.9862\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.0325 - val_accuracy: 0.9894\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.0780 - val_accuracy: 0.9751\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 0.0245 - val_accuracy: 0.9918\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0136 - val_accuracy: 0.9962\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0118 - val_accuracy: 0.9968\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0430 - accuracy: 0.9871 - val_loss: 0.0789 - val_accuracy: 0.9732\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0172 - val_accuracy: 0.9947\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0125 - val_accuracy: 0.9964\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0115 - val_accuracy: 0.9967\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0476 - val_accuracy: 0.9844\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0706 - val_accuracy: 0.9779\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0318 - val_accuracy: 0.9891\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0167 - val_accuracy: 0.9944\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0937 - val_accuracy: 0.9737\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.0468 - val_accuracy: 0.9854\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0144 - val_accuracy: 0.9959\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0186 - val_accuracy: 0.9941\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0287 - val_accuracy: 0.9901\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0195 - val_accuracy: 0.9938\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0182 - val_accuracy: 0.9941\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.0442 - val_accuracy: 0.9852\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0134 - val_accuracy: 0.9959\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0085 - val_accuracy: 0.9976\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0588 - val_accuracy: 0.9814\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.0233 - val_accuracy: 0.9930\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0310 - val_accuracy: 0.9898\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0142 - val_accuracy: 0.9959\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0224 - val_accuracy: 0.9925\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0136 - val_accuracy: 0.9958\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0742 - val_accuracy: 0.9760\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0388 - val_accuracy: 0.9883\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0131 - val_accuracy: 0.9959\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9970\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9978\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.3494e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.1535 - val_accuracy: 0.9510\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0163 - val_accuracy: 0.9950\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0110 - val_accuracy: 0.9965\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0215 - val_accuracy: 0.9936\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.0208 - val_accuracy: 0.9931\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0112 - val_accuracy: 0.9959\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9973\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 9.0723e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9978\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.0439e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9979\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.1648e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0370 - accuracy: 0.9892 - val_loss: 0.1045 - val_accuracy: 0.9643\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0148 - val_accuracy: 0.9954\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0629 - val_accuracy: 0.9814\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0343 - accuracy: 0.9898 - val_loss: 0.0175 - val_accuracy: 0.9941\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9976\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 8.4309e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9979\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.2750e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9979\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 6.6446e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9977\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.0110e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9979\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.0377 - val_accuracy: 0.9861\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0151 - val_accuracy: 0.9947\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0202 - val_accuracy: 0.9934\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0154 - val_accuracy: 0.9944\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0305 - val_accuracy: 0.9904\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.0272 - val_accuracy: 0.9904\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0147 - val_accuracy: 0.9948\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0153 - val_accuracy: 0.9948\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.2524e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.7795e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9983\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.2730e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7898e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.1369e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 0.0636 - val_accuracy: 0.9794\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0277 - val_accuracy: 0.9913\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0113 - val_accuracy: 0.9969\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.5338e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.2848e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7428e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.2171e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.0448e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0631 - accuracy: 0.9826 - val_loss: 0.0432 - val_accuracy: 0.9861\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.3235e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.5615e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.7308e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.0965e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 4.5293e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.0104e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0540 - accuracy: 0.9847 - val_loss: 0.0665 - val_accuracy: 0.9790\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0115 - val_accuracy: 0.9966\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 8.9808e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9981\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.1121e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.1495e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.5527e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.0612e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 3.8302e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0498 - accuracy: 0.9861 - val_loss: 0.0986 - val_accuracy: 0.9733\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0200 - val_accuracy: 0.9937\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0097 - val_accuracy: 0.9966\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 9.8334e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 6.3007e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.1450e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 4.5065e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 4.0309e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.6320e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0326 - accuracy: 0.9910 - val_loss: 0.1426 - val_accuracy: 0.9587\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0107 - val_accuracy: 0.9966\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.6112e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9986\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.6819e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7784e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 4.1521e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.7176e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.4048e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0564 - accuracy: 0.9841 - val_loss: 0.0226 - val_accuracy: 0.9922\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0163 - val_accuracy: 0.9946\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0076 - val_accuracy: 0.9976\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.4653e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9977\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.3424e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.0428 - val_accuracy: 0.9858\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0121 - val_accuracy: 0.9963\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0097 - val_accuracy: 0.9969\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.1466e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.8051e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 3.9917e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.5791e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p3jawoUUUcrl",
        "outputId": "c36ce2dd-70e5-4f66-cd2d-71b5d4300c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"integer\", reverse = False)\n",
        "score_gru_plain = ultimate_errors(model, x_tst, y_tst)\n",
        "results_dict[\"GRU_plain\"] = score_gru_plain \n",
        "print(\"Accuracy:\", score_gru_plain[0])\n",
        "print(\"MSE:     \", score_gru_plain[1])\n",
        "print(\"MAE:     \", score_gru_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.986376\n",
            "MSE:      34158.442414\n",
            "MAE:      5.003188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vQoSFT9QUcrp"
      },
      "source": [
        "#### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3iryawnbUcrp",
        "outputId": "421c8c73-789e-4bd7-a2af-43ca033c140e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_dict[\"GRU_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 4s 13ms/step - loss: 2.8384 - accuracy: 0.3741 - val_loss: 1.7362 - val_accuracy: 0.4279\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.4930 - accuracy: 0.4798 - val_loss: 1.2679 - val_accuracy: 0.5310\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.1181 - accuracy: 0.5720 - val_loss: 0.9697 - val_accuracy: 0.6248\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8322 - accuracy: 0.6786 - val_loss: 0.7043 - val_accuracy: 0.7363\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.5983 - accuracy: 0.7794 - val_loss: 0.5268 - val_accuracy: 0.8042\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.4328 - accuracy: 0.8513 - val_loss: 0.3771 - val_accuracy: 0.8766\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3259 - accuracy: 0.8985 - val_loss: 0.3054 - val_accuracy: 0.9046\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2534 - accuracy: 0.9282 - val_loss: 0.2288 - val_accuracy: 0.9378\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1997 - accuracy: 0.9500 - val_loss: 0.1898 - val_accuracy: 0.9506\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1638 - accuracy: 0.9618 - val_loss: 0.1656 - val_accuracy: 0.9579\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.1331 - accuracy: 0.9713 - val_loss: 0.1453 - val_accuracy: 0.9621\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1109 - accuracy: 0.9782 - val_loss: 0.1191 - val_accuracy: 0.9698\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0967 - accuracy: 0.9812 - val_loss: 0.0940 - val_accuracy: 0.9799\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0784 - accuracy: 0.9865 - val_loss: 0.0817 - val_accuracy: 0.9836\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0654 - accuracy: 0.9897 - val_loss: 0.0716 - val_accuracy: 0.9859\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0660 - accuracy: 0.9874 - val_loss: 0.0873 - val_accuracy: 0.9803\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0619 - accuracy: 0.9883 - val_loss: 0.0600 - val_accuracy: 0.9866\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0433 - accuracy: 0.9939 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0361 - accuracy: 0.9957 - val_loss: 0.0440 - val_accuracy: 0.9918\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0344 - accuracy: 0.9950 - val_loss: 0.0689 - val_accuracy: 0.9818\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0453 - accuracy: 0.9906 - val_loss: 0.0368 - val_accuracy: 0.9931\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0251 - accuracy: 0.9970 - val_loss: 0.0460 - val_accuracy: 0.9886\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0245 - accuracy: 0.9968 - val_loss: 0.0432 - val_accuracy: 0.9898\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0263 - accuracy: 0.9957 - val_loss: 0.0410 - val_accuracy: 0.9898\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0381 - accuracy: 0.9918 - val_loss: 0.0849 - val_accuracy: 0.9764\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0229 - accuracy: 0.9960 - val_loss: 0.0205 - val_accuracy: 0.9963\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0129 - accuracy: 0.9990 - val_loss: 0.0200 - val_accuracy: 0.9960\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0309 - accuracy: 0.9924 - val_loss: 0.0170 - val_accuracy: 0.9976\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0102 - accuracy: 0.9994 - val_loss: 0.0142 - val_accuracy: 0.9979\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.0148 - val_accuracy: 0.9972\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 0.0257 - val_accuracy: 0.9930\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0419 - val_accuracy: 0.9872\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0168 - accuracy: 0.9966 - val_loss: 0.0147 - val_accuracy: 0.9974\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0071 - accuracy: 0.9996 - val_loss: 0.0134 - val_accuracy: 0.9972\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 0.9981\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0299 - accuracy: 0.9918 - val_loss: 0.0152 - val_accuracy: 0.9973\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0116 - val_accuracy: 0.9977\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0088 - val_accuracy: 0.9986\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.0092 - val_accuracy: 0.9984\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0515 - accuracy: 0.9854 - val_loss: 0.0541 - val_accuracy: 0.9875\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0114 - val_accuracy: 0.9980\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.0096 - val_accuracy: 0.9984\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0521 - val_accuracy: 0.9829\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 0.0113 - val_accuracy: 0.9978\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0082 - val_accuracy: 0.9986\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9989\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.0161 - val_accuracy: 0.9955\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0140 - val_accuracy: 0.9962\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0629 - val_accuracy: 0.9789\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.0978 - val_accuracy: 0.9686\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0362 - accuracy: 0.9900 - val_loss: 0.0107 - val_accuracy: 0.9975\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0445 - val_accuracy: 0.9880\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.0116 - val_accuracy: 0.9967\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.0277 - val_accuracy: 0.9918\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0301 - accuracy: 0.9921 - val_loss: 0.0113 - val_accuracy: 0.9969\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.7388e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0660 - val_accuracy: 0.9782\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.0263 - val_accuracy: 0.9924\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0109 - val_accuracy: 0.9968\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.5198e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.1346e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.2197e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0201 - val_accuracy: 0.9947\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0142 - val_accuracy: 0.9962\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9987\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.9475e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 8.5901e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.9188e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.0697e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 8.0165e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0140 - val_accuracy: 0.9962\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.6049e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 7.1899e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.4410e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.8732e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0306 - accuracy: 0.9917 - val_loss: 0.0699 - val_accuracy: 0.9804\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0164 - val_accuracy: 0.9955\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.4910e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.5151e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.9362e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.3266e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.8521e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.4949e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.0403 - val_accuracy: 0.9867\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0093 - val_accuracy: 0.9977\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.9516e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.3784e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7401e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 4.3529e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.4843e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.0570 - val_accuracy: 0.9848\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 7.9445e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.2297e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.3917e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7792e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 4.3361e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 3.9800e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 3.5757e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.4105e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9991\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0357 - accuracy: 0.9905 - val_loss: 0.0512 - val_accuracy: 0.9841\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 8.4240e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.1465e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 4.4717e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.9720e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.5768e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 3.2484e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.9617e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.7111e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.0472 - val_accuracy: 0.9868\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.0084 - val_accuracy: 0.9975\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 8.8748e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.0118 - val_accuracy: 0.9970\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 6.9775e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.7702e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.9060e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 3.4029e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.0726e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0256 - val_accuracy: 0.9918\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0135 - val_accuracy: 0.9956\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 8.5520e-04 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 4.4605e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.6454e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.1176e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.8078e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 2.5407e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.0591 - val_accuracy: 0.9837\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 7.6153e-04 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 5.9355e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0177 - val_accuracy: 0.9947\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9988\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 9.7704e-04 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 4.6114e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.3778e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.9576e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.6598e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.3948e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 2.1828e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.0429e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.8451e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.0359 - val_accuracy: 0.9887\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 6.3634e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.4068e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 3.6860e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vSAdw0tiUcru",
        "outputId": "529ad0dd-9525-4e83-962c-d11898339836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"integer\", reverse = True)\n",
        "score_gru_reverse = ultimate_errors(model, x_tst, y_tst)\n",
        "results_dict[\"GRU_rev\"] = score_gru_reverse \n",
        "print(\"Accuracy:\", score_gru_reverse[0])\n",
        "print(\"MSE:     \", score_gru_reverse[1])\n",
        "print(\"MAE:     \", score_gru_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.995493\n",
            "MSE:      5743.797206\n",
            "MAE:      0.956928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3vvFCiBnKsv",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDgvkIYi8G0J",
        "colab_type": "code",
        "outputId": "f49ed380-b101-449c-a631-52358c6c71eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#plot results\n",
        "results_df = pd.DataFrame(results_dict,\n",
        "                          index = [\"ACC\", \"MSE\", \"MAE\"])\n",
        "print(results_df.to_latex(float_format=\"%.3f\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrrr}\n",
            "\\toprule\n",
            "{} &  LSTM\\_plain &  LSTM\\_rev &  SimpleRNN\\_plain &  SimpleRNN\\_rev &  GRU\\_plain &  GRU\\_rev \\\\\n",
            "\\midrule\n",
            "ACC &       0.991 &     0.999 &            0.840 &          0.958 &      0.986 &    0.995 \\\\\n",
            "MSE &   18914.243 &  2600.610 &        82362.182 &      15667.299 &  34158.442 & 5743.797 \\\\\n",
            "MAE &       3.074 &     0.391 &           16.623 &          3.393 &      5.003 &    0.957 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnVIezkENc0D",
        "colab_type": "code",
        "outputId": "21541841-2e00-496b-fbdb-421798801fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "for key, item in histories_dict.items():\n",
        "    plt.plot(pd.DataFrame(item.history[\"val_accuracy\"]))\n",
        "\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.legend(histories_dict.keys())\n",
        "plt.title(\"Validation Accuracy while training \\n on the Integer Representation\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PB00dUCadg1",
        "colab_type": "text"
      },
      "source": [
        "# Task 2: Bit representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgO-oqN8Nf3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set data parameters\n",
        "TRAINING_SIZE = 5e4\n",
        "DIGITS, BITS = 3, 10\n",
        "MAXLEN = BITS + 1 + BITS\n",
        "chars = '01+'\n",
        "ctable = CharacterTable(chars) #generate Character table for this encoding\n",
        "\n",
        "#Set Model Parameters\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "histories_dict, results_dict = {}, {}\n",
        "\n",
        "#dictionaries to save results\n",
        "histories_bits, results_bits = {}, {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO0xo2Vo3EX2",
        "colab_type": "text"
      },
      "source": [
        "### Generate plain and reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvQfpv05qO2B",
        "colab_type": "code",
        "outputId": "e8d7041f-2b44-4bde-e4e5-43f6dd39b2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# generate plain data\n",
        "x_train_plain, x_val_plain, y_train_plain, y_val_plain = generate_bit_data(TRAINING_SIZE, DIGITS, BITS, as_pairs = False, reverse = False)\n",
        "\n",
        "# generate reverse data\n",
        "x_train_rev, x_val_rev, y_train_rev, y_val_rev = generate_bit_data(TRAINING_SIZE, DIGITS, BITS, as_pairs = False, reverse = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n",
            "Generating data...\n",
            "Total addition questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcrwv1jv3ORd",
        "colab_type": "text"
      },
      "source": [
        "### Model: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poWgjxd-3S_b",
        "colab_type": "code",
        "outputId": "c80474db-368a-4f9a-97bc-eb196eda99d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Try replacing GRU, or SimpleRNN.\n",
        "RNN = layers.LSTM\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_LSTM_bit\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_LSTM_bit\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               67584     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 11, 128)           131584    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 11, 3)             387       \n",
            "=================================================================\n",
            "Total params: 199,555\n",
            "Trainable params: 199,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb2iKdt63fl1",
        "colab_type": "text"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGava5iO3h_c",
        "colab_type": "code",
        "outputId": "51a94c8b-3c4b-4206-9822-bb3e6071e680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bits[\"LSTM_plain\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.6795 - accuracy: 0.5308 - val_loss: 0.6718 - val_accuracy: 0.5304\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6704 - accuracy: 0.5322 - val_loss: 0.6599 - val_accuracy: 0.5432\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6471 - accuracy: 0.5576 - val_loss: 0.6210 - val_accuracy: 0.5772\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5811 - accuracy: 0.6039 - val_loss: 0.5479 - val_accuracy: 0.6221\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5380 - accuracy: 0.6348 - val_loss: 0.5212 - val_accuracy: 0.6516\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5138 - accuracy: 0.6553 - val_loss: 0.4871 - val_accuracy: 0.6804\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4951 - accuracy: 0.6707 - val_loss: 0.4674 - val_accuracy: 0.6877\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4749 - accuracy: 0.6838 - val_loss: 0.4413 - val_accuracy: 0.7137\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4604 - accuracy: 0.6949 - val_loss: 0.4874 - val_accuracy: 0.6794\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4495 - accuracy: 0.7031 - val_loss: 0.4614 - val_accuracy: 0.6956\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4407 - accuracy: 0.7106 - val_loss: 0.4958 - val_accuracy: 0.6709\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4281 - accuracy: 0.7197 - val_loss: 0.4884 - val_accuracy: 0.6829\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.4285 - accuracy: 0.7192 - val_loss: 0.4329 - val_accuracy: 0.7141\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4202 - accuracy: 0.7243 - val_loss: 0.3877 - val_accuracy: 0.7466\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4160 - accuracy: 0.7284 - val_loss: 0.3950 - val_accuracy: 0.7417\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4130 - accuracy: 0.7309 - val_loss: 0.3811 - val_accuracy: 0.7505\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4097 - accuracy: 0.7332 - val_loss: 0.4019 - val_accuracy: 0.7338\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3999 - accuracy: 0.7398 - val_loss: 0.3793 - val_accuracy: 0.7545\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4035 - accuracy: 0.7364 - val_loss: 0.4090 - val_accuracy: 0.7298\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3978 - accuracy: 0.7427 - val_loss: 0.3956 - val_accuracy: 0.7434\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3968 - accuracy: 0.7423 - val_loss: 0.4132 - val_accuracy: 0.7239\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3936 - accuracy: 0.7448 - val_loss: 0.3724 - val_accuracy: 0.7604\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3942 - accuracy: 0.7458 - val_loss: 0.3792 - val_accuracy: 0.7537\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3883 - accuracy: 0.7486 - val_loss: 0.3856 - val_accuracy: 0.7567\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3864 - accuracy: 0.7513 - val_loss: 0.3766 - val_accuracy: 0.7589\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3849 - accuracy: 0.7520 - val_loss: 0.3717 - val_accuracy: 0.7586\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3782 - accuracy: 0.7577 - val_loss: 0.3709 - val_accuracy: 0.7583\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3825 - accuracy: 0.7549 - val_loss: 0.3802 - val_accuracy: 0.7535\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3719 - accuracy: 0.7610 - val_loss: 0.3423 - val_accuracy: 0.7819\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3782 - accuracy: 0.7585 - val_loss: 0.3537 - val_accuracy: 0.7724\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3744 - accuracy: 0.7593 - val_loss: 0.3854 - val_accuracy: 0.7492\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3699 - accuracy: 0.7628 - val_loss: 0.5080 - val_accuracy: 0.6943\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3652 - accuracy: 0.7669 - val_loss: 0.3733 - val_accuracy: 0.7591\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3652 - accuracy: 0.7668 - val_loss: 0.3758 - val_accuracy: 0.7585\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3682 - accuracy: 0.7653 - val_loss: 0.3455 - val_accuracy: 0.7842\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3617 - accuracy: 0.7700 - val_loss: 0.3306 - val_accuracy: 0.7897\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3696 - accuracy: 0.7661 - val_loss: 0.3881 - val_accuracy: 0.7519\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3572 - accuracy: 0.7721 - val_loss: 0.3770 - val_accuracy: 0.7609\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3548 - accuracy: 0.7743 - val_loss: 0.3438 - val_accuracy: 0.7827\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3649 - accuracy: 0.7687 - val_loss: 0.3450 - val_accuracy: 0.7808\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3551 - accuracy: 0.7750 - val_loss: 0.3189 - val_accuracy: 0.8059\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3510 - accuracy: 0.7770 - val_loss: 0.3279 - val_accuracy: 0.7951\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3552 - accuracy: 0.7754 - val_loss: 0.3380 - val_accuracy: 0.7864\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3517 - accuracy: 0.7766 - val_loss: 0.3299 - val_accuracy: 0.7901\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3412 - accuracy: 0.7840 - val_loss: 0.3388 - val_accuracy: 0.7846\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3522 - accuracy: 0.7765 - val_loss: 0.3677 - val_accuracy: 0.7661\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3487 - accuracy: 0.7792 - val_loss: 0.3538 - val_accuracy: 0.7795\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3459 - accuracy: 0.7810 - val_loss: 0.3513 - val_accuracy: 0.7750\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3379 - accuracy: 0.7871 - val_loss: 0.3196 - val_accuracy: 0.7980\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3416 - accuracy: 0.7845 - val_loss: 0.3182 - val_accuracy: 0.7992\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3469 - accuracy: 0.7817 - val_loss: 0.3482 - val_accuracy: 0.7807\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3389 - accuracy: 0.7865 - val_loss: 0.3103 - val_accuracy: 0.8089\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3384 - accuracy: 0.7874 - val_loss: 0.3087 - val_accuracy: 0.8089\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3367 - accuracy: 0.7885 - val_loss: 0.3686 - val_accuracy: 0.7654\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3387 - accuracy: 0.7870 - val_loss: 0.3243 - val_accuracy: 0.7966\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3366 - accuracy: 0.7879 - val_loss: 0.4033 - val_accuracy: 0.7556\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3369 - accuracy: 0.7881 - val_loss: 0.3076 - val_accuracy: 0.8079\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3383 - accuracy: 0.7887 - val_loss: 0.3480 - val_accuracy: 0.7809\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3356 - accuracy: 0.7904 - val_loss: 0.3040 - val_accuracy: 0.8125\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3300 - accuracy: 0.7925 - val_loss: 0.3571 - val_accuracy: 0.7721\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3303 - accuracy: 0.7930 - val_loss: 0.3338 - val_accuracy: 0.7833\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3369 - accuracy: 0.7884 - val_loss: 0.3274 - val_accuracy: 0.7954\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3302 - accuracy: 0.7928 - val_loss: 0.3203 - val_accuracy: 0.7951\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3293 - accuracy: 0.7946 - val_loss: 0.3140 - val_accuracy: 0.8006\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3235 - accuracy: 0.7976 - val_loss: 0.3043 - val_accuracy: 0.8102\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3305 - accuracy: 0.7932 - val_loss: 0.3456 - val_accuracy: 0.7863\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3276 - accuracy: 0.7947 - val_loss: 0.2989 - val_accuracy: 0.8191\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3254 - accuracy: 0.7981 - val_loss: 0.3218 - val_accuracy: 0.7981\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3223 - accuracy: 0.7995 - val_loss: 0.2991 - val_accuracy: 0.8169\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3197 - accuracy: 0.8025 - val_loss: 0.3168 - val_accuracy: 0.8057\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3178 - accuracy: 0.8039 - val_loss: 0.2930 - val_accuracy: 0.8221\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3242 - accuracy: 0.7987 - val_loss: 0.3162 - val_accuracy: 0.8086\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3225 - accuracy: 0.8004 - val_loss: 0.3700 - val_accuracy: 0.7667\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3242 - accuracy: 0.7986 - val_loss: 0.3232 - val_accuracy: 0.7949\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3158 - accuracy: 0.8053 - val_loss: 0.2996 - val_accuracy: 0.8208\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3239 - accuracy: 0.8011 - val_loss: 0.3081 - val_accuracy: 0.8181\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3113 - accuracy: 0.8097 - val_loss: 0.3222 - val_accuracy: 0.7996\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.3122 - accuracy: 0.8113 - val_loss: 0.2861 - val_accuracy: 0.8269\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3103 - accuracy: 0.8135 - val_loss: 0.3076 - val_accuracy: 0.8163\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3123 - accuracy: 0.8148 - val_loss: 0.2844 - val_accuracy: 0.8319\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3158 - accuracy: 0.8154 - val_loss: 0.3268 - val_accuracy: 0.8097\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3096 - accuracy: 0.8231 - val_loss: 0.2976 - val_accuracy: 0.8331\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3022 - accuracy: 0.8349 - val_loss: 0.4034 - val_accuracy: 0.7796\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2975 - accuracy: 0.8422 - val_loss: 0.3409 - val_accuracy: 0.8176\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.2909 - accuracy: 0.8440 - val_loss: 0.2547 - val_accuracy: 0.8714\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2669 - accuracy: 0.8552 - val_loss: 0.2398 - val_accuracy: 0.8690\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2667 - accuracy: 0.8498 - val_loss: 0.2421 - val_accuracy: 0.8629\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2490 - accuracy: 0.8590 - val_loss: 0.2968 - val_accuracy: 0.8210\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2515 - accuracy: 0.8568 - val_loss: 0.2111 - val_accuracy: 0.8852\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2406 - accuracy: 0.8651 - val_loss: 0.2177 - val_accuracy: 0.8793\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2401 - accuracy: 0.8659 - val_loss: 0.2252 - val_accuracy: 0.8754\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2366 - accuracy: 0.8693 - val_loss: 0.2166 - val_accuracy: 0.8817\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2310 - accuracy: 0.8750 - val_loss: 0.2651 - val_accuracy: 0.8564\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.2215 - accuracy: 0.8846 - val_loss: 0.1770 - val_accuracy: 0.9162\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2061 - accuracy: 0.8952 - val_loss: 0.1829 - val_accuracy: 0.9066\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1949 - accuracy: 0.9017 - val_loss: 0.1698 - val_accuracy: 0.9186\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1841 - accuracy: 0.9067 - val_loss: 0.2092 - val_accuracy: 0.8921\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1895 - accuracy: 0.9021 - val_loss: 0.1667 - val_accuracy: 0.9150\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1801 - accuracy: 0.9084 - val_loss: 0.1565 - val_accuracy: 0.9211\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1745 - accuracy: 0.9104 - val_loss: 0.1506 - val_accuracy: 0.9253\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1771 - accuracy: 0.9083 - val_loss: 0.1936 - val_accuracy: 0.8985\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1681 - accuracy: 0.9125 - val_loss: 0.2126 - val_accuracy: 0.8839\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1680 - accuracy: 0.9139 - val_loss: 0.1436 - val_accuracy: 0.9302\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1620 - accuracy: 0.9167 - val_loss: 0.1648 - val_accuracy: 0.9106\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1666 - accuracy: 0.9149 - val_loss: 0.1695 - val_accuracy: 0.9102\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1579 - accuracy: 0.9206 - val_loss: 0.1424 - val_accuracy: 0.9293\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1467 - accuracy: 0.9270 - val_loss: 0.1298 - val_accuracy: 0.9361\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1469 - accuracy: 0.9280 - val_loss: 0.1635 - val_accuracy: 0.9147\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1420 - accuracy: 0.9315 - val_loss: 0.1721 - val_accuracy: 0.9125\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1306 - accuracy: 0.9391 - val_loss: 0.1051 - val_accuracy: 0.9537\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1271 - accuracy: 0.9440 - val_loss: 0.1159 - val_accuracy: 0.9490\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1108 - accuracy: 0.9528 - val_loss: 0.1121 - val_accuracy: 0.9517\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1014 - accuracy: 0.9589 - val_loss: 0.1653 - val_accuracy: 0.9296\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0997 - accuracy: 0.9607 - val_loss: 0.0639 - val_accuracy: 0.9784\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0845 - accuracy: 0.9687 - val_loss: 0.1546 - val_accuracy: 0.9345\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0745 - accuracy: 0.9719 - val_loss: 0.0773 - val_accuracy: 0.9689\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0767 - accuracy: 0.9706 - val_loss: 0.0828 - val_accuracy: 0.9657\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0835 - accuracy: 0.9676 - val_loss: 0.0812 - val_accuracy: 0.9662\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0867 - accuracy: 0.9689 - val_loss: 0.0956 - val_accuracy: 0.9595\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0596 - accuracy: 0.9778 - val_loss: 0.0368 - val_accuracy: 0.9869\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0775 - accuracy: 0.9688 - val_loss: 0.0850 - val_accuracy: 0.9614\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0570 - accuracy: 0.9775 - val_loss: 0.0264 - val_accuracy: 0.9909\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0687 - accuracy: 0.9724 - val_loss: 0.0266 - val_accuracy: 0.9906\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0702 - accuracy: 0.9736 - val_loss: 0.0500 - val_accuracy: 0.9809\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9827 - val_loss: 0.0275 - val_accuracy: 0.9901\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0792 - accuracy: 0.9684 - val_loss: 0.0572 - val_accuracy: 0.9792\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0717 - accuracy: 0.9729 - val_loss: 0.0491 - val_accuracy: 0.9835\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0643 - accuracy: 0.9753 - val_loss: 0.0260 - val_accuracy: 0.9909\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0633 - accuracy: 0.9782 - val_loss: 0.0324 - val_accuracy: 0.9874\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0612 - accuracy: 0.9757 - val_loss: 0.0622 - val_accuracy: 0.9733\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0597 - accuracy: 0.9764 - val_loss: 0.0283 - val_accuracy: 0.9896\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0556 - accuracy: 0.9792 - val_loss: 0.0201 - val_accuracy: 0.9931\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0569 - accuracy: 0.9786 - val_loss: 0.1066 - val_accuracy: 0.9528\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0683 - accuracy: 0.9766 - val_loss: 0.0344 - val_accuracy: 0.9890\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0549 - accuracy: 0.9794 - val_loss: 0.0248 - val_accuracy: 0.9903\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0668 - accuracy: 0.9743 - val_loss: 0.0916 - val_accuracy: 0.9609\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0626 - accuracy: 0.9765 - val_loss: 0.0411 - val_accuracy: 0.9849\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0430 - accuracy: 0.9851 - val_loss: 0.0398 - val_accuracy: 0.9834\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0544 - accuracy: 0.9787 - val_loss: 0.0719 - val_accuracy: 0.9673\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 0.0205 - val_accuracy: 0.9934\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0485 - accuracy: 0.9819 - val_loss: 0.0572 - val_accuracy: 0.9774\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0501 - accuracy: 0.9811 - val_loss: 0.0225 - val_accuracy: 0.9920\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0472 - accuracy: 0.9820 - val_loss: 0.2045 - val_accuracy: 0.9152\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0458 - accuracy: 0.9829 - val_loss: 0.0178 - val_accuracy: 0.9937\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0490 - accuracy: 0.9809 - val_loss: 0.0259 - val_accuracy: 0.9912\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0366 - accuracy: 0.9864 - val_loss: 0.0934 - val_accuracy: 0.9651\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0202 - val_accuracy: 0.9930\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0551 - accuracy: 0.9801 - val_loss: 0.0254 - val_accuracy: 0.9929\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0586 - accuracy: 0.9795 - val_loss: 0.0264 - val_accuracy: 0.9934\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0544 - accuracy: 0.9830 - val_loss: 0.1246 - val_accuracy: 0.9414\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0542 - accuracy: 0.9806 - val_loss: 0.0550 - val_accuracy: 0.9815\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.2062 - val_accuracy: 0.9175\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0527 - accuracy: 0.9799 - val_loss: 0.0490 - val_accuracy: 0.9807\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.1386 - val_accuracy: 0.9411\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.0150 - val_accuracy: 0.9956\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0352 - accuracy: 0.9873 - val_loss: 0.0170 - val_accuracy: 0.9938\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0347 - accuracy: 0.9871 - val_loss: 0.0273 - val_accuracy: 0.9898\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.0196 - val_accuracy: 0.9938\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.2394 - val_accuracy: 0.9219\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.0229 - val_accuracy: 0.9917\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.0150 - val_accuracy: 0.9951\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0135 - val_accuracy: 0.9963\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0318 - accuracy: 0.9922 - val_loss: 0.2822 - val_accuracy: 0.9034\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0305 - accuracy: 0.9898 - val_loss: 0.0095 - val_accuracy: 0.9976\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.0278 - val_accuracy: 0.9905\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0112 - val_accuracy: 0.9965\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.0277 - val_accuracy: 0.9902\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0140 - val_accuracy: 0.9961\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0191 - val_accuracy: 0.9934\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0523 - accuracy: 0.9838 - val_loss: 0.0745 - val_accuracy: 0.9725\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.0090 - val_accuracy: 0.9968\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0455 - accuracy: 0.9872 - val_loss: 0.0133 - val_accuracy: 0.9963\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.1008 - val_accuracy: 0.9563\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0163 - val_accuracy: 0.9937\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0760 - accuracy: 0.9758 - val_loss: 0.0317 - val_accuracy: 0.9891\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0324 - accuracy: 0.9898 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.0085 - val_accuracy: 0.9975\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0417 - val_accuracy: 0.9856\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0475 - accuracy: 0.9849 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0055 - val_accuracy: 0.9988\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9994\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0319 - val_accuracy: 0.9873\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0050 - val_accuracy: 0.9989\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0307 - val_accuracy: 0.9889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QRwV8hXN4ahN",
        "outputId": "9355e603-05df-4c90-deee-a46279ca5e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"bit\", reverse = False)\n",
        "score_lstm_bit_plain = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bits[\"LSTM_plain\"] = score_lstm_bit_plain\n",
        "print(\"Accuracy:\", score_lstm_bit_plain[0])\n",
        "print(\"MSE:     \", score_lstm_bit_plain[1])\n",
        "print(\"MAE:     \", score_lstm_bit_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.8013738749714533\n",
            "MSE:      777.5589897652144\n",
            "MAE:      5.1541199527198955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfxDahIJ3ubn",
        "colab_type": "text"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq4Deuyujb8Y",
        "colab_type": "code",
        "outputId": "b1c96095-45d2-408d-b1c5-42e5d360e2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Try replacing GRU, or SimpleRNN.\n",
        "RNN = layers.LSTM\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_LSTM_bit\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_LSTM_bit\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               67584     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 11, 128)           131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 11, 3)             387       \n",
            "=================================================================\n",
            "Total params: 199,555\n",
            "Trainable params: 199,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG7NUAky3wnc",
        "colab_type": "code",
        "outputId": "073103e2-620b-45e3-f71f-939f7872246a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bits[\"LSTM_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6625 - accuracy: 0.5496 - val_loss: 0.6265 - val_accuracy: 0.5736\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6069 - accuracy: 0.5881 - val_loss: 0.5966 - val_accuracy: 0.5939\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5617 - accuracy: 0.6197 - val_loss: 0.5378 - val_accuracy: 0.6316\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5281 - accuracy: 0.6451 - val_loss: 0.5418 - val_accuracy: 0.6403\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5010 - accuracy: 0.6689 - val_loss: 0.4996 - val_accuracy: 0.6668\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4848 - accuracy: 0.6791 - val_loss: 0.4849 - val_accuracy: 0.6753\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4731 - accuracy: 0.6871 - val_loss: 0.4549 - val_accuracy: 0.6985\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4549 - accuracy: 0.7002 - val_loss: 0.4413 - val_accuracy: 0.7076\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4488 - accuracy: 0.7049 - val_loss: 0.4214 - val_accuracy: 0.7239\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4339 - accuracy: 0.7149 - val_loss: 0.4113 - val_accuracy: 0.7305\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4240 - accuracy: 0.7219 - val_loss: 0.4126 - val_accuracy: 0.7282\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4195 - accuracy: 0.7260 - val_loss: 0.4060 - val_accuracy: 0.7334\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4124 - accuracy: 0.7310 - val_loss: 0.3902 - val_accuracy: 0.7461\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4061 - accuracy: 0.7352 - val_loss: 0.4095 - val_accuracy: 0.7312\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3983 - accuracy: 0.7416 - val_loss: 0.4003 - val_accuracy: 0.7375\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3898 - accuracy: 0.7475 - val_loss: 0.3850 - val_accuracy: 0.7491\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3826 - accuracy: 0.7522 - val_loss: 0.3762 - val_accuracy: 0.7570\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3869 - accuracy: 0.7509 - val_loss: 0.3849 - val_accuracy: 0.7527\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3743 - accuracy: 0.7608 - val_loss: 0.3819 - val_accuracy: 0.7551\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3703 - accuracy: 0.7630 - val_loss: 0.3548 - val_accuracy: 0.7726\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3665 - accuracy: 0.7670 - val_loss: 0.3545 - val_accuracy: 0.7733\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3654 - accuracy: 0.7672 - val_loss: 0.4055 - val_accuracy: 0.7447\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3638 - accuracy: 0.7701 - val_loss: 0.3602 - val_accuracy: 0.7727\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3536 - accuracy: 0.7763 - val_loss: 0.3692 - val_accuracy: 0.7673\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3540 - accuracy: 0.7767 - val_loss: 0.3519 - val_accuracy: 0.7777\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3485 - accuracy: 0.7801 - val_loss: 0.3722 - val_accuracy: 0.7659\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3447 - accuracy: 0.7827 - val_loss: 0.3304 - val_accuracy: 0.7913\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3457 - accuracy: 0.7831 - val_loss: 0.3274 - val_accuracy: 0.7941\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3388 - accuracy: 0.7872 - val_loss: 0.3253 - val_accuracy: 0.7968\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3326 - accuracy: 0.7923 - val_loss: 0.3190 - val_accuracy: 0.8037\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3329 - accuracy: 0.7926 - val_loss: 0.3196 - val_accuracy: 0.8007\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3289 - accuracy: 0.7961 - val_loss: 0.3446 - val_accuracy: 0.7831\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3248 - accuracy: 0.7987 - val_loss: 0.3434 - val_accuracy: 0.7860\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3329 - accuracy: 0.7942 - val_loss: 0.3150 - val_accuracy: 0.8045\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3189 - accuracy: 0.8043 - val_loss: 0.3728 - val_accuracy: 0.7668\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3187 - accuracy: 0.8052 - val_loss: 0.3733 - val_accuracy: 0.7701\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3213 - accuracy: 0.8034 - val_loss: 0.3157 - val_accuracy: 0.8063\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.3141 - accuracy: 0.8085 - val_loss: 0.3004 - val_accuracy: 0.8165\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3153 - accuracy: 0.8091 - val_loss: 0.3129 - val_accuracy: 0.8091\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3040 - accuracy: 0.8166 - val_loss: 0.3139 - val_accuracy: 0.8091\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3095 - accuracy: 0.8145 - val_loss: 0.2931 - val_accuracy: 0.8220\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3025 - accuracy: 0.8196 - val_loss: 0.2797 - val_accuracy: 0.8368\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2973 - accuracy: 0.8241 - val_loss: 0.3018 - val_accuracy: 0.8234\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2928 - accuracy: 0.8296 - val_loss: 0.3231 - val_accuracy: 0.8130\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2923 - accuracy: 0.8333 - val_loss: 0.2815 - val_accuracy: 0.8399\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2774 - accuracy: 0.8461 - val_loss: 0.3124 - val_accuracy: 0.8311\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.2767 - accuracy: 0.8497 - val_loss: 0.2566 - val_accuracy: 0.8624\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2677 - accuracy: 0.8578 - val_loss: 0.2558 - val_accuracy: 0.8641\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2492 - accuracy: 0.8686 - val_loss: 0.3587 - val_accuracy: 0.8086\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2330 - accuracy: 0.8777 - val_loss: 0.2342 - val_accuracy: 0.8739\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2180 - accuracy: 0.8865 - val_loss: 0.2169 - val_accuracy: 0.8905\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2037 - accuracy: 0.8962 - val_loss: 0.1912 - val_accuracy: 0.9019\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1874 - accuracy: 0.9068 - val_loss: 0.1889 - val_accuracy: 0.9078\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1783 - accuracy: 0.9133 - val_loss: 0.1831 - val_accuracy: 0.9100\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1785 - accuracy: 0.9148 - val_loss: 0.1461 - val_accuracy: 0.9337\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1514 - accuracy: 0.9298 - val_loss: 0.1383 - val_accuracy: 0.9371\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1386 - accuracy: 0.9370 - val_loss: 0.1088 - val_accuracy: 0.9540\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1248 - accuracy: 0.9433 - val_loss: 0.1250 - val_accuracy: 0.9429\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1132 - accuracy: 0.9498 - val_loss: 0.1034 - val_accuracy: 0.9531\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1021 - accuracy: 0.9553 - val_loss: 0.0961 - val_accuracy: 0.9577\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0943 - accuracy: 0.9588 - val_loss: 0.0753 - val_accuracy: 0.9693\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0922 - accuracy: 0.9610 - val_loss: 0.0835 - val_accuracy: 0.9629\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0830 - accuracy: 0.9651 - val_loss: 0.0915 - val_accuracy: 0.9593\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0752 - accuracy: 0.9681 - val_loss: 0.0613 - val_accuracy: 0.9744\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0587 - accuracy: 0.9758 - val_loss: 0.0611 - val_accuracy: 0.9754\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0757 - accuracy: 0.9693 - val_loss: 0.0685 - val_accuracy: 0.9710\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0513 - accuracy: 0.9791 - val_loss: 0.0449 - val_accuracy: 0.9819\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0582 - accuracy: 0.9771 - val_loss: 0.0414 - val_accuracy: 0.9850\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0421 - accuracy: 0.9840 - val_loss: 0.0575 - val_accuracy: 0.9760\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0375 - accuracy: 0.9855 - val_loss: 0.0337 - val_accuracy: 0.9875\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0355 - accuracy: 0.9864 - val_loss: 0.0237 - val_accuracy: 0.9912\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0485 - accuracy: 0.9819 - val_loss: 0.0509 - val_accuracy: 0.9808\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0163 - val_accuracy: 0.9940\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9892 - val_loss: 0.0345 - val_accuracy: 0.9871\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.0171 - val_accuracy: 0.9942\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0252 - accuracy: 0.9907 - val_loss: 0.0130 - val_accuracy: 0.9960\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 0.0292 - val_accuracy: 0.9888\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.0325 - val_accuracy: 0.9877\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.0477 - val_accuracy: 0.9812\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0353 - val_accuracy: 0.9858\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.0206 - val_accuracy: 0.9923\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.0242 - val_accuracy: 0.9910\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0775 - val_accuracy: 0.9754\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0233 - val_accuracy: 0.9919\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0096 - val_accuracy: 0.9968\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0061 - val_accuracy: 0.9977\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9965\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0242 - val_accuracy: 0.9917\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0161 - val_accuracy: 0.9943\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0053 - val_accuracy: 0.9982\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0214 - val_accuracy: 0.9919\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 8.6184e-04 - val_accuracy: 0.9999\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.6692e-04 - accuracy: 0.9999 - val_loss: 8.1097e-04 - val_accuracy: 0.9998\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0107 - val_accuracy: 0.9965\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 8.6760e-04 - val_accuracy: 0.9998\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0593 - val_accuracy: 0.9805\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0399 - val_accuracy: 0.9845\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 9.6827e-04 - val_accuracy: 0.9997\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 4.3802e-04 - accuracy: 1.0000 - val_loss: 7.4835e-04 - val_accuracy: 0.9999\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.9384e-04 - accuracy: 1.0000 - val_loss: 2.3542e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2928e-04 - accuracy: 1.0000 - val_loss: 1.8929e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0114e-04 - accuracy: 1.0000 - val_loss: 1.7301e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.6088e-05 - accuracy: 1.0000 - val_loss: 1.4367e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 7.4358e-05 - accuracy: 1.0000 - val_loss: 1.1172e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 6.2416e-05 - accuracy: 1.0000 - val_loss: 1.1470e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.3442e-05 - accuracy: 1.0000 - val_loss: 9.1997e-05 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0466 - accuracy: 0.9866 - val_loss: 0.0967 - val_accuracy: 0.9583\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 9.8916e-04 - accuracy: 0.9999 - val_loss: 9.5587e-04 - val_accuracy: 0.9998\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 3.5655e-04 - accuracy: 1.0000 - val_loss: 3.9541e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.2341e-04 - accuracy: 1.0000 - val_loss: 3.9647e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.6666e-04 - accuracy: 1.0000 - val_loss: 2.4029e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2698e-04 - accuracy: 1.0000 - val_loss: 2.0049e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0268e-04 - accuracy: 1.0000 - val_loss: 1.5837e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.3740e-05 - accuracy: 1.0000 - val_loss: 1.3250e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 6.9457e-05 - accuracy: 1.0000 - val_loss: 1.0228e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 5.7312e-05 - accuracy: 1.0000 - val_loss: 9.0657e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0877 - val_accuracy: 0.9718\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 6.9034e-04 - val_accuracy: 0.9998\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0121 - val_accuracy: 0.9960\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 8.8794e-04 - val_accuracy: 0.9999\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 3.2918e-04 - accuracy: 1.0000 - val_loss: 2.5958e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3046e-04 - accuracy: 1.0000 - val_loss: 1.4478e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 7.6871e-05 - accuracy: 1.0000 - val_loss: 1.2576e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.5598e-05 - accuracy: 1.0000 - val_loss: 9.3332e-05 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 4.3871e-05 - accuracy: 1.0000 - val_loss: 7.7672e-05 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 3.5317e-05 - accuracy: 1.0000 - val_loss: 6.4104e-05 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.9077e-05 - accuracy: 1.0000 - val_loss: 5.3093e-05 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.4249e-05 - accuracy: 1.0000 - val_loss: 4.5319e-05 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.0351e-05 - accuracy: 1.0000 - val_loss: 4.3755e-05 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.9816e-05 - accuracy: 1.0000 - val_loss: 3.3137e-05 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4787e-05 - accuracy: 1.0000 - val_loss: 3.2296e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2271e-05 - accuracy: 1.0000 - val_loss: 2.7280e-05 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.9283 - val_accuracy: 0.8626\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 7.5389e-04 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 3.7834e-04 - accuracy: 1.0000 - val_loss: 3.1256e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.5157e-04 - accuracy: 1.0000 - val_loss: 2.0770e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 9.6557e-05 - accuracy: 1.0000 - val_loss: 1.6132e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 6.9872e-05 - accuracy: 1.0000 - val_loss: 1.2919e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.2955e-05 - accuracy: 1.0000 - val_loss: 1.1852e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.1650e-05 - accuracy: 1.0000 - val_loss: 9.1725e-05 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 3.4080e-05 - accuracy: 1.0000 - val_loss: 8.0556e-05 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.7738e-05 - accuracy: 1.0000 - val_loss: 8.3565e-05 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3504e-05 - accuracy: 1.0000 - val_loss: 6.7611e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.9727e-05 - accuracy: 1.0000 - val_loss: 5.8060e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.6520e-05 - accuracy: 1.0000 - val_loss: 4.2736e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4126e-05 - accuracy: 1.0000 - val_loss: 4.0078e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2221e-05 - accuracy: 1.0000 - val_loss: 3.4950e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0366e-05 - accuracy: 1.0000 - val_loss: 3.6217e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.4996e-04 - accuracy: 0.9998 - val_loss: 3.5800e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.6625e-04 - accuracy: 1.0000 - val_loss: 1.9746e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 9.5162e-05 - accuracy: 1.0000 - val_loss: 1.4247e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 7.0434e-05 - accuracy: 1.0000 - val_loss: 1.2441e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.4613e-05 - accuracy: 1.0000 - val_loss: 9.2607e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.3278e-05 - accuracy: 1.0000 - val_loss: 7.9025e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 3.5302e-05 - accuracy: 1.0000 - val_loss: 6.7983e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.8779e-05 - accuracy: 1.0000 - val_loss: 6.0721e-05 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3689e-05 - accuracy: 1.0000 - val_loss: 4.6451e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.9742e-05 - accuracy: 1.0000 - val_loss: 3.8494e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.6417e-05 - accuracy: 1.0000 - val_loss: 3.4152e-05 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3885e-05 - accuracy: 1.0000 - val_loss: 2.8954e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 1.1744e-05 - accuracy: 1.0000 - val_loss: 2.4814e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 9.9970e-06 - accuracy: 1.0000 - val_loss: 2.4364e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.4066e-06 - accuracy: 1.0000 - val_loss: 2.1834e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 7.1367e-06 - accuracy: 1.0000 - val_loss: 1.7005e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 6.0704e-06 - accuracy: 1.0000 - val_loss: 1.4871e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.1336e-06 - accuracy: 1.0000 - val_loss: 1.0711e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.3622e-06 - accuracy: 1.0000 - val_loss: 9.6645e-06 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0224 - accuracy: 0.9943 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.9166e-04 - accuracy: 0.9999 - val_loss: 4.2094e-04 - val_accuracy: 0.9999\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.4985e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 7.0186e-04 - val_accuracy: 0.9998\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.4527e-04 - accuracy: 1.0000 - val_loss: 1.8827e-04 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 7.3384e-05 - accuracy: 1.0000 - val_loss: 1.0881e-04 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.7231e-05 - accuracy: 1.0000 - val_loss: 7.8568e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 3.5139e-05 - accuracy: 1.0000 - val_loss: 6.1314e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.7010e-05 - accuracy: 1.0000 - val_loss: 5.8298e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.1586e-05 - accuracy: 1.0000 - val_loss: 4.8454e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.7483e-05 - accuracy: 1.0000 - val_loss: 3.8042e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4326e-05 - accuracy: 1.0000 - val_loss: 3.7480e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1650e-05 - accuracy: 1.0000 - val_loss: 2.8457e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 9.9497e-06 - accuracy: 1.0000 - val_loss: 2.2685e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.0357e-06 - accuracy: 1.0000 - val_loss: 2.0914e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 6.6614e-06 - accuracy: 1.0000 - val_loss: 1.8174e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.6031e-06 - accuracy: 1.0000 - val_loss: 1.5840e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.8074e-06 - accuracy: 1.0000 - val_loss: 1.4113e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.0913e-06 - accuracy: 1.0000 - val_loss: 1.0562e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vPDsImXbstu",
        "colab_type": "code",
        "outputId": "2c892554-7580-4a95-d667-9cc66620d766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"bit\", reverse = True)\n",
        "score_lstm_bit_rev = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bits[\"LSTM_rev\"] = score_lstm_bit_rev\n",
        "print(\"Accuracy:\", score_lstm_bit_rev[0])\n",
        "print(\"MSE:     \", score_lstm_bit_rev[1])\n",
        "print(\"MAE:     \", score_lstm_bit_rev[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9993473663892735\n",
            "MSE:      0.6925512814265061\n",
            "MAE:      0.01821927533780717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bLPqo6IaSp-w"
      },
      "source": [
        "### Model: SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x-jkeDL4Sp-y",
        "outputId": "db8a7770-aa43-4c25-d42e-f50bdd80b884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Try replacing GRU, or SimpleRNN.\n",
        "RNN = layers.SimpleRNN\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_SimpleRNN_bit\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_SimpleRNN_bit\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               16896     \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 11, 128)           32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 11, 3)             387       \n",
            "=================================================================\n",
            "Total params: 50,179\n",
            "Trainable params: 50,179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ju-LsULaSp-2"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cBEeZjAKSp-2",
        "outputId": "e5e2da33-dccf-4644-8100-f368239da5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs= 200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bits[\"SimpleRNN_plain\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 8s 24ms/step - loss: 0.5633 - accuracy: 0.6477 - val_loss: 0.4416 - val_accuracy: 0.7557\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.3469 - accuracy: 0.8213 - val_loss: 0.2357 - val_accuracy: 0.8975\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0960 - accuracy: 0.9642 - val_loss: 0.0230 - val_accuracy: 0.9939\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0124 - val_accuracy: 0.9968\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0060 - val_accuracy: 0.9986\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0086 - val_accuracy: 0.9975\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 0.9978\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 9.2571e-04 - val_accuracy: 0.9998\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 9.9894e-04 - val_accuracy: 0.9998\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 8.3554e-04 - val_accuracy: 0.9999\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0395 - accuracy: 0.9889 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 7.6206e-04 - val_accuracy: 0.9999\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 6.1738e-04 - val_accuracy: 0.9999\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 4.4110e-04 - accuracy: 0.9999 - val_loss: 4.3641e-04 - val_accuracy: 0.9999\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 5.0543e-04 - val_accuracy: 0.9999\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 4.2219e-04 - val_accuracy: 0.9999\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.4932e-04 - accuracy: 0.9999 - val_loss: 6.8650e-04 - val_accuracy: 0.9999\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 7.8459e-04 - val_accuracy: 0.9999\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 7.6456e-04 - accuracy: 0.9999 - val_loss: 3.2544e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.6699e-04 - accuracy: 1.0000 - val_loss: 3.2421e-04 - val_accuracy: 0.9999\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 5.8667e-04 - accuracy: 0.9999 - val_loss: 2.9134e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 6.6969e-04 - val_accuracy: 0.9998\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.4422e-04 - accuracy: 1.0000 - val_loss: 6.1540e-04 - val_accuracy: 0.9998\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0204 - accuracy: 0.9945 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.5136e-04 - accuracy: 1.0000 - val_loss: 8.3974e-04 - val_accuracy: 0.9998\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.0845e-04 - accuracy: 1.0000 - val_loss: 3.3648e-04 - val_accuracy: 0.9999\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 2.0450e-04 - accuracy: 1.0000 - val_loss: 1.6648e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.0101e-04 - accuracy: 1.0000 - val_loss: 1.3797e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 5.8524e-04 - val_accuracy: 0.9999\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.8412e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 2.1535e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.7502e-04 - accuracy: 1.0000 - val_loss: 5.7799e-04 - val_accuracy: 0.9999\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.3332e-04 - accuracy: 1.0000 - val_loss: 4.3880e-04 - val_accuracy: 0.9999\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0222 - val_accuracy: 0.9926\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 2.4462e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1985e-04 - accuracy: 1.0000 - val_loss: 1.0789e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.7258e-04 - accuracy: 0.9999 - val_loss: 3.2699e-04 - val_accuracy: 0.9999\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.9929e-04 - accuracy: 1.0000 - val_loss: 1.2746e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 8.3084e-05 - accuracy: 1.0000 - val_loss: 1.0600e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 5.2828e-05 - accuracy: 1.0000 - val_loss: 9.8138e-05 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 3.8676e-05 - accuracy: 1.0000 - val_loss: 5.2446e-05 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.7600e-05 - accuracy: 1.0000 - val_loss: 5.1592e-05 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 2.1651e-05 - accuracy: 1.0000 - val_loss: 4.3978e-05 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.7774e-05 - accuracy: 1.0000 - val_loss: 4.9670e-05 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.3892e-05 - accuracy: 1.0000 - val_loss: 3.8409e-05 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1121e-05 - accuracy: 1.0000 - val_loss: 2.9626e-05 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.0352e-05 - accuracy: 1.0000 - val_loss: 3.8745e-05 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.6119e-04 - accuracy: 0.9999 - val_loss: 5.3349e-04 - val_accuracy: 0.9999\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.0437e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 2.4339e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1722e-04 - accuracy: 1.0000 - val_loss: 1.6674e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.8224e-05 - accuracy: 1.0000 - val_loss: 1.2713e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0159 - val_accuracy: 0.9952\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 1.8166e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 8.3428e-05 - accuracy: 1.0000 - val_loss: 6.3250e-05 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.9134e-05 - accuracy: 1.0000 - val_loss: 4.3630e-05 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.6387e-05 - accuracy: 1.0000 - val_loss: 3.2704e-05 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.9501e-05 - accuracy: 1.0000 - val_loss: 2.7773e-05 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.5374e-05 - accuracy: 1.0000 - val_loss: 2.5252e-05 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2644e-05 - accuracy: 1.0000 - val_loss: 2.5427e-05 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 9.9174e-06 - accuracy: 1.0000 - val_loss: 1.5297e-05 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 8.1318e-06 - accuracy: 1.0000 - val_loss: 1.7172e-05 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 6.5304e-06 - accuracy: 1.0000 - val_loss: 1.1394e-05 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 5.6291e-06 - accuracy: 1.0000 - val_loss: 1.1113e-05 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 4.4186e-06 - accuracy: 1.0000 - val_loss: 1.1988e-05 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.8219e-06 - accuracy: 1.0000 - val_loss: 1.2085e-04 - val_accuracy: 0.9999\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 5.7116e-04 - val_accuracy: 0.9999\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.4437e-04 - accuracy: 1.0000 - val_loss: 2.2489e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.3524e-04 - accuracy: 1.0000 - val_loss: 1.4531e-04 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 7.6404e-05 - accuracy: 1.0000 - val_loss: 1.1898e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.3514e-05 - accuracy: 1.0000 - val_loss: 8.9299e-05 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.9537e-05 - accuracy: 1.0000 - val_loss: 1.0598e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.1058e-05 - accuracy: 1.0000 - val_loss: 8.9372e-05 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.4187e-05 - accuracy: 1.0000 - val_loss: 9.3907e-05 - val_accuracy: 0.9999\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 5.9320e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.9118e-04 - accuracy: 1.0000 - val_loss: 3.3125e-04 - val_accuracy: 0.9999\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 9.9185e-05 - accuracy: 1.0000 - val_loss: 1.0136e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.5318e-05 - accuracy: 1.0000 - val_loss: 7.7085e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.7340e-05 - accuracy: 1.0000 - val_loss: 6.4840e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.7747e-05 - accuracy: 1.0000 - val_loss: 5.7530e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.1202e-05 - accuracy: 1.0000 - val_loss: 5.0020e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.6483e-05 - accuracy: 1.0000 - val_loss: 5.6027e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.3339e-05 - accuracy: 1.0000 - val_loss: 1.0489e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 3.4338e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 6.5982e-04 - val_accuracy: 0.9999\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.1781e-04 - accuracy: 1.0000 - val_loss: 1.2774e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 7.0875e-05 - accuracy: 1.0000 - val_loss: 7.3749e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.2076e-05 - accuracy: 1.0000 - val_loss: 5.6882e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.8816e-05 - accuracy: 1.0000 - val_loss: 4.2066e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.2149e-05 - accuracy: 1.0000 - val_loss: 3.3019e-05 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.6435e-05 - accuracy: 1.0000 - val_loss: 2.8686e-05 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.2829e-05 - accuracy: 1.0000 - val_loss: 2.2494e-05 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.0221e-05 - accuracy: 1.0000 - val_loss: 2.0623e-05 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 8.2033e-06 - accuracy: 1.0000 - val_loss: 1.6830e-05 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 6.6852e-06 - accuracy: 1.0000 - val_loss: 1.6499e-05 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.4020e-06 - accuracy: 1.0000 - val_loss: 1.4133e-05 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.3937e-06 - accuracy: 1.0000 - val_loss: 1.2220e-05 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.1750e-04 - accuracy: 0.9999 - val_loss: 2.8468e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.3294e-04 - accuracy: 1.0000 - val_loss: 1.5403e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 7.7187e-05 - accuracy: 1.0000 - val_loss: 1.4142e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.2394e-05 - accuracy: 1.0000 - val_loss: 1.5165e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.8684e-05 - accuracy: 1.0000 - val_loss: 1.6049e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.9607e-05 - accuracy: 1.0000 - val_loss: 1.6321e-04 - val_accuracy: 0.9999\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.2977e-05 - accuracy: 1.0000 - val_loss: 1.7431e-04 - val_accuracy: 0.9999\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.8243e-05 - accuracy: 1.0000 - val_loss: 1.7661e-04 - val_accuracy: 0.9999\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.4642e-05 - accuracy: 1.0000 - val_loss: 1.8017e-04 - val_accuracy: 0.9999\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1828e-05 - accuracy: 1.0000 - val_loss: 1.8636e-04 - val_accuracy: 0.9999\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 9.6562e-06 - accuracy: 1.0000 - val_loss: 1.9108e-04 - val_accuracy: 0.9999\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 7.9102e-06 - accuracy: 1.0000 - val_loss: 2.0298e-04 - val_accuracy: 0.9999\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 6.5420e-06 - accuracy: 1.0000 - val_loss: 2.0412e-04 - val_accuracy: 0.9999\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 5.3680e-06 - accuracy: 1.0000 - val_loss: 2.0881e-04 - val_accuracy: 0.9999\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 4.3849e-06 - accuracy: 1.0000 - val_loss: 2.1065e-04 - val_accuracy: 0.9999\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 3.6190e-06 - accuracy: 1.0000 - val_loss: 2.1642e-04 - val_accuracy: 0.9999\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.0114e-06 - accuracy: 1.0000 - val_loss: 2.1832e-04 - val_accuracy: 0.9999\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.5143e-06 - accuracy: 1.0000 - val_loss: 2.1715e-04 - val_accuracy: 0.9999\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.0815e-06 - accuracy: 1.0000 - val_loss: 2.3198e-04 - val_accuracy: 0.9999\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.7419e-06 - accuracy: 1.0000 - val_loss: 2.3820e-04 - val_accuracy: 0.9999\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.4638e-06 - accuracy: 1.0000 - val_loss: 2.4146e-04 - val_accuracy: 0.9999\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0284 - accuracy: 0.9927 - val_loss: 0.0172 - val_accuracy: 0.9952\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 4.3999e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.3321e-04 - accuracy: 1.0000 - val_loss: 2.0709e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1324e-04 - accuracy: 1.0000 - val_loss: 1.3831e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 7.1894e-05 - accuracy: 1.0000 - val_loss: 9.8837e-05 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 5.0462e-05 - accuracy: 1.0000 - val_loss: 7.5595e-05 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 3.7255e-05 - accuracy: 1.0000 - val_loss: 6.0534e-05 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.8602e-05 - accuracy: 1.0000 - val_loss: 4.9271e-05 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.2773e-05 - accuracy: 1.0000 - val_loss: 4.3343e-05 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.8350e-05 - accuracy: 1.0000 - val_loss: 4.0475e-05 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.4806e-05 - accuracy: 1.0000 - val_loss: 3.6440e-05 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.2205e-05 - accuracy: 1.0000 - val_loss: 3.3145e-05 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.0017e-05 - accuracy: 1.0000 - val_loss: 2.9677e-05 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 8.3272e-06 - accuracy: 1.0000 - val_loss: 2.7837e-05 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 6.8995e-06 - accuracy: 1.0000 - val_loss: 2.5813e-05 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 10s 27ms/step - loss: 5.7785e-06 - accuracy: 1.0000 - val_loss: 2.2574e-05 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 4.8401e-06 - accuracy: 1.0000 - val_loss: 2.0187e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.0202e-06 - accuracy: 1.0000 - val_loss: 1.7802e-05 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 3.3454e-06 - accuracy: 1.0000 - val_loss: 1.6068e-05 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.8289e-06 - accuracy: 1.0000 - val_loss: 1.5445e-05 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.3794e-06 - accuracy: 1.0000 - val_loss: 1.3157e-05 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.9873e-06 - accuracy: 1.0000 - val_loss: 1.2768e-05 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.6815e-06 - accuracy: 1.0000 - val_loss: 1.2763e-05 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.3971e-06 - accuracy: 1.0000 - val_loss: 1.1744e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1873e-06 - accuracy: 1.0000 - val_loss: 1.0686e-05 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.0086e-06 - accuracy: 1.0000 - val_loss: 1.0654e-05 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 8.4682e-07 - accuracy: 1.0000 - val_loss: 1.0523e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 8s 23ms/step - loss: 7.4018e-07 - accuracy: 1.0000 - val_loss: 9.7861e-06 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 6.1536e-07 - accuracy: 1.0000 - val_loss: 1.1573e-05 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.2502e-07 - accuracy: 1.0000 - val_loss: 1.0131e-05 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 4.6624e-07 - accuracy: 1.0000 - val_loss: 1.2215e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.0611e-07 - accuracy: 1.0000 - val_loss: 1.0500e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.5640e-07 - accuracy: 1.0000 - val_loss: 1.0550e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.0974e-07 - accuracy: 1.0000 - val_loss: 1.0583e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.7562e-07 - accuracy: 1.0000 - val_loss: 1.1261e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.4959e-07 - accuracy: 1.0000 - val_loss: 1.0100e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.2639e-07 - accuracy: 1.0000 - val_loss: 1.0099e-05 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 2.0932e-07 - accuracy: 1.0000 - val_loss: 1.1911e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.9115e-07 - accuracy: 1.0000 - val_loss: 8.3995e-06 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.7842e-07 - accuracy: 1.0000 - val_loss: 8.6350e-06 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.6826e-07 - accuracy: 1.0000 - val_loss: 9.5684e-06 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.5980e-07 - accuracy: 1.0000 - val_loss: 9.7926e-06 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.5356e-07 - accuracy: 1.0000 - val_loss: 9.5912e-06 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.5083e-07 - accuracy: 1.0000 - val_loss: 7.9800e-06 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.4161e-07 - accuracy: 1.0000 - val_loss: 9.3327e-06 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.3786e-07 - accuracy: 1.0000 - val_loss: 8.4903e-06 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.3478e-07 - accuracy: 1.0000 - val_loss: 7.2354e-06 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.3193e-07 - accuracy: 1.0000 - val_loss: 8.8397e-06 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.3021e-07 - accuracy: 1.0000 - val_loss: 6.9533e-06 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 6.2983e-04 - accuracy: 0.9999 - val_loss: 3.1444e-04 - val_accuracy: 0.9999\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.6903e-04 - accuracy: 1.0000 - val_loss: 1.8610e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 7.4827e-05 - accuracy: 1.0000 - val_loss: 1.2822e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.7792e-05 - accuracy: 1.0000 - val_loss: 8.9232e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.4199e-05 - accuracy: 1.0000 - val_loss: 7.2922e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.5590e-05 - accuracy: 1.0000 - val_loss: 5.7583e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.9673e-05 - accuracy: 1.0000 - val_loss: 4.9686e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.5379e-05 - accuracy: 1.0000 - val_loss: 4.0094e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.2144e-05 - accuracy: 1.0000 - val_loss: 3.3362e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 9.6863e-06 - accuracy: 1.0000 - val_loss: 2.6791e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 7.7609e-06 - accuracy: 1.0000 - val_loss: 2.2232e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 6.1896e-06 - accuracy: 1.0000 - val_loss: 1.8835e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.0266e-06 - accuracy: 1.0000 - val_loss: 1.6153e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.0486e-06 - accuracy: 1.0000 - val_loss: 1.3528e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.3057e-06 - accuracy: 1.0000 - val_loss: 1.1830e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.6880e-06 - accuracy: 1.0000 - val_loss: 1.0066e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.2001e-06 - accuracy: 1.0000 - val_loss: 9.6058e-06 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.7964e-06 - accuracy: 1.0000 - val_loss: 9.1092e-06 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.4909e-06 - accuracy: 1.0000 - val_loss: 8.4835e-06 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2364e-06 - accuracy: 1.0000 - val_loss: 1.0170e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.0344e-06 - accuracy: 1.0000 - val_loss: 9.9255e-06 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 8.7255e-07 - accuracy: 1.0000 - val_loss: 1.3938e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 7.3827e-07 - accuracy: 1.0000 - val_loss: 1.7399e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 6.3205e-07 - accuracy: 1.0000 - val_loss: 2.6889e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.4305e-07 - accuracy: 1.0000 - val_loss: 2.2013e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.6909e-07 - accuracy: 1.0000 - val_loss: 2.8949e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ur6hHyRSp-6",
        "outputId": "d34012e0-15a1-43b9-f344-f8a7d3334544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"bit\", reverse = False)\n",
        "score_simplernn_bit_plain = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bits[\"SimpleRNN_plain\"] = score_simplernn_bit_plain\n",
        "print(\"Accuracy:\", score_simplernn_bit_plain[0])\n",
        "print(\"MSE:     \", score_simplernn_bit_plain[1])\n",
        "print(\"MAE:     \", score_simplernn_bit_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9991677249268773\n",
            "MSE:      17.273538525927137\n",
            "MAE:      0.06247414070704204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W8n8Tno2Sp-8"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdA8jFmzYfjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# built the model to initialize weights\n",
        "model = Sequential(name = \"model_SimpleRNN_bit\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dW2AVwRfSp-8",
        "outputId": "ef409d2f-61b4-4fcd-922e-762bf8f34938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bits[\"SimpleRNN_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 8s 23ms/step - loss: 0.5805 - accuracy: 0.6436 - val_loss: 0.4226 - val_accuracy: 0.7839\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.1903 - accuracy: 0.9149 - val_loss: 0.0142 - val_accuracy: 0.9982\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0022 - val_accuracy: 0.9999\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 6.3308e-04 - accuracy: 1.0000 - val_loss: 5.5327e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.4132 - val_accuracy: 0.9201\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 5.8142e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 3.7584e-04 - accuracy: 1.0000 - val_loss: 3.6566e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.1186e-04 - accuracy: 1.0000 - val_loss: 2.1987e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.3211e-04 - accuracy: 1.0000 - val_loss: 1.5488e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 9.3443e-05 - accuracy: 1.0000 - val_loss: 1.2574e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 6.9639e-05 - accuracy: 1.0000 - val_loss: 9.6272e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 5.3204e-05 - accuracy: 1.0000 - val_loss: 8.0733e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 4.1372e-05 - accuracy: 1.0000 - val_loss: 6.4242e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 3.2672e-05 - accuracy: 1.0000 - val_loss: 5.6381e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.6020e-05 - accuracy: 1.0000 - val_loss: 4.9492e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.0940e-05 - accuracy: 1.0000 - val_loss: 3.6207e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.6916e-05 - accuracy: 1.0000 - val_loss: 3.3575e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.3740e-05 - accuracy: 1.0000 - val_loss: 2.3547e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1190e-05 - accuracy: 1.0000 - val_loss: 2.3044e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 8s 23ms/step - loss: 9.1382e-06 - accuracy: 1.0000 - val_loss: 1.7341e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 7.5129e-06 - accuracy: 1.0000 - val_loss: 1.6148e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 6.1551e-06 - accuracy: 1.0000 - val_loss: 1.1330e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 5.0727e-06 - accuracy: 1.0000 - val_loss: 8.0390e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 4.1934e-06 - accuracy: 1.0000 - val_loss: 8.1238e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 3.4607e-06 - accuracy: 1.0000 - val_loss: 5.0819e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.8612e-06 - accuracy: 1.0000 - val_loss: 4.2393e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.3733e-06 - accuracy: 1.0000 - val_loss: 3.3231e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.9787e-06 - accuracy: 1.0000 - val_loss: 2.7434e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.6457e-06 - accuracy: 1.0000 - val_loss: 2.2852e-06 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.3756e-06 - accuracy: 1.0000 - val_loss: 2.0232e-06 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1491e-06 - accuracy: 1.0000 - val_loss: 1.6950e-06 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 9.6610e-07 - accuracy: 1.0000 - val_loss: 1.4501e-06 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 8.1755e-07 - accuracy: 1.0000 - val_loss: 1.1614e-06 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 6.8968e-07 - accuracy: 1.0000 - val_loss: 9.9672e-07 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.8767e-07 - accuracy: 1.0000 - val_loss: 8.4664e-07 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 5.0378e-07 - accuracy: 1.0000 - val_loss: 8.0545e-07 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 4.3467e-07 - accuracy: 1.0000 - val_loss: 7.1951e-07 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 3.9071e-07 - accuracy: 1.0000 - val_loss: 5.7327e-07 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 3.3368e-07 - accuracy: 1.0000 - val_loss: 4.9126e-07 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.9083e-07 - accuracy: 1.0000 - val_loss: 4.6654e-07 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.6009e-07 - accuracy: 1.0000 - val_loss: 4.0428e-07 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 2.3376e-07 - accuracy: 1.0000 - val_loss: 3.8661e-07 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 2.1293e-07 - accuracy: 1.0000 - val_loss: 3.5603e-07 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.9537e-07 - accuracy: 1.0000 - val_loss: 3.3095e-07 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.8107e-07 - accuracy: 1.0000 - val_loss: 2.8751e-07 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.6961e-07 - accuracy: 1.0000 - val_loss: 2.4058e-07 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.6059e-07 - accuracy: 1.0000 - val_loss: 2.5041e-07 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.5225e-07 - accuracy: 1.0000 - val_loss: 2.4133e-07 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.4598e-07 - accuracy: 1.0000 - val_loss: 2.2028e-07 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.4120e-07 - accuracy: 1.0000 - val_loss: 2.2556e-07 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.3694e-07 - accuracy: 1.0000 - val_loss: 1.9565e-07 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.3368e-07 - accuracy: 1.0000 - val_loss: 2.0863e-07 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.3090e-07 - accuracy: 1.0000 - val_loss: 2.2866e-07 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2878e-07 - accuracy: 1.0000 - val_loss: 2.1000e-07 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2700e-07 - accuracy: 1.0000 - val_loss: 1.9801e-07 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2556e-07 - accuracy: 1.0000 - val_loss: 2.2196e-07 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.2438e-07 - accuracy: 1.0000 - val_loss: 1.8441e-07 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.2347e-07 - accuracy: 1.0000 - val_loss: 1.6418e-07 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2266e-07 - accuracy: 1.0000 - val_loss: 1.4961e-07 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.2207e-07 - accuracy: 1.0000 - val_loss: 1.4295e-07 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.2155e-07 - accuracy: 1.0000 - val_loss: 1.5255e-07 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2111e-07 - accuracy: 1.0000 - val_loss: 1.4323e-07 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2078e-07 - accuracy: 1.0000 - val_loss: 1.5857e-07 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.2051e-07 - accuracy: 1.0000 - val_loss: 1.4128e-07 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.2027e-07 - accuracy: 1.0000 - val_loss: 1.5965e-07 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.2010e-07 - accuracy: 1.0000 - val_loss: 1.4316e-07 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1993e-07 - accuracy: 1.0000 - val_loss: 1.6576e-07 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1983e-07 - accuracy: 1.0000 - val_loss: 1.3504e-07 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1972e-07 - accuracy: 1.0000 - val_loss: 1.4566e-07 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1963e-07 - accuracy: 1.0000 - val_loss: 1.5370e-07 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1957e-07 - accuracy: 1.0000 - val_loss: 1.4774e-07 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1952e-07 - accuracy: 1.0000 - val_loss: 1.4670e-07 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1955e-07 - accuracy: 1.0000 - val_loss: 1.5715e-07 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1943e-07 - accuracy: 1.0000 - val_loss: 1.3019e-07 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1941e-07 - accuracy: 1.0000 - val_loss: 1.3508e-07 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1937e-07 - accuracy: 1.0000 - val_loss: 1.3080e-07 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1935e-07 - accuracy: 1.0000 - val_loss: 1.3380e-07 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1933e-07 - accuracy: 1.0000 - val_loss: 1.3807e-07 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1932e-07 - accuracy: 1.0000 - val_loss: 1.3989e-07 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1930e-07 - accuracy: 1.0000 - val_loss: 1.4069e-07 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1929e-07 - accuracy: 1.0000 - val_loss: 1.3668e-07 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1928e-07 - accuracy: 1.0000 - val_loss: 1.4231e-07 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1927e-07 - accuracy: 1.0000 - val_loss: 1.3130e-07 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1927e-07 - accuracy: 1.0000 - val_loss: 1.3159e-07 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1926e-07 - accuracy: 1.0000 - val_loss: 1.3440e-07 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1925e-07 - accuracy: 1.0000 - val_loss: 1.3640e-07 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1925e-07 - accuracy: 1.0000 - val_loss: 1.3504e-07 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1924e-07 - accuracy: 1.0000 - val_loss: 1.3425e-07 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1924e-07 - accuracy: 1.0000 - val_loss: 1.3296e-07 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1924e-07 - accuracy: 1.0000 - val_loss: 1.3092e-07 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.3199e-07 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.3082e-07 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.3245e-07 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.2858e-07 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.3615e-07 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3535e-07 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3526e-07 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.4033e-07 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3146e-07 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3318e-07 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3363e-07 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3899e-07 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3780e-07 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3559e-07 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3801e-07 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3495e-07 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.3461e-07 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4374e-07 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.4138e-07 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3498e-07 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4367e-07 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 8s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3949e-07 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3741e-07 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4151e-07 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3704e-07 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3828e-07 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3314e-07 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3943e-07 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4222e-07 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3731e-07 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3733e-07 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3884e-07 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4001e-07 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3896e-07 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3503e-07 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3589e-07 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4072e-07 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3536e-07 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3827e-07 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3811e-07 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4798e-07 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4264e-07 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3691e-07 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3816e-07 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4043e-07 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4273e-07 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3893e-07 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4453e-07 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3911e-07 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4376e-07 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4208e-07 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4436e-07 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4815e-07 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3775e-07 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3772e-07 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 8s 22ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3828e-07 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4185e-07 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4535e-07 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4021e-07 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3838e-07 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4372e-07 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3957e-07 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3824e-07 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4501e-07 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3929e-07 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3836e-07 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3922e-07 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3842e-07 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4100e-07 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4286e-07 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4044e-07 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4512e-07 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4850e-07 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4357e-07 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3754e-07 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3939e-07 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4150e-07 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4104e-07 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3855e-07 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4579e-07 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4521e-07 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4175e-07 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4075e-07 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3614e-07 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4063e-07 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4327e-07 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4090e-07 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4340e-07 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3533e-07 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4090e-07 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4194e-07 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3992e-07 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4154e-07 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.3903e-07 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4718e-07 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4228e-07 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4074e-07 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4532e-07 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4646e-07 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4092e-07 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4290e-07 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4345e-07 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4577e-07 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4906e-07 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4915e-07 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5426e-07 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5005e-07 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5308e-07 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 7s 21ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4680e-07 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xiI_DfQYSp_B",
        "outputId": "c9d532fd-1447-4aa5-b45d-688cb43bacd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"bit\", reverse = True)\n",
        "score_simplernn_bit_rev = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bits[\"SimpleRNN_rev\"] = score_simplernn_bit_rev\n",
        "print(\"Accuracy:\", score_simplernn_bit_rev[0])\n",
        "print(\"MSE:     \", score_simplernn_bit_rev[1])\n",
        "print(\"MAE:     \", score_simplernn_bit_rev[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9999818447458216\n",
            "MSE:      0.00014715311281388285\n",
            "MAE:      4.013266713105896e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FJMylKvgbdXI"
      },
      "source": [
        "### Model: GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v_-RvI1DbdXI",
        "outputId": "b7499728-617f-43e1-85e8-2d4f9d741225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.GRU\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_GRU_bit\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_GRU_bit\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 128)               51072     \n",
            "_________________________________________________________________\n",
            "repeat_vector_4 (RepeatVecto (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 11, 128)           99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 11, 3)             387       \n",
            "=================================================================\n",
            "Total params: 150,531\n",
            "Trainable params: 150,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7md294SnbdXK"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3SY9BsK0bdXL",
        "outputId": "bdae3c17-bb6c-480e-9baa-d8dddca18d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bits[\"GRU_plain\"] = history\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.6743 - accuracy: 0.5366 - val_loss: 0.6425 - val_accuracy: 0.5717\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5828 - accuracy: 0.6019 - val_loss: 0.5413 - val_accuracy: 0.6266\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5223 - accuracy: 0.6463 - val_loss: 0.5137 - val_accuracy: 0.6567\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4891 - accuracy: 0.6755 - val_loss: 0.4993 - val_accuracy: 0.6642\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4587 - accuracy: 0.7000 - val_loss: 0.4366 - val_accuracy: 0.7126\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4346 - accuracy: 0.7169 - val_loss: 0.4075 - val_accuracy: 0.7337\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4238 - accuracy: 0.7253 - val_loss: 0.4224 - val_accuracy: 0.7221\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4117 - accuracy: 0.7339 - val_loss: 0.3901 - val_accuracy: 0.7516\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4015 - accuracy: 0.7417 - val_loss: 0.3835 - val_accuracy: 0.7533\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4027 - accuracy: 0.7414 - val_loss: 0.3979 - val_accuracy: 0.7428\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3867 - accuracy: 0.7524 - val_loss: 0.3789 - val_accuracy: 0.7579\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3815 - accuracy: 0.7562 - val_loss: 0.4061 - val_accuracy: 0.7343\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3818 - accuracy: 0.7570 - val_loss: 0.3667 - val_accuracy: 0.7661\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3725 - accuracy: 0.7636 - val_loss: 0.3409 - val_accuracy: 0.7869\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3722 - accuracy: 0.7638 - val_loss: 0.4069 - val_accuracy: 0.7446\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3661 - accuracy: 0.7675 - val_loss: 0.3403 - val_accuracy: 0.7882\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3669 - accuracy: 0.7680 - val_loss: 0.3737 - val_accuracy: 0.7592\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3607 - accuracy: 0.7725 - val_loss: 0.3301 - val_accuracy: 0.7969\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3594 - accuracy: 0.7744 - val_loss: 0.3535 - val_accuracy: 0.7749\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3620 - accuracy: 0.7705 - val_loss: 0.3871 - val_accuracy: 0.7476\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3533 - accuracy: 0.7776 - val_loss: 0.3655 - val_accuracy: 0.7678\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3530 - accuracy: 0.7787 - val_loss: 0.3801 - val_accuracy: 0.7464\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3525 - accuracy: 0.7785 - val_loss: 0.3362 - val_accuracy: 0.7873\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3509 - accuracy: 0.7788 - val_loss: 0.3214 - val_accuracy: 0.8025\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3439 - accuracy: 0.7850 - val_loss: 0.4049 - val_accuracy: 0.7396\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3448 - accuracy: 0.7838 - val_loss: 0.3202 - val_accuracy: 0.8053\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3405 - accuracy: 0.7872 - val_loss: 0.3803 - val_accuracy: 0.7548\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3425 - accuracy: 0.7860 - val_loss: 0.3423 - val_accuracy: 0.7932\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3398 - accuracy: 0.7878 - val_loss: 0.3457 - val_accuracy: 0.7777\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3354 - accuracy: 0.7921 - val_loss: 0.3087 - val_accuracy: 0.8144\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3385 - accuracy: 0.7901 - val_loss: 0.3186 - val_accuracy: 0.8028\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3343 - accuracy: 0.7922 - val_loss: 0.3509 - val_accuracy: 0.7751\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3284 - accuracy: 0.7960 - val_loss: 0.3238 - val_accuracy: 0.7958\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3295 - accuracy: 0.7958 - val_loss: 0.3632 - val_accuracy: 0.7720\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3363 - accuracy: 0.7909 - val_loss: 0.3123 - val_accuracy: 0.8075\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3362 - accuracy: 0.7916 - val_loss: 0.3699 - val_accuracy: 0.7620\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3265 - accuracy: 0.7980 - val_loss: 0.3176 - val_accuracy: 0.8035\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3313 - accuracy: 0.7948 - val_loss: 0.2988 - val_accuracy: 0.8151\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3265 - accuracy: 0.7986 - val_loss: 0.2811 - val_accuracy: 0.8354\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3306 - accuracy: 0.7970 - val_loss: 0.3174 - val_accuracy: 0.8057\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3257 - accuracy: 0.7992 - val_loss: 0.4096 - val_accuracy: 0.7610\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3247 - accuracy: 0.8004 - val_loss: 0.3461 - val_accuracy: 0.7820\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3213 - accuracy: 0.8045 - val_loss: 0.4015 - val_accuracy: 0.7586\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3215 - accuracy: 0.8085 - val_loss: 0.2902 - val_accuracy: 0.8291\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3204 - accuracy: 0.8117 - val_loss: 0.3026 - val_accuracy: 0.8280\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3146 - accuracy: 0.8205 - val_loss: 0.3526 - val_accuracy: 0.7965\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3129 - accuracy: 0.8273 - val_loss: 0.2930 - val_accuracy: 0.8423\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3014 - accuracy: 0.8385 - val_loss: 0.2765 - val_accuracy: 0.8560\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2874 - accuracy: 0.8476 - val_loss: 0.3025 - val_accuracy: 0.8335\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2790 - accuracy: 0.8485 - val_loss: 0.3098 - val_accuracy: 0.8272\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2737 - accuracy: 0.8467 - val_loss: 0.2328 - val_accuracy: 0.8745\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2655 - accuracy: 0.8466 - val_loss: 0.2510 - val_accuracy: 0.8573\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2548 - accuracy: 0.8538 - val_loss: 0.3361 - val_accuracy: 0.8037\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2570 - accuracy: 0.8523 - val_loss: 0.2335 - val_accuracy: 0.8685\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2490 - accuracy: 0.8604 - val_loss: 0.2672 - val_accuracy: 0.8547\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.2372 - accuracy: 0.8751 - val_loss: 0.2076 - val_accuracy: 0.8944\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2204 - accuracy: 0.8851 - val_loss: 0.1844 - val_accuracy: 0.9078\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2105 - accuracy: 0.8894 - val_loss: 0.1941 - val_accuracy: 0.8970\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2090 - accuracy: 0.8890 - val_loss: 0.1804 - val_accuracy: 0.9080\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1962 - accuracy: 0.8969 - val_loss: 0.1739 - val_accuracy: 0.9133\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1889 - accuracy: 0.9015 - val_loss: 0.1895 - val_accuracy: 0.8979\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1897 - accuracy: 0.9003 - val_loss: 0.1716 - val_accuracy: 0.9056\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1859 - accuracy: 0.9016 - val_loss: 0.1724 - val_accuracy: 0.9079\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1831 - accuracy: 0.9054 - val_loss: 0.2080 - val_accuracy: 0.8874\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1880 - accuracy: 0.9027 - val_loss: 0.1584 - val_accuracy: 0.9204\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1863 - accuracy: 0.9042 - val_loss: 0.1874 - val_accuracy: 0.9010\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1789 - accuracy: 0.9088 - val_loss: 0.1688 - val_accuracy: 0.9132\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1695 - accuracy: 0.9140 - val_loss: 0.1716 - val_accuracy: 0.9149\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1697 - accuracy: 0.9144 - val_loss: 0.1362 - val_accuracy: 0.9379\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1716 - accuracy: 0.9136 - val_loss: 0.1495 - val_accuracy: 0.9307\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1565 - accuracy: 0.9236 - val_loss: 0.1900 - val_accuracy: 0.9002\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1561 - accuracy: 0.9255 - val_loss: 0.1416 - val_accuracy: 0.9373\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.1569 - accuracy: 0.9244 - val_loss: 0.1223 - val_accuracy: 0.9510\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1487 - accuracy: 0.9303 - val_loss: 0.1671 - val_accuracy: 0.9174\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1430 - accuracy: 0.9333 - val_loss: 0.1363 - val_accuracy: 0.9361\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1485 - accuracy: 0.9320 - val_loss: 0.1861 - val_accuracy: 0.9139\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1330 - accuracy: 0.9396 - val_loss: 0.1297 - val_accuracy: 0.9400\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1343 - accuracy: 0.9398 - val_loss: 0.1569 - val_accuracy: 0.9242\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1300 - accuracy: 0.9418 - val_loss: 0.1364 - val_accuracy: 0.9370\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.1216 - accuracy: 0.9470 - val_loss: 0.1026 - val_accuracy: 0.9553\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1271 - accuracy: 0.9446 - val_loss: 0.1117 - val_accuracy: 0.9496\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1055 - accuracy: 0.9548 - val_loss: 0.0979 - val_accuracy: 0.9572\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1020 - accuracy: 0.9566 - val_loss: 0.1157 - val_accuracy: 0.9486\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1085 - accuracy: 0.9547 - val_loss: 0.1187 - val_accuracy: 0.9496\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0897 - accuracy: 0.9631 - val_loss: 0.0971 - val_accuracy: 0.9599\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0899 - accuracy: 0.9626 - val_loss: 0.1371 - val_accuracy: 0.9383\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0868 - accuracy: 0.9642 - val_loss: 0.1740 - val_accuracy: 0.9294\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0922 - accuracy: 0.9625 - val_loss: 0.1545 - val_accuracy: 0.9280\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0839 - accuracy: 0.9662 - val_loss: 0.1451 - val_accuracy: 0.9387\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0833 - accuracy: 0.9666 - val_loss: 0.0983 - val_accuracy: 0.9579\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0705 - accuracy: 0.9729 - val_loss: 0.0387 - val_accuracy: 0.9863\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0785 - accuracy: 0.9684 - val_loss: 0.1124 - val_accuracy: 0.9518\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0796 - accuracy: 0.9672 - val_loss: 0.0988 - val_accuracy: 0.9560\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0617 - accuracy: 0.9754 - val_loss: 0.0392 - val_accuracy: 0.9878\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0778 - accuracy: 0.9698 - val_loss: 0.0399 - val_accuracy: 0.9844\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0648 - accuracy: 0.9743 - val_loss: 0.1391 - val_accuracy: 0.9441\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0935 - accuracy: 0.9612 - val_loss: 0.1195 - val_accuracy: 0.9442\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0473 - accuracy: 0.9816 - val_loss: 0.0281 - val_accuracy: 0.9906\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0879 - accuracy: 0.9654 - val_loss: 0.1264 - val_accuracy: 0.9436\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0707 - accuracy: 0.9719 - val_loss: 0.0836 - val_accuracy: 0.9620\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0622 - accuracy: 0.9745 - val_loss: 0.0508 - val_accuracy: 0.9788\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0615 - accuracy: 0.9767 - val_loss: 0.0328 - val_accuracy: 0.9896\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0497 - accuracy: 0.9805 - val_loss: 0.0249 - val_accuracy: 0.9914\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0674 - accuracy: 0.9748 - val_loss: 0.0237 - val_accuracy: 0.9913\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0602 - accuracy: 0.9761 - val_loss: 0.0396 - val_accuracy: 0.9841\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0574 - accuracy: 0.9769 - val_loss: 0.0244 - val_accuracy: 0.9926\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0634 - accuracy: 0.9756 - val_loss: 0.0176 - val_accuracy: 0.9946\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0486 - accuracy: 0.9806 - val_loss: 0.0137 - val_accuracy: 0.9964\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0630 - accuracy: 0.9781 - val_loss: 0.0214 - val_accuracy: 0.9921\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0552 - accuracy: 0.9790 - val_loss: 0.0232 - val_accuracy: 0.9933\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0426 - accuracy: 0.9849 - val_loss: 0.0635 - val_accuracy: 0.9753\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0605 - accuracy: 0.9770 - val_loss: 0.0538 - val_accuracy: 0.9755\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0668 - accuracy: 0.9741 - val_loss: 0.0154 - val_accuracy: 0.9957\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0493 - accuracy: 0.9817 - val_loss: 0.0160 - val_accuracy: 0.9949\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0528 - accuracy: 0.9790 - val_loss: 0.0555 - val_accuracy: 0.9775\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0465 - accuracy: 0.9818 - val_loss: 0.0378 - val_accuracy: 0.9832\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.0192 - val_accuracy: 0.9927\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0676 - accuracy: 0.9733 - val_loss: 0.0134 - val_accuracy: 0.9959\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0538 - accuracy: 0.9789 - val_loss: 0.0231 - val_accuracy: 0.9940\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.1262 - val_accuracy: 0.9502\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0427 - accuracy: 0.9834 - val_loss: 0.0154 - val_accuracy: 0.9959\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0552 - accuracy: 0.9783 - val_loss: 0.0161 - val_accuracy: 0.9962\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0475 - accuracy: 0.9822 - val_loss: 0.0111 - val_accuracy: 0.9971\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0641 - accuracy: 0.9772 - val_loss: 0.0245 - val_accuracy: 0.9928\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0542 - accuracy: 0.9797 - val_loss: 0.0463 - val_accuracy: 0.9852\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0462 - accuracy: 0.9827 - val_loss: 0.0124 - val_accuracy: 0.9965\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 0.0127 - val_accuracy: 0.9970\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0455 - accuracy: 0.9828 - val_loss: 0.0238 - val_accuracy: 0.9905\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0564 - accuracy: 0.9789 - val_loss: 0.0124 - val_accuracy: 0.9970\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0602 - accuracy: 0.9770 - val_loss: 0.0152 - val_accuracy: 0.9963\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0527 - accuracy: 0.9820 - val_loss: 0.0500 - val_accuracy: 0.9862\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0385 - accuracy: 0.9872 - val_loss: 0.0633 - val_accuracy: 0.9740\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0477 - accuracy: 0.9814 - val_loss: 0.0116 - val_accuracy: 0.9970\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0529 - accuracy: 0.9806 - val_loss: 0.0362 - val_accuracy: 0.9859\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9859 - val_loss: 0.0531 - val_accuracy: 0.9763\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.0320 - val_accuracy: 0.9888\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9870 - val_loss: 0.0285 - val_accuracy: 0.9921\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0387 - accuracy: 0.9858 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0500 - accuracy: 0.9804 - val_loss: 0.0531 - val_accuracy: 0.9783\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0348 - accuracy: 0.9875 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0459 - accuracy: 0.9830 - val_loss: 0.0452 - val_accuracy: 0.9828\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9894 - val_loss: 0.1927 - val_accuracy: 0.9343\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0420 - accuracy: 0.9841 - val_loss: 0.0717 - val_accuracy: 0.9707\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0451 - accuracy: 0.9829 - val_loss: 0.0354 - val_accuracy: 0.9867\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9897 - val_loss: 0.0380 - val_accuracy: 0.9846\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.0091 - val_accuracy: 0.9981\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.0105 - val_accuracy: 0.9961\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.0307 - val_accuracy: 0.9877\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.9862 - val_loss: 0.0183 - val_accuracy: 0.9939\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.0090 - val_accuracy: 0.9979\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.0287 - val_accuracy: 0.9890\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0419 - accuracy: 0.9852 - val_loss: 0.0303 - val_accuracy: 0.9889\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0254 - val_accuracy: 0.9911\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.0100 - val_accuracy: 0.9968\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0260 - val_accuracy: 0.9896\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0150 - val_accuracy: 0.9948\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0127 - val_accuracy: 0.9962\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0384 - accuracy: 0.9868 - val_loss: 0.0053 - val_accuracy: 0.9993\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.0271 - val_accuracy: 0.9908\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0080 - val_accuracy: 0.9978\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.0106 - val_accuracy: 0.9967\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0192 - val_accuracy: 0.9934\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.0255 - val_accuracy: 0.9916\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1519 - val_accuracy: 0.9542\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0223 - val_accuracy: 0.9926\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0180 - val_accuracy: 0.9932\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0187 - val_accuracy: 0.9921\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.0338 - val_accuracy: 0.9858\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0264 - val_accuracy: 0.9896\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1256 - val_accuracy: 0.9397\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0098 - val_accuracy: 0.9971\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0097 - val_accuracy: 0.9972\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0150 - val_accuracy: 0.9962\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0436 - accuracy: 0.9856 - val_loss: 0.0143 - val_accuracy: 0.9961\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0149 - val_accuracy: 0.9950\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0114 - val_accuracy: 0.9955\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.0059 - val_accuracy: 0.9991\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wAhZOCOibdXP",
        "outputId": "42848d6f-65a2-432d-b2ca-663c50a1305e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"bit\", reverse = False)\n",
        "score_gru_bit_plain = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bits[\"GRU_plain\"] = score_gru_bit_plain\n",
        "print(\"Accuracy:\", score_gru_bit_plain[0])\n",
        "print(\"MSE:     \", score_gru_bit_plain[1])\n",
        "print(\"MAE:     \", score_gru_bit_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9845040127889433\n",
            "MSE:      22.262810681787126\n",
            "MAE:      0.3365726128946259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CaP9gKhtbdXR"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6mSnHgi0bdXS",
        "outputId": "d02d764d-ee8f-40c2-ebd2-51e86c42801e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bits[\"GRU_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.3862 - accuracy: 0.5735 - val_loss: 0.6227 - val_accuracy: 0.6263\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5373 - accuracy: 0.6663 - val_loss: 0.4904 - val_accuracy: 0.6915\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4555 - accuracy: 0.7096 - val_loss: 0.4375 - val_accuracy: 0.7214\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4137 - accuracy: 0.7368 - val_loss: 0.3895 - val_accuracy: 0.7535\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3730 - accuracy: 0.7644 - val_loss: 0.3737 - val_accuracy: 0.7649\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3508 - accuracy: 0.7793 - val_loss: 0.3431 - val_accuracy: 0.7874\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3336 - accuracy: 0.7919 - val_loss: 0.3216 - val_accuracy: 0.7990\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3203 - accuracy: 0.8023 - val_loss: 0.3109 - val_accuracy: 0.8079\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3069 - accuracy: 0.8121 - val_loss: 0.2970 - val_accuracy: 0.8161\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2959 - accuracy: 0.8185 - val_loss: 0.3121 - val_accuracy: 0.8094\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2842 - accuracy: 0.8249 - val_loss: 0.2974 - val_accuracy: 0.8147\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2791 - accuracy: 0.8280 - val_loss: 0.2785 - val_accuracy: 0.8286\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2683 - accuracy: 0.8344 - val_loss: 0.2671 - val_accuracy: 0.8333\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2613 - accuracy: 0.8385 - val_loss: 0.2760 - val_accuracy: 0.8285\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2599 - accuracy: 0.8401 - val_loss: 0.2721 - val_accuracy: 0.8341\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2530 - accuracy: 0.8440 - val_loss: 0.2752 - val_accuracy: 0.8319\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2515 - accuracy: 0.8457 - val_loss: 0.2511 - val_accuracy: 0.8452\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2454 - accuracy: 0.8484 - val_loss: 0.2357 - val_accuracy: 0.8535\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2421 - accuracy: 0.8517 - val_loss: 0.2593 - val_accuracy: 0.8418\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2370 - accuracy: 0.8542 - val_loss: 0.2497 - val_accuracy: 0.8504\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2354 - accuracy: 0.8563 - val_loss: 0.2404 - val_accuracy: 0.8503\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2342 - accuracy: 0.8578 - val_loss: 0.2410 - val_accuracy: 0.8538\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.2296 - accuracy: 0.8601 - val_loss: 0.2299 - val_accuracy: 0.8600\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2231 - accuracy: 0.8643 - val_loss: 0.2279 - val_accuracy: 0.8617\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2224 - accuracy: 0.8651 - val_loss: 0.2296 - val_accuracy: 0.8602\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2215 - accuracy: 0.8668 - val_loss: 0.2340 - val_accuracy: 0.8594\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2169 - accuracy: 0.8700 - val_loss: 0.2154 - val_accuracy: 0.8700\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2127 - accuracy: 0.8730 - val_loss: 0.2296 - val_accuracy: 0.8667\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2081 - accuracy: 0.8763 - val_loss: 0.2090 - val_accuracy: 0.8743\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2019 - accuracy: 0.8799 - val_loss: 0.2015 - val_accuracy: 0.8785\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1984 - accuracy: 0.8834 - val_loss: 0.1961 - val_accuracy: 0.8830\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1996 - accuracy: 0.8825 - val_loss: 0.1901 - val_accuracy: 0.8849\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1894 - accuracy: 0.8886 - val_loss: 0.2005 - val_accuracy: 0.8803\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1849 - accuracy: 0.8918 - val_loss: 0.1951 - val_accuracy: 0.8847\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1872 - accuracy: 0.8915 - val_loss: 0.2208 - val_accuracy: 0.8706\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1814 - accuracy: 0.8951 - val_loss: 0.1945 - val_accuracy: 0.8881\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1781 - accuracy: 0.8976 - val_loss: 0.1842 - val_accuracy: 0.8935\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1746 - accuracy: 0.8994 - val_loss: 0.1814 - val_accuracy: 0.8956\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1692 - accuracy: 0.9039 - val_loss: 0.1994 - val_accuracy: 0.8901\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1636 - accuracy: 0.9069 - val_loss: 0.1645 - val_accuracy: 0.9067\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1608 - accuracy: 0.9093 - val_loss: 0.1623 - val_accuracy: 0.9066\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1605 - accuracy: 0.9103 - val_loss: 0.1579 - val_accuracy: 0.9133\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1506 - accuracy: 0.9156 - val_loss: 0.1715 - val_accuracy: 0.9044\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1486 - accuracy: 0.9184 - val_loss: 0.1696 - val_accuracy: 0.9033\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1462 - accuracy: 0.9196 - val_loss: 0.1525 - val_accuracy: 0.9154\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1406 - accuracy: 0.9234 - val_loss: 0.1376 - val_accuracy: 0.9256\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1369 - accuracy: 0.9259 - val_loss: 0.1461 - val_accuracy: 0.9231\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1379 - accuracy: 0.9259 - val_loss: 0.1372 - val_accuracy: 0.9260\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1310 - accuracy: 0.9298 - val_loss: 0.1544 - val_accuracy: 0.9151\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1224 - accuracy: 0.9349 - val_loss: 0.1267 - val_accuracy: 0.9315\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1220 - accuracy: 0.9364 - val_loss: 0.1098 - val_accuracy: 0.9415\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1201 - accuracy: 0.9374 - val_loss: 0.1342 - val_accuracy: 0.9285\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1154 - accuracy: 0.9399 - val_loss: 0.1240 - val_accuracy: 0.9359\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1089 - accuracy: 0.9445 - val_loss: 0.1238 - val_accuracy: 0.9363\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1063 - accuracy: 0.9462 - val_loss: 0.1284 - val_accuracy: 0.9357\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1022 - accuracy: 0.9487 - val_loss: 0.1092 - val_accuracy: 0.9452\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1059 - accuracy: 0.9473 - val_loss: 0.1542 - val_accuracy: 0.9240\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0933 - accuracy: 0.9539 - val_loss: 0.1024 - val_accuracy: 0.9486\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0971 - accuracy: 0.9521 - val_loss: 0.0940 - val_accuracy: 0.9535\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.9563 - val_loss: 0.1007 - val_accuracy: 0.9489\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0848 - accuracy: 0.9589 - val_loss: 0.0923 - val_accuracy: 0.9550\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0863 - accuracy: 0.9584 - val_loss: 0.0762 - val_accuracy: 0.9640\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0832 - accuracy: 0.9606 - val_loss: 0.0832 - val_accuracy: 0.9596\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0719 - accuracy: 0.9661 - val_loss: 0.1102 - val_accuracy: 0.9460\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0849 - accuracy: 0.9593 - val_loss: 0.0958 - val_accuracy: 0.9535\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0666 - accuracy: 0.9686 - val_loss: 0.0741 - val_accuracy: 0.9653\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0817 - accuracy: 0.9623 - val_loss: 0.0692 - val_accuracy: 0.9674\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0664 - accuracy: 0.9691 - val_loss: 0.1253 - val_accuracy: 0.9415\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0693 - accuracy: 0.9674 - val_loss: 0.0772 - val_accuracy: 0.9627\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0779 - accuracy: 0.9641 - val_loss: 0.1572 - val_accuracy: 0.9310\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0631 - accuracy: 0.9709 - val_loss: 0.0683 - val_accuracy: 0.9680\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0661 - accuracy: 0.9693 - val_loss: 0.0531 - val_accuracy: 0.9741\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0573 - accuracy: 0.9735 - val_loss: 0.0627 - val_accuracy: 0.9709\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0702 - accuracy: 0.9676 - val_loss: 0.0576 - val_accuracy: 0.9716\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0573 - accuracy: 0.9736 - val_loss: 0.0559 - val_accuracy: 0.9743\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0607 - accuracy: 0.9726 - val_loss: 0.0581 - val_accuracy: 0.9726\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0646 - accuracy: 0.9706 - val_loss: 0.0538 - val_accuracy: 0.9736\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0521 - accuracy: 0.9765 - val_loss: 0.0938 - val_accuracy: 0.9571\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0536 - accuracy: 0.9757 - val_loss: 0.0594 - val_accuracy: 0.9720\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.9754 - val_loss: 0.0603 - val_accuracy: 0.9726\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0469 - accuracy: 0.9788 - val_loss: 0.0650 - val_accuracy: 0.9693\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0561 - accuracy: 0.9749 - val_loss: 0.0533 - val_accuracy: 0.9752\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0542 - accuracy: 0.9758 - val_loss: 0.0551 - val_accuracy: 0.9755\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0508 - accuracy: 0.9775 - val_loss: 0.0599 - val_accuracy: 0.9737\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0464 - accuracy: 0.9795 - val_loss: 0.0765 - val_accuracy: 0.9640\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0487 - accuracy: 0.9783 - val_loss: 0.0631 - val_accuracy: 0.9723\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0494 - accuracy: 0.9781 - val_loss: 0.0519 - val_accuracy: 0.9753\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0492 - accuracy: 0.9783 - val_loss: 0.0766 - val_accuracy: 0.9673\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9839 - val_loss: 0.0978 - val_accuracy: 0.9589\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0514 - accuracy: 0.9775 - val_loss: 0.0749 - val_accuracy: 0.9645\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0447 - accuracy: 0.9799 - val_loss: 0.0497 - val_accuracy: 0.9772\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0391 - accuracy: 0.9827 - val_loss: 0.0348 - val_accuracy: 0.9844\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0505 - accuracy: 0.9785 - val_loss: 0.0756 - val_accuracy: 0.9677\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9845 - val_loss: 0.0715 - val_accuracy: 0.9681\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0543 - accuracy: 0.9766 - val_loss: 0.0505 - val_accuracy: 0.9772\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0405 - accuracy: 0.9825 - val_loss: 0.0440 - val_accuracy: 0.9800\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0482 - accuracy: 0.9789 - val_loss: 0.0412 - val_accuracy: 0.9813\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.9832 - val_loss: 0.0429 - val_accuracy: 0.9806\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0331 - accuracy: 0.9854 - val_loss: 0.0457 - val_accuracy: 0.9792\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0506 - accuracy: 0.9786 - val_loss: 0.0804 - val_accuracy: 0.9661\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0326 - accuracy: 0.9861 - val_loss: 0.0314 - val_accuracy: 0.9857\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0445 - accuracy: 0.9810 - val_loss: 0.0410 - val_accuracy: 0.9818\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.9828 - val_loss: 0.0433 - val_accuracy: 0.9805\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0426 - accuracy: 0.9823 - val_loss: 0.0289 - val_accuracy: 0.9862\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0418 - accuracy: 0.9823 - val_loss: 0.0305 - val_accuracy: 0.9863\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9868 - val_loss: 0.0452 - val_accuracy: 0.9800\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9892 - val_loss: 0.0304 - val_accuracy: 0.9872\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0520 - accuracy: 0.9784 - val_loss: 0.0434 - val_accuracy: 0.9814\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9869 - val_loss: 0.0308 - val_accuracy: 0.9864\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9839 - val_loss: 0.0465 - val_accuracy: 0.9811\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0323 - accuracy: 0.9863 - val_loss: 0.0394 - val_accuracy: 0.9828\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0313 - accuracy: 0.9868 - val_loss: 0.0392 - val_accuracy: 0.9839\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0398 - accuracy: 0.9833 - val_loss: 0.0352 - val_accuracy: 0.9840\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9853 - val_loss: 0.0557 - val_accuracy: 0.9767\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0398 - accuracy: 0.9842 - val_loss: 0.0663 - val_accuracy: 0.9710\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9855 - val_loss: 0.0776 - val_accuracy: 0.9712\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9868 - val_loss: 0.0452 - val_accuracy: 0.9838\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9855 - val_loss: 0.1605 - val_accuracy: 0.9435\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0339 - accuracy: 0.9859 - val_loss: 0.0460 - val_accuracy: 0.9790\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0330 - accuracy: 0.9860 - val_loss: 0.0219 - val_accuracy: 0.9898\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0332 - accuracy: 0.9863 - val_loss: 0.0555 - val_accuracy: 0.9764\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9898 - val_loss: 0.0438 - val_accuracy: 0.9820\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0322 - accuracy: 0.9868 - val_loss: 0.0270 - val_accuracy: 0.9887\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0221 - accuracy: 0.9908 - val_loss: 0.0273 - val_accuracy: 0.9877\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0419 - accuracy: 0.9829 - val_loss: 0.0287 - val_accuracy: 0.9882\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0195 - accuracy: 0.9919 - val_loss: 0.0239 - val_accuracy: 0.9892\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0433 - accuracy: 0.9821 - val_loss: 0.0949 - val_accuracy: 0.9576\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0325 - accuracy: 0.9868 - val_loss: 0.0219 - val_accuracy: 0.9894\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0261 - accuracy: 0.9893 - val_loss: 0.0344 - val_accuracy: 0.9856\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.9885 - val_loss: 0.0275 - val_accuracy: 0.9880\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0279 - accuracy: 0.9885 - val_loss: 0.0238 - val_accuracy: 0.9898\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0282 - accuracy: 0.9885 - val_loss: 0.0618 - val_accuracy: 0.9746\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0342 - accuracy: 0.9865 - val_loss: 0.0307 - val_accuracy: 0.9872\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9869 - val_loss: 0.0395 - val_accuracy: 0.9838\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 0.0206 - val_accuracy: 0.9909\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9907 - val_loss: 0.0335 - val_accuracy: 0.9861\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0299 - accuracy: 0.9885 - val_loss: 0.0577 - val_accuracy: 0.9772\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0326 - accuracy: 0.9869 - val_loss: 0.0183 - val_accuracy: 0.9925\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0285 - accuracy: 0.9883 - val_loss: 0.0380 - val_accuracy: 0.9838\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0403 - val_accuracy: 0.9839\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.0212 - val_accuracy: 0.9913\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0425 - accuracy: 0.9836 - val_loss: 0.0212 - val_accuracy: 0.9909\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0388 - accuracy: 0.9846 - val_loss: 0.0260 - val_accuracy: 0.9892\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0268 - accuracy: 0.9895 - val_loss: 0.0299 - val_accuracy: 0.9882\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0260 - accuracy: 0.9896 - val_loss: 0.0179 - val_accuracy: 0.9926\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0290 - accuracy: 0.9883 - val_loss: 0.0271 - val_accuracy: 0.9884\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0138 - accuracy: 0.9946 - val_loss: 0.0231 - val_accuracy: 0.9901\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9864 - val_loss: 0.0567 - val_accuracy: 0.9774\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 0.0307 - val_accuracy: 0.9875\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0192 - val_accuracy: 0.9921\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9914 - val_loss: 0.0417 - val_accuracy: 0.9835\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0226 - accuracy: 0.9912 - val_loss: 0.0372 - val_accuracy: 0.9841\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0204 - accuracy: 0.9919 - val_loss: 0.0240 - val_accuracy: 0.9904\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0213 - accuracy: 0.9917 - val_loss: 0.0143 - val_accuracy: 0.9943\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0348 - accuracy: 0.9867 - val_loss: 0.0230 - val_accuracy: 0.9903\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0477 - val_accuracy: 0.9817\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0299 - accuracy: 0.9883 - val_loss: 0.0351 - val_accuracy: 0.9858\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.0246 - val_accuracy: 0.9903\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.0217 - val_accuracy: 0.9919\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0363 - accuracy: 0.9864 - val_loss: 0.0235 - val_accuracy: 0.9903\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0164 - accuracy: 0.9938 - val_loss: 0.0123 - val_accuracy: 0.9949\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0149 - accuracy: 0.9944 - val_loss: 0.0875 - val_accuracy: 0.9667\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.0150 - val_accuracy: 0.9943\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9850 - val_loss: 0.0128 - val_accuracy: 0.9951\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0262 - val_accuracy: 0.9904\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 0.0646 - val_accuracy: 0.9745\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.0164 - val_accuracy: 0.9931\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0176 - val_accuracy: 0.9930\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9877 - val_loss: 0.0193 - val_accuracy: 0.9918\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0909 - val_accuracy: 0.9704\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.9890 - val_loss: 0.0250 - val_accuracy: 0.9904\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.0122 - val_accuracy: 0.9953\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.0376 - val_accuracy: 0.9851\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.0181 - val_accuracy: 0.9927\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0614 - val_accuracy: 0.9769\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.0147 - val_accuracy: 0.9944\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.9925 - val_loss: 0.0665 - val_accuracy: 0.9746\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0374 - accuracy: 0.9861 - val_loss: 0.0385 - val_accuracy: 0.9840\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0147 - val_accuracy: 0.9939\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9924 - val_loss: 0.0429 - val_accuracy: 0.9828\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0105 - val_accuracy: 0.9961\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0172 - val_accuracy: 0.9932\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0212 - val_accuracy: 0.9915\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.0227 - val_accuracy: 0.9912\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.0247 - val_accuracy: 0.9904\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 0.0140 - val_accuracy: 0.9949\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0773 - val_accuracy: 0.9712\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9923 - val_loss: 0.0244 - val_accuracy: 0.9904\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.0120 - val_accuracy: 0.9952\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.0178 - val_accuracy: 0.9926\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 0.0199 - val_accuracy: 0.9920\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0132 - val_accuracy: 0.9955\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.0217 - val_accuracy: 0.9924\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0087 - val_accuracy: 0.9969\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.0346 - val_accuracy: 0.9872\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 0.0172 - val_accuracy: 0.9935\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9964\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 0.0123 - val_accuracy: 0.9954\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0844 - val_accuracy: 0.9742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fX0oN9fIbdXV",
        "outputId": "2007de11-5c4d-4816-a07b-330852776be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"bit\", reverse = True)\n",
        "score_gru_bit_reverse = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bits[\"GRU_rev\"] = score_gru_bit_reverse\n",
        "print(\"Accuracy:\", score_gru_bit_reverse[0])\n",
        "print(\"MSE:     \", score_gru_bit_reverse[1])\n",
        "print(\"MAE:     \", score_gru_bit_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.741636399946872\n",
            "MSE:      948.5307602560464\n",
            "MAE:      4.673903924305968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BBa--R9rVfe",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyzzO-iGDJDw",
        "colab_type": "code",
        "outputId": "73a942a3-6970-45c5-80a7-b512d112e1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#Plot Results\n",
        "results_df = pd.DataFrame(results_bits,\n",
        "                          index = [\"ACC\", \"MSE\", \"MAE\"])\n",
        "print(results_df.to_latex(float_format=\"%.3f\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrrr}\n",
            "\\toprule\n",
            "{} &  LSTM\\_plain &  LSTM\\_rev &  SimpleRNN\\_plain &  SimpleRNN\\_rev &  GRU\\_plain &  GRU\\_rev \\\\\n",
            "\\midrule\n",
            "ACC &       0.801 &     0.999 &            0.999 &          1.000 &      0.985 &    0.742 \\\\\n",
            "MSE &     777.559 &     0.693 &           17.274 &          0.000 &     22.263 &  948.531 \\\\\n",
            "MAE &       5.154 &     0.018 &            0.062 &          0.000 &      0.337 &    4.674 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVp9sJooQtAp",
        "colab_type": "code",
        "outputId": "42cb5251-6134-4a8e-f255-32236cf2ead3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "#Plot training\n",
        "fig, ax = plt.subplots()\n",
        "for key, item in histories_bits.items():\n",
        "    plt.plot(pd.DataFrame(item.history[\"val_accuracy\"]))\n",
        "\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.legend(histories_bits.keys())\n",
        "plt.title(\"Validation Accuracy while training \\n on the Binary Representation\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qheOjj47fiqg",
        "colab_type": "text"
      },
      "source": [
        "# Task 3: Pairs of digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8VOnhGE2rBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data parameters\n",
        "TRAINING_SIZE = 5e4\n",
        "DIGITS = 3\n",
        "MAXLEN = DIGITS + DIGITS\n",
        "chars = '0123456789 '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "#empty dictionaries to save results\n",
        "histories_digits_pairs, results_digits_pair = {}, {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWfeVjRP1xYl",
        "colab_type": "code",
        "outputId": "ea06e4ef-90c0-4a10-b2f7-154d4daa1442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# generate plain data\n",
        "x_train_plain, x_val_plain, y_train_plain, y_val_plain = generate_data(TRAINING_SIZE, DIGITS, as_pairs = True, reverse = False)\n",
        "\n",
        "# generate reverse data\n",
        "x_train_rev, x_val_rev, y_train_rev, y_val_rev = generate_data(TRAINING_SIZE, DIGITS, as_pairs = True, reverse = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n",
            "Generating data...\n",
            "Total addition questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJpTq0Dr2ZCQ",
        "colab_type": "text"
      },
      "source": [
        "#### Model: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iri4jhF62lMk",
        "colab_type": "code",
        "outputId": "4b20d8af-80a3-413f-8089-d4400838f7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.LSTM\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_LSTM_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_LSTM_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 128)               71680     \n",
            "_________________________________________________________________\n",
            "repeat_vector_5 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 4, 11)             1419      \n",
            "=================================================================\n",
            "Total params: 204,683\n",
            "Trainable params: 204,683\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7np81mPW2c6v",
        "colab_type": "text"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2CIolmk-3cxW",
        "outputId": "e4dbbea3-e85b-4bcc-b389-38e56ff52955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "\n",
        "histories_digits_pairs[\"LSTM_plain\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.8481 - accuracy: 0.3254 - val_loss: 1.6636 - val_accuracy: 0.3853\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.5092 - accuracy: 0.4343 - val_loss: 1.3857 - val_accuracy: 0.4755\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.3373 - accuracy: 0.4916 - val_loss: 1.2977 - val_accuracy: 0.5031\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.2568 - accuracy: 0.5206 - val_loss: 1.2262 - val_accuracy: 0.5283\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1927 - accuracy: 0.5445 - val_loss: 1.1553 - val_accuracy: 0.5575\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1290 - accuracy: 0.5671 - val_loss: 1.0943 - val_accuracy: 0.5799\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0745 - accuracy: 0.5862 - val_loss: 1.0552 - val_accuracy: 0.5892\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0245 - accuracy: 0.6037 - val_loss: 1.0201 - val_accuracy: 0.6043\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9874 - accuracy: 0.6179 - val_loss: 0.9755 - val_accuracy: 0.6239\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9556 - accuracy: 0.6320 - val_loss: 0.9406 - val_accuracy: 0.6405\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9206 - accuracy: 0.6469 - val_loss: 0.9364 - val_accuracy: 0.6353\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.8929 - accuracy: 0.6593 - val_loss: 0.8845 - val_accuracy: 0.6588\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.8606 - accuracy: 0.6714 - val_loss: 0.8513 - val_accuracy: 0.6736\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8237 - accuracy: 0.6886 - val_loss: 0.8105 - val_accuracy: 0.6926\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7674 - accuracy: 0.7101 - val_loss: 0.7323 - val_accuracy: 0.7175\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6625 - accuracy: 0.7512 - val_loss: 0.5999 - val_accuracy: 0.7771\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5105 - accuracy: 0.8131 - val_loss: 0.4531 - val_accuracy: 0.8324\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3822 - accuracy: 0.8731 - val_loss: 0.3508 - val_accuracy: 0.8846\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2979 - accuracy: 0.9118 - val_loss: 0.2667 - val_accuracy: 0.9232\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2317 - accuracy: 0.9382 - val_loss: 0.2121 - val_accuracy: 0.9442\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1806 - accuracy: 0.9555 - val_loss: 0.1756 - val_accuracy: 0.9506\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1471 - accuracy: 0.9645 - val_loss: 0.1365 - val_accuracy: 0.9661\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1153 - accuracy: 0.9736 - val_loss: 0.1181 - val_accuracy: 0.9668\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0983 - accuracy: 0.9771 - val_loss: 0.0924 - val_accuracy: 0.9776\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0791 - accuracy: 0.9828 - val_loss: 0.0755 - val_accuracy: 0.9823\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0629 - accuracy: 0.9870 - val_loss: 0.0672 - val_accuracy: 0.9822\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0553 - accuracy: 0.9880 - val_loss: 0.0586 - val_accuracy: 0.9843\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.9893 - val_loss: 0.0574 - val_accuracy: 0.9847\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0408 - accuracy: 0.9910 - val_loss: 0.0519 - val_accuracy: 0.9846\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0454 - accuracy: 0.9900 - val_loss: 0.2515 - val_accuracy: 0.9113\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.0348 - val_accuracy: 0.9908\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9957 - val_loss: 0.0321 - val_accuracy: 0.9915\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.0338 - val_accuracy: 0.9898\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.0226 - val_accuracy: 0.9944\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0248 - val_accuracy: 0.9934\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0178 - accuracy: 0.9961 - val_loss: 0.0206 - val_accuracy: 0.9943\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 0.0206 - val_accuracy: 0.9937\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.0316 - val_accuracy: 0.9891\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0349 - val_accuracy: 0.9892\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.0150 - val_accuracy: 0.9958\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.0148 - val_accuracy: 0.9966\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0103 - val_accuracy: 0.9972\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0146 - val_accuracy: 0.9951\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 0.0155 - val_accuracy: 0.9955\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0145 - val_accuracy: 0.9952\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0176 - val_accuracy: 0.9945\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0109 - val_accuracy: 0.9967\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0080 - val_accuracy: 0.9976\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.0318 - val_accuracy: 0.9902\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0094 - val_accuracy: 0.9969\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0090 - val_accuracy: 0.9976\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0099 - val_accuracy: 0.9969\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0593 - accuracy: 0.9829 - val_loss: 0.0187 - val_accuracy: 0.9947\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.0336 - val_accuracy: 0.9890\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9980\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0158 - val_accuracy: 0.9948\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0105 - val_accuracy: 0.9967\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9981\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0094 - val_accuracy: 0.9969\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0069 - val_accuracy: 0.9977\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9985\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0099 - val_accuracy: 0.9966\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0103 - val_accuracy: 0.9967\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0093 - val_accuracy: 0.9968\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0051 - val_accuracy: 0.9981\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9986\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0979 - val_accuracy: 0.9736\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9985\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0113 - val_accuracy: 0.9965\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0097 - val_accuracy: 0.9972\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0134 - val_accuracy: 0.9952\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0614 - val_accuracy: 0.9811\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 9.6100e-04 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0502 - val_accuracy: 0.9837\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9974\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0191 - val_accuracy: 0.9941\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0201 - val_accuracy: 0.9935\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.6634e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.6212e-04 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.1986e-04 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0207 - val_accuracy: 0.9926\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.8497e-04 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.1576e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.6086e-04 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0750 - val_accuracy: 0.9753\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.1739e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.7465e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.1168e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.4113e-04 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0167 - val_accuracy: 0.9947\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.2668e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.0832e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 0.9980\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9991\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.4281e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.1422e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.7824e-04 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0319 - val_accuracy: 0.9900\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.3432e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.2763e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.6721e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.8823e-04 - accuracy: 0.9999 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.7953e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0409 - val_accuracy: 0.9868\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.6628e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.9374e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.2982e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.4001e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.8966e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.4644e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.8955e-04 - accuracy: 0.9998 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0752 - val_accuracy: 0.9768\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.9855e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.4114e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.0536e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.8218e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.6898e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0359 - val_accuracy: 0.9886\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.1064e-04 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.3698e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.6987e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.7133e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.5234e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.1726e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.6382e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.0793e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0492 - val_accuracy: 0.9847\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0164 - val_accuracy: 0.9947\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.4373e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.0957e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.1690e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.7742e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.1745e-04 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0212 - val_accuracy: 0.9940\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.9425e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.2419e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.0403e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.8062e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0093 - val_accuracy: 0.9968\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.6046e-04 - accuracy: 1.0000 - val_loss: 9.0041e-04 - val_accuracy: 0.9998\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.2086e-04 - accuracy: 1.0000 - val_loss: 6.9085e-04 - val_accuracy: 0.9998\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.7567e-04 - accuracy: 1.0000 - val_loss: 6.5727e-04 - val_accuracy: 0.9999\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.6139e-04 - accuracy: 1.0000 - val_loss: 8.1388e-04 - val_accuracy: 0.9998\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.4746e-04 - accuracy: 1.0000 - val_loss: 6.6218e-04 - val_accuracy: 0.9998\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0250 - val_accuracy: 0.9923\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.3549e-04 - accuracy: 1.0000 - val_loss: 9.0763e-04 - val_accuracy: 0.9998\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.8031e-04 - accuracy: 1.0000 - val_loss: 8.0693e-04 - val_accuracy: 0.9998\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.5810e-04 - accuracy: 1.0000 - val_loss: 7.3736e-04 - val_accuracy: 0.9998\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.4790e-04 - accuracy: 1.0000 - val_loss: 7.4880e-04 - val_accuracy: 0.9998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XG5pI6-I3cxe",
        "outputId": "372f10c7-8fa7-425d-80dc-2857293e0845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"pairs\", reverse = False)\n",
        "score_lstm_pairs_plain = ultimate_errors(model, x_tst, y_tst, as_bit = False)\n",
        "results_digits_pair[\"LSTM_plain\"] = score_lstm_pairs_plain\n",
        "print(\"Accuracy:\", score_lstm_pairs_plain[0])\n",
        "print(\"MSE:     \", score_lstm_pairs_plain[1])\n",
        "print(\"MAE:     \", score_lstm_pairs_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.998212\n",
            "MSE:      4406.072874\n",
            "MAE:      0.697234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U_uaSSFL4Xu5"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-94ouzEFAhB",
        "colab_type": "code",
        "outputId": "df043442-fb8c-4da5-9e36-6c15c98ac6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.LSTM\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_LSTM_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_LSTM_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 128)               71680     \n",
            "_________________________________________________________________\n",
            "repeat_vector_6 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 4, 11)             1419      \n",
            "=================================================================\n",
            "Total params: 204,683\n",
            "Trainable params: 204,683\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7u9dD6NH4Xu6",
        "outputId": "aa8baa2e-865b-4604-a569-218032dd2fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_digits_pairs[\"LSTM_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.8279 - accuracy: 0.3344 - val_loss: 1.6205 - val_accuracy: 0.3970\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.4807 - accuracy: 0.4461 - val_loss: 1.3701 - val_accuracy: 0.4821\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.3244 - accuracy: 0.4994 - val_loss: 1.2856 - val_accuracy: 0.5106\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.2519 - accuracy: 0.5264 - val_loss: 1.2246 - val_accuracy: 0.5310\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1825 - accuracy: 0.5498 - val_loss: 1.1481 - val_accuracy: 0.5564\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1176 - accuracy: 0.5691 - val_loss: 1.0863 - val_accuracy: 0.5805\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0621 - accuracy: 0.5890 - val_loss: 1.0402 - val_accuracy: 0.5960\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0187 - accuracy: 0.6051 - val_loss: 1.0308 - val_accuracy: 0.5960\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9866 - accuracy: 0.6172 - val_loss: 0.9752 - val_accuracy: 0.6197\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9577 - accuracy: 0.6301 - val_loss: 0.9515 - val_accuracy: 0.6313\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9289 - accuracy: 0.6420 - val_loss: 0.9445 - val_accuracy: 0.6302\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9031 - accuracy: 0.6528 - val_loss: 0.8983 - val_accuracy: 0.6525\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8741 - accuracy: 0.6654 - val_loss: 0.8848 - val_accuracy: 0.6571\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8461 - accuracy: 0.6770 - val_loss: 0.8464 - val_accuracy: 0.6737\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8162 - accuracy: 0.6888 - val_loss: 0.8245 - val_accuracy: 0.6823\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7863 - accuracy: 0.7007 - val_loss: 0.7957 - val_accuracy: 0.6947\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7648 - accuracy: 0.7078 - val_loss: 0.7654 - val_accuracy: 0.7082\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7329 - accuracy: 0.7224 - val_loss: 0.7365 - val_accuracy: 0.7155\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6792 - accuracy: 0.7430 - val_loss: 0.6523 - val_accuracy: 0.7430\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5444 - accuracy: 0.7949 - val_loss: 0.4637 - val_accuracy: 0.8280\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3927 - accuracy: 0.8648 - val_loss: 0.3556 - val_accuracy: 0.8810\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2997 - accuracy: 0.9108 - val_loss: 0.2657 - val_accuracy: 0.9286\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2360 - accuracy: 0.9369 - val_loss: 0.2168 - val_accuracy: 0.9420\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1836 - accuracy: 0.9554 - val_loss: 0.1912 - val_accuracy: 0.9459\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1418 - accuracy: 0.9688 - val_loss: 0.1490 - val_accuracy: 0.9628\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1161 - accuracy: 0.9750 - val_loss: 0.1229 - val_accuracy: 0.9686\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0929 - accuracy: 0.9804 - val_loss: 0.0948 - val_accuracy: 0.9775\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0803 - accuracy: 0.9823 - val_loss: 0.0758 - val_accuracy: 0.9822\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0622 - accuracy: 0.9877 - val_loss: 0.0669 - val_accuracy: 0.9843\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0564 - accuracy: 0.9881 - val_loss: 0.0583 - val_accuracy: 0.9859\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0551 - accuracy: 0.9870 - val_loss: 0.0509 - val_accuracy: 0.9876\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9936 - val_loss: 0.0454 - val_accuracy: 0.9893\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9909 - val_loss: 0.0464 - val_accuracy: 0.9869\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9954 - val_loss: 0.0293 - val_accuracy: 0.9926\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9891 - val_loss: 0.0366 - val_accuracy: 0.9896\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.0377 - val_accuracy: 0.9886\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.0205 - val_accuracy: 0.9952\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.0260 - val_accuracy: 0.9927\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 0.0206 - val_accuracy: 0.9942\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0217 - val_accuracy: 0.9937\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 0.1023 - val_accuracy: 0.9633\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0149 - val_accuracy: 0.9962\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0136 - val_accuracy: 0.9967\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0135 - val_accuracy: 0.9968\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9915\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0133 - val_accuracy: 0.9963\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0652 - val_accuracy: 0.9798\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0095 - val_accuracy: 0.9977\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0109 - val_accuracy: 0.9966\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0176 - val_accuracy: 0.9941\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0281 - val_accuracy: 0.9900\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0101 - val_accuracy: 0.9971\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0199 - val_accuracy: 0.9936\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 0.9960\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0125 - val_accuracy: 0.9960\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0238 - val_accuracy: 0.9934\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0072 - val_accuracy: 0.9976\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.1299 - val_accuracy: 0.9586\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0077 - val_accuracy: 0.9976\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0148 - val_accuracy: 0.9955\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0209 - val_accuracy: 0.9937\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0105 - val_accuracy: 0.9969\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0549 - val_accuracy: 0.9823\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9977\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.0205 - val_accuracy: 0.9930\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0669 - val_accuracy: 0.9790\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0054 - val_accuracy: 0.9983\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9982\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0054 - val_accuracy: 0.9983\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0147 - val_accuracy: 0.9954\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0091 - val_accuracy: 0.9972\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0254 - val_accuracy: 0.9916\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0182 - val_accuracy: 0.9944\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0607 - val_accuracy: 0.9809\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0277 - val_accuracy: 0.9906\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0484 - val_accuracy: 0.9866\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0235 - val_accuracy: 0.9924\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.7935e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0178 - val_accuracy: 0.9945\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0057 - val_accuracy: 0.9978\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0024 - val_accuracy: 0.9992\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 7.9522e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.4708e-04 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0473 - val_accuracy: 0.9862\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.4435e-04 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.7402e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 9.2216e-04 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.0135 - val_accuracy: 0.9955\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.0767e-04 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.5998e-04 - accuracy: 0.9999 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.5916e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0937 - val_accuracy: 0.9711\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.4905e-04 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.6745e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.4615e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.8247e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0250 - val_accuracy: 0.9911\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0026 - val_accuracy: 0.9991\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.7027e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.3438e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.6360e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.7324e-04 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0343 - val_accuracy: 0.9894\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 9.5920e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.4509e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0221 - val_accuracy: 0.9938\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.0108e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.9078e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.5398e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.3678e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0343 - val_accuracy: 0.9886\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.0817e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.9794e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.2126e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.2449e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0700 - val_accuracy: 0.9794\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.0681e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.3953e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.7342e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.4749e-04 - accuracy: 1.0000 - val_loss: 9.3473e-04 - val_accuracy: 0.9998\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.9586e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.8011e-04 - accuracy: 1.0000 - val_loss: 9.3840e-04 - val_accuracy: 0.9998\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0281 - val_accuracy: 0.9905\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.2313e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.4433e-04 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.3349e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.6663e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.6999e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.5378e-04 - accuracy: 1.0000 - val_loss: 9.8338e-04 - val_accuracy: 0.9998\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.7429e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.3280e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.1554e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.7447e-04 - accuracy: 1.0000 - val_loss: 9.7144e-04 - val_accuracy: 0.9997\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.6073e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0172 - val_accuracy: 0.9947\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 3.4980e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.7776e-04 - accuracy: 1.0000 - val_loss: 9.8712e-04 - val_accuracy: 0.9998\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.5544e-04 - accuracy: 1.0000 - val_loss: 9.3873e-04 - val_accuracy: 0.9998\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.2378e-04 - accuracy: 1.0000 - val_loss: 8.8168e-04 - val_accuracy: 0.9998\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.1548e-04 - accuracy: 1.0000 - val_loss: 7.9194e-04 - val_accuracy: 0.9998\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 2.1705e-04 - accuracy: 1.0000 - val_loss: 9.0965e-04 - val_accuracy: 0.9997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvWKKKAvfIVz",
        "colab_type": "code",
        "outputId": "4089abfe-1b57-4fe3-b6fc-1d441ceda812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"pairs\", reverse = True)\n",
        "score_lstm_pairs_reverse = ultimate_errors(model, x_train_rev, y_train_rev, as_bit = False)\n",
        "results_digits_pair[\"LSTM_rev\"] = score_lstm_pairs_reverse\n",
        "print(\"Accuracy:\", score_lstm_pairs_reverse[0])\n",
        "print(\"MSE:     \", score_lstm_pairs_reverse[1])\n",
        "print(\"MAE:     \", score_lstm_pairs_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.9998888888888889\n",
            "MSE:      0.0023777777777777777\n",
            "MAE:      0.0003333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVnjhWkg43dZ"
      },
      "source": [
        "### Model: SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czjra1zo43dZ",
        "outputId": "f57798ef-811b-41b5-ce92-df16366ab2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.SimpleRNN \n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_SimpleRNN_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_SimpleRNN_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_4 (SimpleRNN)     (None, 128)               17920     \n",
            "_________________________________________________________________\n",
            "repeat_vector_7 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 4, 128)            32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 4, 11)             1419      \n",
            "=================================================================\n",
            "Total params: 52,235\n",
            "Trainable params: 52,235\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WMhZJCo643dd"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LM5-kvSw43dd",
        "outputId": "78714d8b-d147-446d-90e1-1d19b2613099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "\n",
        "histories_digits_pairs[\"SimpleRNN_plain\"] = history\n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.5694 - accuracy: 0.4204 - val_loss: 1.3651 - val_accuracy: 0.4884\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.2499 - accuracy: 0.5391 - val_loss: 1.1269 - val_accuracy: 0.5816\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.0231 - accuracy: 0.6218 - val_loss: 0.9476 - val_accuracy: 0.6539\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.8785 - accuracy: 0.6777 - val_loss: 0.7898 - val_accuracy: 0.7034\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6256 - accuracy: 0.7723 - val_loss: 0.4973 - val_accuracy: 0.8281\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.4183 - accuracy: 0.8667 - val_loss: 0.4013 - val_accuracy: 0.8588\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3087 - accuracy: 0.9108 - val_loss: 0.2557 - val_accuracy: 0.9322\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2251 - accuracy: 0.9416 - val_loss: 0.2271 - val_accuracy: 0.9307\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1790 - accuracy: 0.9535 - val_loss: 0.2157 - val_accuracy: 0.9294\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1455 - accuracy: 0.9629 - val_loss: 0.1332 - val_accuracy: 0.9660\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1177 - accuracy: 0.9705 - val_loss: 0.1261 - val_accuracy: 0.9636\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1042 - accuracy: 0.9729 - val_loss: 0.1022 - val_accuracy: 0.9713\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0871 - accuracy: 0.9782 - val_loss: 0.0968 - val_accuracy: 0.9726\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0789 - accuracy: 0.9791 - val_loss: 0.0734 - val_accuracy: 0.9797\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0783 - accuracy: 0.9777 - val_loss: 0.0737 - val_accuracy: 0.9782\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0556 - accuracy: 0.9865 - val_loss: 0.0794 - val_accuracy: 0.9754\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0488 - accuracy: 0.9887 - val_loss: 0.0635 - val_accuracy: 0.9810\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0609 - accuracy: 0.9828 - val_loss: 0.0563 - val_accuracy: 0.9834\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0482 - accuracy: 0.9872 - val_loss: 0.1462 - val_accuracy: 0.9467\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0347 - accuracy: 0.9915 - val_loss: 0.0438 - val_accuracy: 0.9879\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0455 - accuracy: 0.9869 - val_loss: 0.0359 - val_accuracy: 0.9895\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0404 - accuracy: 0.9888 - val_loss: 0.0327 - val_accuracy: 0.9908\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0356 - accuracy: 0.9901 - val_loss: 0.0500 - val_accuracy: 0.9829\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0269 - accuracy: 0.9932 - val_loss: 0.0311 - val_accuracy: 0.9909\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 0.0257 - val_accuracy: 0.9930\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.0335 - val_accuracy: 0.9892\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 0.0320 - val_accuracy: 0.9893\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.0225 - val_accuracy: 0.9937\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.0492 - val_accuracy: 0.9839\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.0784 - val_accuracy: 0.9743\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 0.0187 - val_accuracy: 0.9942\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0154 - val_accuracy: 0.9962\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0473 - val_accuracy: 0.9841\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0217 - accuracy: 0.9940 - val_loss: 0.0160 - val_accuracy: 0.9948\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.0811 - val_accuracy: 0.9736\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0129 - val_accuracy: 0.9965\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.0155 - val_accuracy: 0.9954\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0246 - val_accuracy: 0.9926\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0177 - val_accuracy: 0.9950\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0185 - val_accuracy: 0.9942\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.0270 - val_accuracy: 0.9906\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0532 - accuracy: 0.9841 - val_loss: 0.0159 - val_accuracy: 0.9954\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0145 - val_accuracy: 0.9962\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0213 - val_accuracy: 0.9929\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.0261 - val_accuracy: 0.9915\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0107 - val_accuracy: 0.9971\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.0247 - val_accuracy: 0.9924\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0136 - val_accuracy: 0.9967\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0880 - val_accuracy: 0.9703\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9978\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9899 - val_loss: 0.0578 - val_accuracy: 0.9801\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0100 - val_accuracy: 0.9972\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0169 - val_accuracy: 0.9942\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0376 - val_accuracy: 0.9886\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0476 - val_accuracy: 0.9839\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0132 - val_accuracy: 0.9958\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0118 - val_accuracy: 0.9960\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0104 - val_accuracy: 0.9966\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0595 - val_accuracy: 0.9790\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.0115 - val_accuracy: 0.9963\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0126 - val_accuracy: 0.9965\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0091 - val_accuracy: 0.9976\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 0.1164 - val_accuracy: 0.9658\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0082 - val_accuracy: 0.9982\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0089 - val_accuracy: 0.9975\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0519 - val_accuracy: 0.9832\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.0135 - val_accuracy: 0.9958\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0099 - val_accuracy: 0.9967\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0329 - accuracy: 0.9898 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0136 - val_accuracy: 0.9955\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 0.0108 - val_accuracy: 0.9969\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9977\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0400 - accuracy: 0.9882 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0091 - val_accuracy: 0.9971\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.2846 - val_accuracy: 0.9358\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0082 - val_accuracy: 0.9974\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0109 - val_accuracy: 0.9971\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0061 - val_accuracy: 0.9983\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0076 - val_accuracy: 0.9976\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.0412 - val_accuracy: 0.9858\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0178 - val_accuracy: 0.9939\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0102 - val_accuracy: 0.9972\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0298 - val_accuracy: 0.9899\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0199 - val_accuracy: 0.9934\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0164 - val_accuracy: 0.9943\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.0405 - val_accuracy: 0.9859\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9986\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0598 - accuracy: 0.9823 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9988\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0458 - accuracy: 0.9862 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.0113 - val_accuracy: 0.9967\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0107 - val_accuracy: 0.9966\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.0144 - val_accuracy: 0.9954\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9981\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.0380 - val_accuracy: 0.9887\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0947 - val_accuracy: 0.9714\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.5222e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.7508e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.5477e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0663 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9963\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0066 - val_accuracy: 0.9981\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.6476e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.9597e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.0361 - val_accuracy: 0.9883\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0117 - val_accuracy: 0.9963\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0058 - val_accuracy: 0.9986\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.9379e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.8134e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.3304e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.4344e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0582 - accuracy: 0.9835 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.4286e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.3092e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.6861e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.1585e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.2007 - val_accuracy: 0.9477\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0697 - accuracy: 0.9806 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 7.5482e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 8s 23ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0081 - val_accuracy: 0.9976\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.0803 - val_accuracy: 0.9756\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.5016e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.0772e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 5.4497e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.1266e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.8179e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.0404 - val_accuracy: 0.9878\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.2856e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.8447e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 5.3947e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.9362e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.3725e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0555 - accuracy: 0.9847 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0165 - val_accuracy: 0.9948\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.8524e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.3542e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.6111e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0107 - val_accuracy: 0.9970\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.3508e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.3656e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.8940e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 4.4521e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 3.9978e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 4.3764e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JHoLMuq443dh",
        "outputId": "e42b0022-81f2-45c1-edcc-74863e52cce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"pairs\", reverse = False)\n",
        "score_simplernn_pairs_plain = ultimate_errors(model, x_tst, y_tst, as_bit = False)\n",
        "results_digits_pair[\"SimpleRNN_plain\"] = score_simplernn_pairs_plain\n",
        "print(\"Accuracy:\", score_simplernn_pairs_plain[0])\n",
        "print(\"MSE:     \", score_simplernn_pairs_plain[1])\n",
        "print(\"MAE:     \", score_simplernn_pairs_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.996088\n",
            "MSE:      981.009201\n",
            "MAE:      0.331211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8VsnAQIx43dj"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI-PHk0nkzYy",
        "colab_type": "code",
        "outputId": "8648ad5f-d387-40ab-a2c8-c1874b1477ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# rebuilt the model\n",
        "model = Sequential(name = \"model_SimpleRNN_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_SimpleRNN_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_6 (SimpleRNN)     (None, 128)               17920     \n",
            "_________________________________________________________________\n",
            "repeat_vector_8 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_7 (SimpleRNN)     (None, 4, 128)            32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 4, 11)             1419      \n",
            "=================================================================\n",
            "Total params: 52,235\n",
            "Trainable params: 52,235\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIJHBIN143dj",
        "outputId": "156850d8-03ab-4fb8-a571-732b0c5711da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "\n",
        "histories_digits_pairs[\"SimpleRNN_rev\"] = history\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 4s 11ms/step - loss: 1.5704 - accuracy: 0.4213 - val_loss: 1.3579 - val_accuracy: 0.4991\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.2487 - accuracy: 0.5386 - val_loss: 1.1327 - val_accuracy: 0.5818\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 1.0418 - accuracy: 0.6133 - val_loss: 0.9760 - val_accuracy: 0.6371\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.9031 - accuracy: 0.6679 - val_loss: 0.8325 - val_accuracy: 0.6906\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.6758 - accuracy: 0.7535 - val_loss: 0.5495 - val_accuracy: 0.7963\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.4367 - accuracy: 0.8544 - val_loss: 0.3856 - val_accuracy: 0.8684\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.3073 - accuracy: 0.9103 - val_loss: 0.2905 - val_accuracy: 0.9058\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.2267 - accuracy: 0.9388 - val_loss: 0.2173 - val_accuracy: 0.9345\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1787 - accuracy: 0.9517 - val_loss: 0.1672 - val_accuracy: 0.9520\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1400 - accuracy: 0.9632 - val_loss: 0.1442 - val_accuracy: 0.9568\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1147 - accuracy: 0.9703 - val_loss: 0.1182 - val_accuracy: 0.9667\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1013 - accuracy: 0.9724 - val_loss: 0.0934 - val_accuracy: 0.9743\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0869 - accuracy: 0.9763 - val_loss: 0.0841 - val_accuracy: 0.9753\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0876 - accuracy: 0.9739 - val_loss: 0.0937 - val_accuracy: 0.9711\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0635 - accuracy: 0.9836 - val_loss: 0.0595 - val_accuracy: 0.9843\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0573 - accuracy: 0.9849 - val_loss: 0.0581 - val_accuracy: 0.9826\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0712 - accuracy: 0.9780 - val_loss: 0.0964 - val_accuracy: 0.9671\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0473 - accuracy: 0.9879 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 0.9848\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0424 - accuracy: 0.9881 - val_loss: 0.0488 - val_accuracy: 0.9853\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.0351 - val_accuracy: 0.9906\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9899 - val_loss: 0.0616 - val_accuracy: 0.9792\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.0422 - val_accuracy: 0.9864\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0309 - val_accuracy: 0.9912\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 0.1056 - val_accuracy: 0.9657\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0405 - accuracy: 0.9875 - val_loss: 0.0230 - val_accuracy: 0.9938\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.0789 - val_accuracy: 0.9713\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.0227 - val_accuracy: 0.9938\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0169 - accuracy: 0.9965 - val_loss: 0.0193 - val_accuracy: 0.9949\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.0330 - val_accuracy: 0.9893\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.0492 - val_accuracy: 0.9851\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.0766 - val_accuracy: 0.9733\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0243 - val_accuracy: 0.9930\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.0265 - val_accuracy: 0.9913\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0537 - accuracy: 0.9818 - val_loss: 0.0301 - val_accuracy: 0.9904\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0195 - val_accuracy: 0.9941\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0161 - val_accuracy: 0.9952\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0524 - accuracy: 0.9840 - val_loss: 0.0226 - val_accuracy: 0.9937\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.0139 - val_accuracy: 0.9967\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0388 - val_accuracy: 0.9876\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0366 - accuracy: 0.9877 - val_loss: 0.0242 - val_accuracy: 0.9926\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0335 - accuracy: 0.9895 - val_loss: 0.0594 - val_accuracy: 0.9798\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.0175 - val_accuracy: 0.9952\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0133 - val_accuracy: 0.9963\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.1332 - val_accuracy: 0.9525\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.0120 - val_accuracy: 0.9966\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0154 - val_accuracy: 0.9949\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.0304 - val_accuracy: 0.9899\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.0167 - val_accuracy: 0.9948\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0122 - val_accuracy: 0.9963\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0309 - val_accuracy: 0.9895\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0113 - val_accuracy: 0.9970\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0289 - val_accuracy: 0.9908\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.0122 - val_accuracy: 0.9967\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0102 - val_accuracy: 0.9972\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0118 - val_accuracy: 0.9962\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0099 - val_accuracy: 0.9974\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0941 - val_accuracy: 0.9689\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.0101 - val_accuracy: 0.9972\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0100 - val_accuracy: 0.9969\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0521 - val_accuracy: 0.9827\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0196 - val_accuracy: 0.9934\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0105 - val_accuracy: 0.9969\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0135 - val_accuracy: 0.9962\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0397 - accuracy: 0.9876 - val_loss: 0.0162 - val_accuracy: 0.9955\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0757 - val_accuracy: 0.9742\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0104 - val_accuracy: 0.9971\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0591 - val_accuracy: 0.9807\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0359 - accuracy: 0.9889 - val_loss: 0.0511 - val_accuracy: 0.9816\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0063 - val_accuracy: 0.9987\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0088 - val_accuracy: 0.9974\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0380 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0082 - val_accuracy: 0.9974\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0586 - accuracy: 0.9821 - val_loss: 0.0370 - val_accuracy: 0.9882\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.0094 - val_accuracy: 0.9973\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0127 - val_accuracy: 0.9965\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.0201 - val_accuracy: 0.9937\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0056 - val_accuracy: 0.9985\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.0132 - val_accuracy: 0.9959\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.0362 - val_accuracy: 0.9876\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0069 - val_accuracy: 0.9979\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 0.0178 - val_accuracy: 0.9945\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0076 - val_accuracy: 0.9979\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0251 - val_accuracy: 0.9927\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.0079 - val_accuracy: 0.9977\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0093 - val_accuracy: 0.9973\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0246 - val_accuracy: 0.9923\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 0.0093 - val_accuracy: 0.9972\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0524 - accuracy: 0.9845 - val_loss: 0.0157 - val_accuracy: 0.9951\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0742 - val_accuracy: 0.9762\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9974\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.0209 - val_accuracy: 0.9944\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.9684e-04 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0108 - val_accuracy: 0.9965\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0144 - val_accuracy: 0.9952\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.8657e-04 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 9.8135e-04 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.0209 - val_accuracy: 0.9927\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0126 - val_accuracy: 0.9959\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0539 - val_accuracy: 0.9828\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.7418e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0526 - val_accuracy: 0.9813\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0070 - val_accuracy: 0.9975\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 8.7189e-04 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.8271e-04 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.0081 - val_accuracy: 0.9977\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 8.4327e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.8977e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.1212 - val_accuracy: 0.9603\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 8.2437e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 7.1045e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.0107 - val_accuracy: 0.9965\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0444 - val_accuracy: 0.9865\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 7.9642e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.4539e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.6382e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0509 - accuracy: 0.9857 - val_loss: 0.0095 - val_accuracy: 0.9975\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.0721e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.1453e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.7635e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.4367 - val_accuracy: 0.9023\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0100 - val_accuracy: 0.9970\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.8680e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 5.7623e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.8949e-04 - accuracy: 0.9999 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0510 - accuracy: 0.9847 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 7.5303e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.8370e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 5.2876e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.0353e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 6.1960e-04 - accuracy: 0.9999 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.0561 - accuracy: 0.9844 - val_loss: 0.0143 - val_accuracy: 0.9955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TmQq0W5C43dn",
        "outputId": "24bb87e1-5a96-4976-a6ce-017e3f610e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"pairs\", reverse = True)\n",
        "score_simplernn_pairs_reverse = ultimate_errors(model, x_val, y_val, as_bit = False)\n",
        "results_digits_pair[\"SimpleRNN_rev\"] = score_simplernn_pairs_reverse\n",
        "print(\"Accuracy:\", score_simplernn_pairs_reverse[0])\n",
        "print(\"MSE:     \", score_simplernn_pairs_reverse[1])\n",
        "print(\"MAE:     \", score_simplernn_pairs_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.065245\n",
            "MSE:      330220.078216\n",
            "MAE:      459.893404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rsl94KOL5aRe"
      },
      "source": [
        "### Model: GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exyQIzqB5aRf",
        "outputId": "1c8f09c0-9149-4161-e81c-e687c53d6c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.GRU\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_GRU_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# comile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_GRU_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_2 (GRU)                  (None, 128)               54144     \n",
            "_________________________________________________________________\n",
            "repeat_vector_9 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 4, 128)            99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 4, 11)             1419      \n",
            "=================================================================\n",
            "Total params: 154,635\n",
            "Trainable params: 154,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GGCye8vQ5aRi"
      },
      "source": [
        "#### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ouEgYurm5aRj",
        "outputId": "19060906-4edb-43c0-eed4-d3a38a79a03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_digits_pairs[\"GRU_plain\"] = history\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.8077 - accuracy: 0.3380 - val_loss: 1.6442 - val_accuracy: 0.3889\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.5077 - accuracy: 0.4370 - val_loss: 1.4351 - val_accuracy: 0.4530\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.3456 - accuracy: 0.4892 - val_loss: 1.3180 - val_accuracy: 0.5049\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.2853 - accuracy: 0.5084 - val_loss: 1.2609 - val_accuracy: 0.5178\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.2377 - accuracy: 0.5268 - val_loss: 1.2133 - val_accuracy: 0.5371\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1997 - accuracy: 0.5412 - val_loss: 1.1665 - val_accuracy: 0.5555\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1547 - accuracy: 0.5579 - val_loss: 1.1287 - val_accuracy: 0.5703\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1103 - accuracy: 0.5771 - val_loss: 1.1040 - val_accuracy: 0.5770\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0597 - accuracy: 0.5965 - val_loss: 1.0194 - val_accuracy: 0.6109\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0066 - accuracy: 0.6152 - val_loss: 1.0049 - val_accuracy: 0.6097\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9747 - accuracy: 0.6257 - val_loss: 0.9430 - val_accuracy: 0.6462\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9407 - accuracy: 0.6392 - val_loss: 0.9548 - val_accuracy: 0.6172\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9142 - accuracy: 0.6496 - val_loss: 0.8923 - val_accuracy: 0.6686\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8899 - accuracy: 0.6599 - val_loss: 0.8867 - val_accuracy: 0.6490\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8688 - accuracy: 0.6676 - val_loss: 0.8546 - val_accuracy: 0.6754\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8611 - accuracy: 0.6692 - val_loss: 0.8645 - val_accuracy: 0.6630\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8454 - accuracy: 0.6745 - val_loss: 0.8202 - val_accuracy: 0.6876\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8369 - accuracy: 0.6776 - val_loss: 0.8905 - val_accuracy: 0.6302\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8323 - accuracy: 0.6765 - val_loss: 0.8134 - val_accuracy: 0.6869\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8208 - accuracy: 0.6829 - val_loss: 0.8100 - val_accuracy: 0.6913\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8152 - accuracy: 0.6828 - val_loss: 0.8583 - val_accuracy: 0.6586\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8009 - accuracy: 0.6908 - val_loss: 0.8096 - val_accuracy: 0.6791\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7967 - accuracy: 0.6917 - val_loss: 0.8014 - val_accuracy: 0.6838\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7975 - accuracy: 0.6901 - val_loss: 0.8107 - val_accuracy: 0.6807\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7873 - accuracy: 0.6951 - val_loss: 0.7840 - val_accuracy: 0.6931\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7823 - accuracy: 0.6952 - val_loss: 0.7908 - val_accuracy: 0.6897\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7888 - accuracy: 0.6930 - val_loss: 0.7691 - val_accuracy: 0.7018\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7745 - accuracy: 0.6994 - val_loss: 0.7821 - val_accuracy: 0.6916\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7705 - accuracy: 0.7004 - val_loss: 0.7862 - val_accuracy: 0.6887\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7714 - accuracy: 0.6998 - val_loss: 0.8155 - val_accuracy: 0.6705\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7640 - accuracy: 0.7024 - val_loss: 0.7561 - val_accuracy: 0.7072\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7514 - accuracy: 0.7085 - val_loss: 0.7297 - val_accuracy: 0.7181\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7372 - accuracy: 0.7158 - val_loss: 0.7831 - val_accuracy: 0.6863\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7208 - accuracy: 0.7233 - val_loss: 0.7112 - val_accuracy: 0.7334\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7110 - accuracy: 0.7276 - val_loss: 0.6982 - val_accuracy: 0.7330\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6887 - accuracy: 0.7370 - val_loss: 0.6737 - val_accuracy: 0.7447\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6658 - accuracy: 0.7466 - val_loss: 0.7032 - val_accuracy: 0.7317\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6261 - accuracy: 0.7685 - val_loss: 0.6819 - val_accuracy: 0.7459\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6122 - accuracy: 0.7728 - val_loss: 0.5942 - val_accuracy: 0.7797\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5869 - accuracy: 0.7842 - val_loss: 0.5470 - val_accuracy: 0.8063\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5531 - accuracy: 0.7992 - val_loss: 0.5555 - val_accuracy: 0.7899\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5193 - accuracy: 0.8150 - val_loss: 0.6032 - val_accuracy: 0.7642\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5076 - accuracy: 0.8173 - val_loss: 0.4834 - val_accuracy: 0.8255\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4711 - accuracy: 0.8336 - val_loss: 0.5026 - val_accuracy: 0.8113\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4549 - accuracy: 0.8385 - val_loss: 0.4245 - val_accuracy: 0.8504\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4176 - accuracy: 0.8562 - val_loss: 0.3958 - val_accuracy: 0.8615\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4113 - accuracy: 0.8563 - val_loss: 0.4112 - val_accuracy: 0.8502\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3943 - accuracy: 0.8635 - val_loss: 0.4389 - val_accuracy: 0.8284\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3592 - accuracy: 0.8781 - val_loss: 0.3514 - val_accuracy: 0.8804\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3578 - accuracy: 0.8749 - val_loss: 0.3479 - val_accuracy: 0.8787\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3268 - accuracy: 0.8907 - val_loss: 0.3286 - val_accuracy: 0.8921\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3234 - accuracy: 0.8898 - val_loss: 0.3067 - val_accuracy: 0.8960\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3150 - accuracy: 0.8928 - val_loss: 0.3787 - val_accuracy: 0.8505\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3032 - accuracy: 0.8962 - val_loss: 0.3158 - val_accuracy: 0.8948\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2981 - accuracy: 0.8984 - val_loss: 0.2802 - val_accuracy: 0.9040\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2702 - accuracy: 0.9101 - val_loss: 0.2909 - val_accuracy: 0.8950\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2517 - accuracy: 0.9177 - val_loss: 0.2332 - val_accuracy: 0.9221\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2464 - accuracy: 0.9179 - val_loss: 0.2716 - val_accuracy: 0.9015\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2283 - accuracy: 0.9259 - val_loss: 0.2335 - val_accuracy: 0.9197\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2339 - accuracy: 0.9226 - val_loss: 0.2165 - val_accuracy: 0.9275\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2260 - accuracy: 0.9248 - val_loss: 0.2355 - val_accuracy: 0.9154\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2189 - accuracy: 0.9270 - val_loss: 0.2112 - val_accuracy: 0.9273\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1923 - accuracy: 0.9399 - val_loss: 0.1729 - val_accuracy: 0.9476\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2146 - accuracy: 0.9290 - val_loss: 0.2403 - val_accuracy: 0.9114\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1735 - accuracy: 0.9463 - val_loss: 0.1573 - val_accuracy: 0.9530\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1899 - accuracy: 0.9367 - val_loss: 0.1772 - val_accuracy: 0.9426\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1637 - accuracy: 0.9485 - val_loss: 0.1527 - val_accuracy: 0.9545\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1757 - accuracy: 0.9417 - val_loss: 0.1843 - val_accuracy: 0.9392\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1648 - accuracy: 0.9462 - val_loss: 0.1598 - val_accuracy: 0.9467\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1578 - accuracy: 0.9487 - val_loss: 0.1776 - val_accuracy: 0.9392\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1550 - accuracy: 0.9496 - val_loss: 0.1599 - val_accuracy: 0.9469\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1402 - accuracy: 0.9561 - val_loss: 0.1184 - val_accuracy: 0.9659\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1416 - accuracy: 0.9544 - val_loss: 0.2692 - val_accuracy: 0.9003\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1314 - accuracy: 0.9592 - val_loss: 0.1096 - val_accuracy: 0.9703\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1558 - accuracy: 0.9485 - val_loss: 0.1229 - val_accuracy: 0.9625\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1053 - accuracy: 0.9704 - val_loss: 0.1079 - val_accuracy: 0.9671\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1307 - accuracy: 0.9582 - val_loss: 0.1137 - val_accuracy: 0.9646\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1116 - accuracy: 0.9658 - val_loss: 0.1976 - val_accuracy: 0.9258\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1521 - accuracy: 0.9482 - val_loss: 0.1124 - val_accuracy: 0.9646\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1034 - accuracy: 0.9693 - val_loss: 0.1086 - val_accuracy: 0.9655\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1079 - accuracy: 0.9670 - val_loss: 0.1073 - val_accuracy: 0.9670\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1231 - accuracy: 0.9597 - val_loss: 0.0979 - val_accuracy: 0.9701\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1016 - accuracy: 0.9687 - val_loss: 0.0862 - val_accuracy: 0.9743\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0934 - accuracy: 0.9720 - val_loss: 0.1341 - val_accuracy: 0.9531\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1388 - accuracy: 0.9543 - val_loss: 0.0960 - val_accuracy: 0.9685\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0838 - accuracy: 0.9759 - val_loss: 0.0787 - val_accuracy: 0.9780\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1027 - accuracy: 0.9676 - val_loss: 0.0927 - val_accuracy: 0.9697\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0976 - accuracy: 0.9701 - val_loss: 0.1047 - val_accuracy: 0.9666\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1088 - accuracy: 0.9642 - val_loss: 0.1023 - val_accuracy: 0.9670\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0803 - accuracy: 0.9768 - val_loss: 0.1161 - val_accuracy: 0.9584\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0897 - accuracy: 0.9719 - val_loss: 0.0664 - val_accuracy: 0.9828\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0744 - accuracy: 0.9786 - val_loss: 0.1133 - val_accuracy: 0.9607\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1149 - accuracy: 0.9629 - val_loss: 0.0715 - val_accuracy: 0.9796\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0846 - accuracy: 0.9743 - val_loss: 0.0622 - val_accuracy: 0.9834\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0805 - accuracy: 0.9754 - val_loss: 0.1333 - val_accuracy: 0.9504\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1030 - accuracy: 0.9659 - val_loss: 0.2383 - val_accuracy: 0.9281\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0865 - accuracy: 0.9752 - val_loss: 0.0584 - val_accuracy: 0.9862\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0794 - accuracy: 0.9757 - val_loss: 0.0821 - val_accuracy: 0.9727\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0618 - accuracy: 0.9827 - val_loss: 0.0769 - val_accuracy: 0.9765\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1051 - accuracy: 0.9650 - val_loss: 0.0565 - val_accuracy: 0.9852\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0568 - accuracy: 0.9849 - val_loss: 0.0967 - val_accuracy: 0.9657\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1088 - accuracy: 0.9643 - val_loss: 0.0854 - val_accuracy: 0.9741\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0969 - accuracy: 0.9691 - val_loss: 0.2108 - val_accuracy: 0.9309\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0661 - accuracy: 0.9811 - val_loss: 0.0558 - val_accuracy: 0.9857\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0804 - accuracy: 0.9751 - val_loss: 0.0932 - val_accuracy: 0.9707\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0524 - accuracy: 0.9861 - val_loss: 0.0462 - val_accuracy: 0.9887\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0735 - accuracy: 0.9779 - val_loss: 0.1110 - val_accuracy: 0.9588\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0733 - accuracy: 0.9779 - val_loss: 0.0594 - val_accuracy: 0.9827\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0697 - accuracy: 0.9786 - val_loss: 0.1292 - val_accuracy: 0.9531\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.9821 - val_loss: 0.0602 - val_accuracy: 0.9796\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.1363 - val_accuracy: 0.9516\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0588 - accuracy: 0.9825 - val_loss: 0.0367 - val_accuracy: 0.9917\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.0482 - val_accuracy: 0.9869\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0701 - accuracy: 0.9780 - val_loss: 0.0622 - val_accuracy: 0.9787\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0830 - accuracy: 0.9754 - val_loss: 0.1335 - val_accuracy: 0.9519\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9884 - val_loss: 0.0348 - val_accuracy: 0.9921\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0844 - accuracy: 0.9739 - val_loss: 0.0667 - val_accuracy: 0.9779\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9893 - val_loss: 0.0355 - val_accuracy: 0.9911\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0703 - accuracy: 0.9776 - val_loss: 0.0662 - val_accuracy: 0.9776\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0621 - accuracy: 0.9811 - val_loss: 0.0497 - val_accuracy: 0.9847\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0480 - accuracy: 0.9856 - val_loss: 0.0630 - val_accuracy: 0.9787\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0935 - accuracy: 0.9692 - val_loss: 0.0363 - val_accuracy: 0.9916\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.0572 - val_accuracy: 0.9816\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0552 - accuracy: 0.9828 - val_loss: 0.1077 - val_accuracy: 0.9624\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.0392 - val_accuracy: 0.9885\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.9869 - val_loss: 0.0399 - val_accuracy: 0.9898\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0587 - accuracy: 0.9823 - val_loss: 0.1649 - val_accuracy: 0.9384\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0719 - accuracy: 0.9770 - val_loss: 0.0597 - val_accuracy: 0.9805\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0787 - accuracy: 0.9752 - val_loss: 0.0745 - val_accuracy: 0.9732\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0450 - accuracy: 0.9871 - val_loss: 0.0291 - val_accuracy: 0.9930\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 0.0394 - val_accuracy: 0.9873\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0743 - accuracy: 0.9748 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0628 - accuracy: 0.9806 - val_loss: 0.0345 - val_accuracy: 0.9919\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0274 - accuracy: 0.9938 - val_loss: 0.0407 - val_accuracy: 0.9878\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.2693 - val_accuracy: 0.9154\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0708 - accuracy: 0.9771 - val_loss: 0.0854 - val_accuracy: 0.9655\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9945 - val_loss: 0.0326 - val_accuracy: 0.9906\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0743 - accuracy: 0.9766 - val_loss: 0.0566 - val_accuracy: 0.9808\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0638 - accuracy: 0.9791 - val_loss: 0.0329 - val_accuracy: 0.9916\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9924 - val_loss: 0.0280 - val_accuracy: 0.9925\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0792 - accuracy: 0.9740 - val_loss: 0.0386 - val_accuracy: 0.9897\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9942 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.1422 - val_accuracy: 0.9517\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0874 - accuracy: 0.9700 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0281 - accuracy: 0.9924 - val_loss: 0.0405 - val_accuracy: 0.9880\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0297 - accuracy: 0.9918 - val_loss: 0.0332 - val_accuracy: 0.9900\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0851 - accuracy: 0.9729 - val_loss: 0.0323 - val_accuracy: 0.9898\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.0719 - val_accuracy: 0.9742\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 0.2852 - val_accuracy: 0.9265\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0409 - accuracy: 0.9881 - val_loss: 0.0248 - val_accuracy: 0.9933\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0704 - accuracy: 0.9782 - val_loss: 0.0589 - val_accuracy: 0.9793\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9951 - val_loss: 0.0245 - val_accuracy: 0.9929\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0715 - accuracy: 0.9761 - val_loss: 0.0380 - val_accuracy: 0.9894\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9894 - val_loss: 0.0269 - val_accuracy: 0.9922\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.0425 - val_accuracy: 0.9870\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 0.0709 - val_accuracy: 0.9751\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 0.0188 - val_accuracy: 0.9959\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0586 - val_accuracy: 0.9793\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0845 - accuracy: 0.9729 - val_loss: 0.0773 - val_accuracy: 0.9736\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.0275 - val_accuracy: 0.9902\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.0419 - val_accuracy: 0.9855\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0885 - accuracy: 0.9704 - val_loss: 0.1128 - val_accuracy: 0.9554\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.0274 - val_accuracy: 0.9913\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.0294 - val_accuracy: 0.9901\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0678 - accuracy: 0.9779 - val_loss: 0.0591 - val_accuracy: 0.9801\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.0234 - val_accuracy: 0.9925\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0719 - accuracy: 0.9751 - val_loss: 0.0526 - val_accuracy: 0.9834\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0179 - accuracy: 0.9963 - val_loss: 0.0280 - val_accuracy: 0.9909\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0790 - accuracy: 0.9742 - val_loss: 0.1129 - val_accuracy: 0.9552\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0362 - accuracy: 0.9897 - val_loss: 0.0186 - val_accuracy: 0.9956\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0642 - val_accuracy: 0.9794\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0535 - accuracy: 0.9822 - val_loss: 0.0339 - val_accuracy: 0.9899\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.0186 - val_accuracy: 0.9952\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0659 - accuracy: 0.9773 - val_loss: 0.0331 - val_accuracy: 0.9896\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.1012 - val_accuracy: 0.9691\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0520 - accuracy: 0.9834 - val_loss: 0.0243 - val_accuracy: 0.9933\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0265 - val_accuracy: 0.9920\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0700 - accuracy: 0.9780 - val_loss: 0.0347 - val_accuracy: 0.9880\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0258 - val_accuracy: 0.9911\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0681 - accuracy: 0.9778 - val_loss: 0.0600 - val_accuracy: 0.9768\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.0269 - val_accuracy: 0.9908\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0391 - accuracy: 0.9876 - val_loss: 0.0914 - val_accuracy: 0.9696\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9876 - val_loss: 0.0215 - val_accuracy: 0.9946\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.2900 - val_accuracy: 0.8987\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.0170 - val_accuracy: 0.9958\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 0.1034 - val_accuracy: 0.9651\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0433 - accuracy: 0.9856 - val_loss: 0.0616 - val_accuracy: 0.9774\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.0894 - val_accuracy: 0.9668\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0732 - accuracy: 0.9754 - val_loss: 0.0215 - val_accuracy: 0.9948\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0173 - val_accuracy: 0.9958\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.0634 - val_accuracy: 0.9779\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 0.0320 - val_accuracy: 0.9898\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.0371 - val_accuracy: 0.9882\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0467 - accuracy: 0.9850 - val_loss: 0.0537 - val_accuracy: 0.9822\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9935 - val_loss: 0.0325 - val_accuracy: 0.9890\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0572 - accuracy: 0.9831 - val_loss: 0.1381 - val_accuracy: 0.9470\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0332 - val_accuracy: 0.9886\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0597 - accuracy: 0.9802 - val_loss: 0.0174 - val_accuracy: 0.9959\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.0772 - val_accuracy: 0.9749\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0290 - val_accuracy: 0.9911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ezN5Nkpq5aRm",
        "outputId": "bd13cb4b-8d85-4ade-87a1-ab54d89110ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"pairs\", reverse = False)\n",
        "score_gru_pairs_plain = ultimate_errors(model, x_train_rev, y_train_rev, as_bit = False)\n",
        "results_digits_pair[\"GRU_plain\"] = score_gru_pairs_plain\n",
        "\n",
        "print(\"Accuracy:\", score_gru_pairs_plain[0])\n",
        "print(\"MSE:     \", score_gru_pairs_plain[1])\n",
        "print(\"MAE:     \", score_gru_pairs_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.9602\n",
            "MSE:      4720.947955555555\n",
            "MAE:      1.238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7rC-BQKkiqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rebuilt the model\n",
        "model = Sequential(name = \"model_GRU_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# comile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oty77xIS5aRp"
      },
      "source": [
        "#### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kn6Rt3RL5aRp",
        "outputId": "a307c80e-ab56-43f4-e652-771c163d86ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_digits_pairs[\"GRU_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.8093 - accuracy: 0.3356 - val_loss: 1.6538 - val_accuracy: 0.3768\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.4888 - accuracy: 0.4376 - val_loss: 1.3849 - val_accuracy: 0.4724\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.3439 - accuracy: 0.4859 - val_loss: 1.3175 - val_accuracy: 0.4956\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.2839 - accuracy: 0.5080 - val_loss: 1.2520 - val_accuracy: 0.5251\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.2333 - accuracy: 0.5274 - val_loss: 1.2312 - val_accuracy: 0.5278\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1843 - accuracy: 0.5471 - val_loss: 1.1505 - val_accuracy: 0.5598\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1299 - accuracy: 0.5664 - val_loss: 1.0911 - val_accuracy: 0.5799\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.0595 - accuracy: 0.5954 - val_loss: 1.0283 - val_accuracy: 0.6015\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9934 - accuracy: 0.6218 - val_loss: 0.9710 - val_accuracy: 0.6270\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9483 - accuracy: 0.6380 - val_loss: 0.9441 - val_accuracy: 0.6330\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.9108 - accuracy: 0.6535 - val_loss: 0.9061 - val_accuracy: 0.6521\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8857 - accuracy: 0.6628 - val_loss: 0.8948 - val_accuracy: 0.6510\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8618 - accuracy: 0.6731 - val_loss: 0.8513 - val_accuracy: 0.6765\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8370 - accuracy: 0.6824 - val_loss: 0.8462 - val_accuracy: 0.6776\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.8147 - accuracy: 0.6913 - val_loss: 0.8237 - val_accuracy: 0.6827\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7833 - accuracy: 0.7043 - val_loss: 0.7846 - val_accuracy: 0.6993\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.7177 - accuracy: 0.7323 - val_loss: 0.6718 - val_accuracy: 0.7544\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.6083 - accuracy: 0.7840 - val_loss: 0.5583 - val_accuracy: 0.8005\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5087 - accuracy: 0.8247 - val_loss: 0.4520 - val_accuracy: 0.8494\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.4141 - accuracy: 0.8658 - val_loss: 0.4046 - val_accuracy: 0.8632\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.3466 - accuracy: 0.8921 - val_loss: 0.3165 - val_accuracy: 0.9005\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2981 - accuracy: 0.9064 - val_loss: 0.2767 - val_accuracy: 0.9136\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2675 - accuracy: 0.9145 - val_loss: 0.2718 - val_accuracy: 0.9061\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2383 - accuracy: 0.9231 - val_loss: 0.2320 - val_accuracy: 0.9226\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.2169 - accuracy: 0.9301 - val_loss: 0.2051 - val_accuracy: 0.9322\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1971 - accuracy: 0.9360 - val_loss: 0.2287 - val_accuracy: 0.9192\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1882 - accuracy: 0.9375 - val_loss: 0.2155 - val_accuracy: 0.9223\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1766 - accuracy: 0.9407 - val_loss: 0.1797 - val_accuracy: 0.9368\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1545 - accuracy: 0.9493 - val_loss: 0.1742 - val_accuracy: 0.9398\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1490 - accuracy: 0.9505 - val_loss: 0.1555 - val_accuracy: 0.9470\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1411 - accuracy: 0.9522 - val_loss: 0.1587 - val_accuracy: 0.9444\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1630 - accuracy: 0.9438 - val_loss: 0.1402 - val_accuracy: 0.9499\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1144 - accuracy: 0.9626 - val_loss: 0.1315 - val_accuracy: 0.9537\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1317 - accuracy: 0.9550 - val_loss: 0.1485 - val_accuracy: 0.9477\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1106 - accuracy: 0.9623 - val_loss: 0.1133 - val_accuracy: 0.9610\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1097 - accuracy: 0.9625 - val_loss: 0.1080 - val_accuracy: 0.9657\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1061 - accuracy: 0.9636 - val_loss: 0.1172 - val_accuracy: 0.9569\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1055 - accuracy: 0.9633 - val_loss: 0.1143 - val_accuracy: 0.9565\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.1029 - accuracy: 0.9633 - val_loss: 0.1236 - val_accuracy: 0.9549\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0954 - accuracy: 0.9664 - val_loss: 0.0910 - val_accuracy: 0.9681\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0962 - accuracy: 0.9666 - val_loss: 0.0954 - val_accuracy: 0.9650\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0878 - accuracy: 0.9696 - val_loss: 0.0818 - val_accuracy: 0.9711\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0881 - accuracy: 0.9689 - val_loss: 0.0769 - val_accuracy: 0.9750\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0793 - accuracy: 0.9730 - val_loss: 0.1069 - val_accuracy: 0.9613\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0853 - accuracy: 0.9693 - val_loss: 0.0692 - val_accuracy: 0.9768\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0682 - accuracy: 0.9768 - val_loss: 0.0863 - val_accuracy: 0.9676\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0869 - accuracy: 0.9686 - val_loss: 0.0821 - val_accuracy: 0.9707\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0686 - accuracy: 0.9760 - val_loss: 0.0648 - val_accuracy: 0.9793\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0642 - accuracy: 0.9779 - val_loss: 0.0652 - val_accuracy: 0.9772\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0708 - accuracy: 0.9757 - val_loss: 0.0632 - val_accuracy: 0.9791\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0787 - accuracy: 0.9719 - val_loss: 0.0868 - val_accuracy: 0.9679\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0584 - accuracy: 0.9798 - val_loss: 0.0777 - val_accuracy: 0.9717\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0656 - accuracy: 0.9768 - val_loss: 0.1074 - val_accuracy: 0.9613\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0581 - accuracy: 0.9798 - val_loss: 0.0750 - val_accuracy: 0.9720\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 0.0457 - val_accuracy: 0.9845\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 0.0717 - val_accuracy: 0.9725\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0438 - accuracy: 0.9855 - val_loss: 0.0514 - val_accuracy: 0.9819\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0635 - accuracy: 0.9772 - val_loss: 0.0448 - val_accuracy: 0.9855\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9846 - val_loss: 0.0564 - val_accuracy: 0.9790\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0708 - accuracy: 0.9744 - val_loss: 0.0897 - val_accuracy: 0.9668\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9843 - val_loss: 0.0454 - val_accuracy: 0.9855\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9830 - val_loss: 0.0409 - val_accuracy: 0.9862\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0578 - accuracy: 0.9801 - val_loss: 0.0493 - val_accuracy: 0.9829\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.0386 - val_accuracy: 0.9884\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.0482 - val_accuracy: 0.9815\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0477 - accuracy: 0.9838 - val_loss: 0.0597 - val_accuracy: 0.9780\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9884 - val_loss: 0.0354 - val_accuracy: 0.9878\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0527 - accuracy: 0.9814 - val_loss: 0.0598 - val_accuracy: 0.9785\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 0.0395 - val_accuracy: 0.9848\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0365 - val_accuracy: 0.9857\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0543 - accuracy: 0.9816 - val_loss: 0.0442 - val_accuracy: 0.9850\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0263 - val_accuracy: 0.9917\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0347 - val_accuracy: 0.9876\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 0.0285 - val_accuracy: 0.9908\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0544 - val_accuracy: 0.9793\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.0330 - val_accuracy: 0.9880\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0433 - accuracy: 0.9851 - val_loss: 0.0558 - val_accuracy: 0.9794\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0235 - val_accuracy: 0.9926\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.0205 - val_accuracy: 0.9941\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.0238 - val_accuracy: 0.9921\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0470 - val_accuracy: 0.9837\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0208 - val_accuracy: 0.9930\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0180 - val_accuracy: 0.9949\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0422 - val_accuracy: 0.9855\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.0155 - val_accuracy: 0.9955\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0176 - val_accuracy: 0.9948\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0302 - val_accuracy: 0.9896\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0223 - val_accuracy: 0.9933\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 0.0112 - val_accuracy: 0.9971\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0150 - val_accuracy: 0.9954\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.0142 - val_accuracy: 0.9963\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0884 - val_accuracy: 0.9711\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0112 - val_accuracy: 0.9968\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0379 - val_accuracy: 0.9869\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0082 - val_accuracy: 0.9983\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0077 - val_accuracy: 0.9979\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.0268 - val_accuracy: 0.9905\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0081 - val_accuracy: 0.9976\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.0108 - val_accuracy: 0.9974\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0053 - val_accuracy: 0.9991\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0108 - val_accuracy: 0.9965\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0484 - accuracy: 0.9852 - val_loss: 0.0109 - val_accuracy: 0.9977\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0369 - val_accuracy: 0.9864\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9952 - val_loss: 0.1109 - val_accuracy: 0.9657\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0085 - val_accuracy: 0.9978\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0099 - val_accuracy: 0.9969\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0143 - val_accuracy: 0.9961\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0141 - val_accuracy: 0.9963\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0183 - val_accuracy: 0.9945\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0097 - val_accuracy: 0.9974\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9998\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.0670 - val_accuracy: 0.9780\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0046 - val_accuracy: 0.9990\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0136 - val_accuracy: 0.9961\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 9.9802e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0688 - val_accuracy: 0.9769\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 9.1029e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.7098e-04 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0370 - accuracy: 0.9916 - val_loss: 0.1086 - val_accuracy: 0.9640\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 0.9979\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0108 - val_accuracy: 0.9966\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 8.6427e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.1670e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0988 - val_accuracy: 0.9706\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.1491e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.6607e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.8491e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.9737e-04 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.0083 - val_accuracy: 0.9977\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 8.7015e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 6.8883e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.6378e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.7583e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.2089 - val_accuracy: 0.9439\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0070 - val_accuracy: 0.9977\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 9.2638e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 6.4532e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 5.3189e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.8468e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 5.1540e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0201 - val_accuracy: 0.9938\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.8123e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 4.9703e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.2596e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 4.0787e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0956 - val_accuracy: 0.9678\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 9.9786e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 7.9204e-04 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3nxvN_Jp5aRs",
        "outputId": "342e8e43-ef4f-4ea6-cc94-575b3989cbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"pairs\", reverse = True)\n",
        "score_gru_pairs_reverse = ultimate_errors(model, x_train_rev, y_train_rev, as_bit = False)\n",
        "results_digits_pair[\"GRU_rev\"] = score_gru_pairs_reverse\n",
        "print(\"Accuracy:\", score_gru_pairs_reverse[0])\n",
        "print(\"MSE:     \", score_gru_pairs_reverse[1])\n",
        "print(\"MAE:     \", score_gru_pairs_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1000000\n",
            "Accuracy: 0.9999555555555556\n",
            "MSE:      0.4444444444444444\n",
            "MAE:      0.0044444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DihQPWABla25",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFH4hRmzm2pG",
        "colab_type": "code",
        "outputId": "18d0ec2b-ff75-44e9-e111-4a5ef4dbf558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#Show results\n",
        "results_df = pd.DataFrame(results_digits_pair,\n",
        "                          index = [\"ACC\", \"MSE\", \"MAE\"])\n",
        "print(results_df.to_latex(float_format=\"%.3f\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrrr}\n",
            "\\toprule\n",
            "{} &  LSTM\\_plain &  LSTM\\_rev &  SimpleRNN\\_plain &  SimpleRNN\\_rev &  GRU\\_plain &  GRU\\_rev \\\\\n",
            "\\midrule\n",
            "ACC &       0.998 &     1.000 &            0.996 &          0.065 &      0.960 &    1.000 \\\\\n",
            "MSE &    4406.073 &     0.002 &          981.009 &     330220.078 &   4720.948 &    0.444 \\\\\n",
            "MAE &       0.697 &     0.000 &            0.331 &        459.893 &      1.238 &    0.004 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOzrIwZdm4tI",
        "colab_type": "code",
        "outputId": "02b1d595-1b50-412d-d597-5eb98461cd88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "#plot training\n",
        "fig, ax = plt.subplots()\n",
        "for key, item in histories_digits_pairs.items():\n",
        "    plt.plot(pd.DataFrame(item.history[\"val_accuracy\"]))\n",
        "\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.legend(histories_digits_pairs.keys())\n",
        "plt.title(\"Validation Accuracy while training \\n on the Representation of Integers as Pairs\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml8Va6eVIOpj",
        "colab_type": "text"
      },
      "source": [
        "# Task 4: Pairs of bits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXVeVnUdKV77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_SIZE = 5e4\n",
        "DIGITS = 3\n",
        "BITS = 10\n",
        "MAXLEN = BITS + BITS\n",
        "chars = '01'\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "results_bit_pairs, histories_bit_pairs = {}, {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mEoNIo2KK9J",
        "colab_type": "code",
        "outputId": "4810ed72-5e7e-4e11-c21c-8b504b133be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# generate plain data\n",
        "x_train_plain, x_val_plain, y_train_plain, y_val_plain = generate_bit_data(TRAINING_SIZE, DIGITS, BITS, as_pairs = True, reverse = False)\n",
        "\n",
        "# generate reverse data\n",
        "x_train_rev, x_val_rev, y_train_rev, y_val_rev = generate_bit_data(TRAINING_SIZE, DIGITS, BITS, as_pairs = True, reverse = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n",
            "Generating data...\n",
            "Total addition questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4s_Dy0PLfJo",
        "colab_type": "text"
      },
      "source": [
        "### Model: LSTM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_lt5rr-LmOs",
        "colab_type": "code",
        "outputId": "b360808a-8875-4868-d159-b128b9734e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.LSTM\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_LSTM_bit_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_LSTM_bit_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               67072     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 11, 128)           131584    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 11, 2)             258       \n",
            "=================================================================\n",
            "Total params: 198,914\n",
            "Trainable params: 198,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gY4NNyVLios",
        "colab_type": "text"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGcVBWCoLld9",
        "colab_type": "code",
        "outputId": "463918de-d6e0-4f92-d1d8-6754dfd8f32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "\n",
        "histories_bit_pairs[\"LSTM_plain\"] = history\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 9s 27ms/step - loss: 0.6011 - accuracy: 0.5928 - val_loss: 0.5422 - val_accuracy: 0.6364\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.5255 - accuracy: 0.6519 - val_loss: 0.4986 - val_accuracy: 0.6747\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4959 - accuracy: 0.6722 - val_loss: 0.4938 - val_accuracy: 0.6744\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4840 - accuracy: 0.6818 - val_loss: 0.4614 - val_accuracy: 0.6957\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4707 - accuracy: 0.6915 - val_loss: 0.4612 - val_accuracy: 0.6964\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4583 - accuracy: 0.6992 - val_loss: 0.4539 - val_accuracy: 0.7002\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4488 - accuracy: 0.7076 - val_loss: 0.4423 - val_accuracy: 0.7095\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4418 - accuracy: 0.7127 - val_loss: 0.4260 - val_accuracy: 0.7191\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4321 - accuracy: 0.7205 - val_loss: 0.4203 - val_accuracy: 0.7277\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4255 - accuracy: 0.7243 - val_loss: 0.4216 - val_accuracy: 0.7259\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4203 - accuracy: 0.7289 - val_loss: 0.4220 - val_accuracy: 0.7255\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.4157 - accuracy: 0.7319 - val_loss: 0.4127 - val_accuracy: 0.7336\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4048 - accuracy: 0.7404 - val_loss: 0.4040 - val_accuracy: 0.7421\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.4068 - accuracy: 0.7400 - val_loss: 0.4045 - val_accuracy: 0.7395\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.3960 - accuracy: 0.7475 - val_loss: 0.3826 - val_accuracy: 0.7533\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3949 - accuracy: 0.7499 - val_loss: 0.3843 - val_accuracy: 0.7521\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.3880 - accuracy: 0.7546 - val_loss: 0.3745 - val_accuracy: 0.7599\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3809 - accuracy: 0.7610 - val_loss: 0.3702 - val_accuracy: 0.7649\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3722 - accuracy: 0.7672 - val_loss: 0.3723 - val_accuracy: 0.7644\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3808 - accuracy: 0.7656 - val_loss: 0.3819 - val_accuracy: 0.7597\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.3642 - accuracy: 0.7751 - val_loss: 0.3583 - val_accuracy: 0.7759\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3571 - accuracy: 0.7793 - val_loss: 0.3500 - val_accuracy: 0.7848\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3525 - accuracy: 0.7835 - val_loss: 0.3406 - val_accuracy: 0.7856\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3414 - accuracy: 0.7927 - val_loss: 0.3440 - val_accuracy: 0.7918\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3397 - accuracy: 0.7946 - val_loss: 0.3438 - val_accuracy: 0.7883\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3287 - accuracy: 0.8031 - val_loss: 0.3439 - val_accuracy: 0.7973\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.3316 - accuracy: 0.8063 - val_loss: 0.3239 - val_accuracy: 0.8140\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3126 - accuracy: 0.8224 - val_loss: 0.3209 - val_accuracy: 0.8159\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.2967 - accuracy: 0.8403 - val_loss: 0.2762 - val_accuracy: 0.8553\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.2830 - accuracy: 0.8554 - val_loss: 0.4716 - val_accuracy: 0.7781\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.2587 - accuracy: 0.8658 - val_loss: 0.2521 - val_accuracy: 0.8703\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.2145 - accuracy: 0.8920 - val_loss: 0.2088 - val_accuracy: 0.8957\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1886 - accuracy: 0.9076 - val_loss: 0.1805 - val_accuracy: 0.9106\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1529 - accuracy: 0.9260 - val_loss: 0.1514 - val_accuracy: 0.9271\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1351 - accuracy: 0.9358 - val_loss: 0.1213 - val_accuracy: 0.9439\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1603 - accuracy: 0.9309 - val_loss: 0.2254 - val_accuracy: 0.8907\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.1151 - accuracy: 0.9474 - val_loss: 0.1075 - val_accuracy: 0.9508\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0886 - accuracy: 0.9600 - val_loss: 0.1115 - val_accuracy: 0.9478\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0832 - accuracy: 0.9628 - val_loss: 0.0815 - val_accuracy: 0.9633\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0711 - accuracy: 0.9687 - val_loss: 0.0696 - val_accuracy: 0.9694\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0751 - accuracy: 0.9681 - val_loss: 0.0689 - val_accuracy: 0.9703\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0571 - accuracy: 0.9761 - val_loss: 0.2892 - val_accuracy: 0.9255\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.0628 - accuracy: 0.9743 - val_loss: 0.0550 - val_accuracy: 0.9758\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0489 - accuracy: 0.9797 - val_loss: 0.0480 - val_accuracy: 0.9795\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0418 - accuracy: 0.9828 - val_loss: 0.0467 - val_accuracy: 0.9800\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0454 - accuracy: 0.9815 - val_loss: 0.0368 - val_accuracy: 0.9842\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0545 - accuracy: 0.9793 - val_loss: 0.0415 - val_accuracy: 0.9825\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0285 - accuracy: 0.9886 - val_loss: 0.0346 - val_accuracy: 0.9856\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0407 - accuracy: 0.9836 - val_loss: 0.0434 - val_accuracy: 0.9815\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0267 - accuracy: 0.9894 - val_loss: 0.0271 - val_accuracy: 0.9885\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0574 - accuracy: 0.9805 - val_loss: 0.0278 - val_accuracy: 0.9889\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0222 - accuracy: 0.9914 - val_loss: 0.0303 - val_accuracy: 0.9883\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0278 - accuracy: 0.9894 - val_loss: 0.0282 - val_accuracy: 0.9887\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0182 - accuracy: 0.9931 - val_loss: 0.0226 - val_accuracy: 0.9910\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.0199 - val_accuracy: 0.9925\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.0543 - val_accuracy: 0.9811\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.0229 - val_accuracy: 0.9906\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 0.0279 - val_accuracy: 0.9897\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0151 - val_accuracy: 0.9944\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.0780 - val_accuracy: 0.9722\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0141 - val_accuracy: 0.9950\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0151 - val_accuracy: 0.9946\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.0241 - val_accuracy: 0.9905\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 0.0195 - val_accuracy: 0.9924\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0378 - val_accuracy: 0.9878\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.0126 - val_accuracy: 0.9953\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0118 - val_accuracy: 0.9956\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0107 - val_accuracy: 0.9960\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0495 - accuracy: 0.9859 - val_loss: 0.0220 - val_accuracy: 0.9920\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0122 - val_accuracy: 0.9954\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0118 - val_accuracy: 0.9957\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0373 - val_accuracy: 0.9870\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0133 - val_accuracy: 0.9950\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0133 - val_accuracy: 0.9955\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0106 - val_accuracy: 0.9963\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0073 - val_accuracy: 0.9977\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0272 - val_accuracy: 0.9915\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0061 - val_accuracy: 0.9977\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0122 - val_accuracy: 0.9958\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0190 - val_accuracy: 0.9929\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0055 - val_accuracy: 0.9979\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0086 - val_accuracy: 0.9969\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0093 - val_accuracy: 0.9967\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0055 - val_accuracy: 0.9980\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 9.5274e-04 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0137 - val_accuracy: 0.9948\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0068 - val_accuracy: 0.9978\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0172 - val_accuracy: 0.9944\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 8.3391e-04 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.8938e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9969\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.0298 - val_accuracy: 0.9904\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 8.7092e-04 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.8702e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0204 - val_accuracy: 0.9932\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.4592e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.8196e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.0242e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.6668e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4258e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0227 - val_accuracy: 0.9915\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0043 - val_accuracy: 0.9986\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9990\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.6415e-04 - accuracy: 0.9999 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.2154e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.9506e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.4257e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9994\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1297e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.0527e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0377 - accuracy: 0.9895 - val_loss: 0.0087 - val_accuracy: 0.9972\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.4861e-04 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0095 - val_accuracy: 0.9967\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0068 - val_accuracy: 0.9978\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.3741e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 4.8671e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.8696e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2662e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 9.9306e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 7.9710e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.7070e-05 - accuracy: 1.0000 - val_loss: 9.5644e-04 - val_accuracy: 0.9997\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.5894e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.6837e-05 - accuracy: 1.0000 - val_loss: 9.7674e-04 - val_accuracy: 0.9997\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 3.9922e-05 - accuracy: 1.0000 - val_loss: 9.4590e-04 - val_accuracy: 0.9997\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.5242e-05 - accuracy: 1.0000 - val_loss: 9.7387e-04 - val_accuracy: 0.9997\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.8628e-05 - accuracy: 1.0000 - val_loss: 9.5475e-04 - val_accuracy: 0.9997\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.4201e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.0585e-05 - accuracy: 1.0000 - val_loss: 9.8812e-04 - val_accuracy: 0.9997\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.7647e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4812e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2714e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.4135e-04 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.6175e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.5333e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1190e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.6740e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.9449e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.6827e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.7095e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.9476e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.3374e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.8233e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.4048e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.0488e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.7455e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.5002e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2825e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.0916e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 9.3984e-06 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 7.9231e-06 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.7858e-06 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.7553e-06 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.8856e-06 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.2467e-06 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0229 - accuracy: 0.9960 - val_loss: 0.1798 - val_accuracy: 0.9461\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.0360e-04 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.4126e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0193 - val_accuracy: 0.9938\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.4526e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4111e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.6367e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.8219e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.9079e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.2436e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.7345e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.3168e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.9721e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.6881e-05 - accuracy: 1.0000 - val_loss: 9.8455e-04 - val_accuracy: 0.9997\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4415e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2363e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.0631e-05 - accuracy: 1.0000 - val_loss: 9.7766e-04 - val_accuracy: 0.9997\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 9.1022e-06 - accuracy: 1.0000 - val_loss: 9.9023e-04 - val_accuracy: 0.9997\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 7.8490e-06 - accuracy: 1.0000 - val_loss: 9.5346e-04 - val_accuracy: 0.9997\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.7433e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.7847e-06 - accuracy: 1.0000 - val_loss: 9.7516e-04 - val_accuracy: 0.9997\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 4.9551e-06 - accuracy: 1.0000 - val_loss: 9.4004e-04 - val_accuracy: 0.9997\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.2726e-06 - accuracy: 1.0000 - val_loss: 9.9150e-04 - val_accuracy: 0.9997\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.6768e-06 - accuracy: 1.0000 - val_loss: 9.7222e-04 - val_accuracy: 0.9997\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.1445e-06 - accuracy: 1.0000 - val_loss: 9.7568e-04 - val_accuracy: 0.9997\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.7047e-06 - accuracy: 1.0000 - val_loss: 9.9694e-04 - val_accuracy: 0.9997\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.3036e-06 - accuracy: 1.0000 - val_loss: 9.9673e-04 - val_accuracy: 0.9997\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.0039e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.7032e-06 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4524e-06 - accuracy: 1.0000 - val_loss: 9.9326e-04 - val_accuracy: 0.9996\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2565e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.0791e-06 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 9.2569e-07 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2g9_JO75Rmq8",
        "outputId": "395863ce-a39f-4ee1-90f2-60714170dac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"bitpairs\", reverse = False)\n",
        "score_lstm_bitpairs_plain = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bit_pairs[\"LSTM_plain\"] = score_lstm_bitpairs_plain\n",
        "print(\"Accuracy:\", score_lstm_bitpairs_plain[0])\n",
        "print(\"MSE:     \", score_lstm_bitpairs_plain[1])\n",
        "print(\"MAE:     \", score_lstm_bitpairs_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9872034124233537\n",
            "MSE:      15.382470050997153\n",
            "MAE:      0.26811583816597534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "diRND_62Sn9m"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAY-v_zqSA9D",
        "colab_type": "code",
        "outputId": "3b76b860-2bcc-452e-d20b-b1c1bdc3a6e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# built the model again to initialize weights\n",
        "model = Sequential(name = \"model_LSTM_bit_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_LSTM_bit_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               67072     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 11, 128)           131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 11, 2)             258       \n",
            "=================================================================\n",
            "Total params: 198,914\n",
            "Trainable params: 198,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XTywRYPBSn9m",
        "outputId": "c3279db8-9a16-43a2-bcce-0e33136141d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bit_pairs[\"LSTM_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 7s 20ms/step - loss: 0.5549 - accuracy: 0.6500 - val_loss: 0.4401 - val_accuracy: 0.7481\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3575 - accuracy: 0.8083 - val_loss: 0.2673 - val_accuracy: 0.8672\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.2140 - accuracy: 0.8968 - val_loss: 0.1574 - val_accuracy: 0.9263\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1259 - accuracy: 0.9434 - val_loss: 0.0891 - val_accuracy: 0.9618\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0679 - accuracy: 0.9720 - val_loss: 0.0528 - val_accuracy: 0.9791\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0424 - accuracy: 0.9836 - val_loss: 0.0345 - val_accuracy: 0.9872\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.0172 - val_accuracy: 0.9938\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.1854 - val_accuracy: 0.9444\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.8960e-04 - accuracy: 0.9999 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.2063e-04 - accuracy: 1.0000 - val_loss: 4.8521e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 2.3495e-04 - accuracy: 1.0000 - val_loss: 3.9796e-04 - val_accuracy: 0.9999\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4226e-04 - accuracy: 1.0000 - val_loss: 2.7852e-04 - val_accuracy: 0.9999\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 9.4659e-05 - accuracy: 1.0000 - val_loss: 2.0041e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 7.1280e-05 - accuracy: 1.0000 - val_loss: 1.9475e-04 - val_accuracy: 0.9999\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.6258e-05 - accuracy: 1.0000 - val_loss: 1.6707e-04 - val_accuracy: 0.9999\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.4327e-05 - accuracy: 1.0000 - val_loss: 1.5379e-04 - val_accuracy: 0.9999\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.5417e-05 - accuracy: 1.0000 - val_loss: 1.3678e-04 - val_accuracy: 0.9999\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.8258e-05 - accuracy: 1.0000 - val_loss: 1.0780e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.2890e-05 - accuracy: 1.0000 - val_loss: 1.0295e-04 - val_accuracy: 0.9999\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.8494e-05 - accuracy: 1.0000 - val_loss: 8.1184e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.5088e-05 - accuracy: 1.0000 - val_loss: 1.0164e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2186e-05 - accuracy: 1.0000 - val_loss: 8.5584e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.0011e-05 - accuracy: 1.0000 - val_loss: 5.4955e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.1619e-06 - accuracy: 1.0000 - val_loss: 6.6986e-05 - val_accuracy: 0.9999\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 6.7542e-06 - accuracy: 1.0000 - val_loss: 5.4018e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.5236e-06 - accuracy: 1.0000 - val_loss: 4.6157e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.5598e-06 - accuracy: 1.0000 - val_loss: 4.2650e-05 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.7717e-06 - accuracy: 1.0000 - val_loss: 3.6484e-05 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.0890e-06 - accuracy: 1.0000 - val_loss: 4.8895e-05 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 2.6088e-06 - accuracy: 1.0000 - val_loss: 3.2809e-05 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.1325e-06 - accuracy: 1.0000 - val_loss: 2.4295e-05 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.7702e-06 - accuracy: 1.0000 - val_loss: 2.9395e-05 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4765e-06 - accuracy: 1.0000 - val_loss: 3.4120e-05 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.2315e-06 - accuracy: 1.0000 - val_loss: 2.2718e-05 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.0337e-06 - accuracy: 1.0000 - val_loss: 1.2418e-05 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.7470e-07 - accuracy: 1.0000 - val_loss: 1.7397e-05 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 7.4155e-07 - accuracy: 1.0000 - val_loss: 2.9907e-05 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.2747e-07 - accuracy: 1.0000 - val_loss: 2.6314e-05 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.3549e-07 - accuracy: 1.0000 - val_loss: 1.4598e-05 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 4.5964e-07 - accuracy: 1.0000 - val_loss: 1.1310e-05 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.9875e-07 - accuracy: 1.0000 - val_loss: 1.1285e-05 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.5026e-07 - accuracy: 1.0000 - val_loss: 2.3024e-05 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 3.0852e-07 - accuracy: 1.0000 - val_loss: 5.5272e-06 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.7379e-07 - accuracy: 1.0000 - val_loss: 7.6989e-06 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.4539e-07 - accuracy: 1.0000 - val_loss: 6.0229e-06 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.2300e-07 - accuracy: 1.0000 - val_loss: 1.2236e-05 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.0394e-07 - accuracy: 1.0000 - val_loss: 7.7444e-06 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.8861e-07 - accuracy: 1.0000 - val_loss: 3.7269e-06 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.7618e-07 - accuracy: 1.0000 - val_loss: 9.2683e-06 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.6613e-07 - accuracy: 1.0000 - val_loss: 1.6949e-06 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.5728e-07 - accuracy: 1.0000 - val_loss: 5.2822e-06 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.5048e-07 - accuracy: 1.0000 - val_loss: 4.7384e-06 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4472e-07 - accuracy: 1.0000 - val_loss: 3.7227e-06 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.4019e-07 - accuracy: 1.0000 - val_loss: 3.4662e-06 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.3653e-07 - accuracy: 1.0000 - val_loss: 6.8943e-06 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.3360e-07 - accuracy: 1.0000 - val_loss: 5.3118e-06 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.3093e-07 - accuracy: 1.0000 - val_loss: 5.9154e-06 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2895e-07 - accuracy: 1.0000 - val_loss: 2.4220e-06 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2719e-07 - accuracy: 1.0000 - val_loss: 2.6933e-06 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.2584e-07 - accuracy: 1.0000 - val_loss: 1.6226e-06 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2469e-07 - accuracy: 1.0000 - val_loss: 8.1893e-07 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2380e-07 - accuracy: 1.0000 - val_loss: 1.4346e-06 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2305e-07 - accuracy: 1.0000 - val_loss: 2.5917e-06 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2239e-07 - accuracy: 1.0000 - val_loss: 1.9379e-06 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.2190e-07 - accuracy: 1.0000 - val_loss: 4.9174e-07 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2148e-07 - accuracy: 1.0000 - val_loss: 1.1938e-06 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2112e-07 - accuracy: 1.0000 - val_loss: 1.3476e-06 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2082e-07 - accuracy: 1.0000 - val_loss: 1.8090e-06 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2060e-07 - accuracy: 1.0000 - val_loss: 9.5405e-07 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.2039e-07 - accuracy: 1.0000 - val_loss: 4.6044e-07 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2022e-07 - accuracy: 1.0000 - val_loss: 5.7634e-07 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2007e-07 - accuracy: 1.0000 - val_loss: 7.8606e-07 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1997e-07 - accuracy: 1.0000 - val_loss: 8.4035e-07 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1986e-07 - accuracy: 1.0000 - val_loss: 4.7784e-07 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1979e-07 - accuracy: 1.0000 - val_loss: 9.7595e-07 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1971e-07 - accuracy: 1.0000 - val_loss: 6.1343e-07 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1964e-07 - accuracy: 1.0000 - val_loss: 2.8970e-07 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1959e-07 - accuracy: 1.0000 - val_loss: 1.0422e-06 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1954e-07 - accuracy: 1.0000 - val_loss: 3.2058e-07 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1952e-07 - accuracy: 1.0000 - val_loss: 5.5252e-07 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1947e-07 - accuracy: 1.0000 - val_loss: 5.8273e-07 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1944e-07 - accuracy: 1.0000 - val_loss: 3.5381e-07 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1942e-07 - accuracy: 1.0000 - val_loss: 4.3324e-07 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1939e-07 - accuracy: 1.0000 - val_loss: 4.3871e-07 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1939e-07 - accuracy: 1.0000 - val_loss: 5.9631e-07 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1936e-07 - accuracy: 1.0000 - val_loss: 3.2059e-07 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1935e-07 - accuracy: 1.0000 - val_loss: 2.2042e-07 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 1.1933e-07 - accuracy: 1.0000 - val_loss: 2.1308e-07 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1932e-07 - accuracy: 1.0000 - val_loss: 2.4491e-07 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1931e-07 - accuracy: 1.0000 - val_loss: 3.4314e-07 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1930e-07 - accuracy: 1.0000 - val_loss: 1.9205e-07 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1929e-07 - accuracy: 1.0000 - val_loss: 2.4746e-07 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1928e-07 - accuracy: 1.0000 - val_loss: 1.8299e-07 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1927e-07 - accuracy: 1.0000 - val_loss: 1.8124e-07 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1927e-07 - accuracy: 1.0000 - val_loss: 2.7234e-07 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1927e-07 - accuracy: 1.0000 - val_loss: 1.8999e-07 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1926e-07 - accuracy: 1.0000 - val_loss: 1.9759e-07 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1925e-07 - accuracy: 1.0000 - val_loss: 1.7735e-07 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1925e-07 - accuracy: 1.0000 - val_loss: 1.8957e-07 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1925e-07 - accuracy: 1.0000 - val_loss: 1.7249e-07 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1925e-07 - accuracy: 1.0000 - val_loss: 1.9687e-07 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1924e-07 - accuracy: 1.0000 - val_loss: 1.7925e-07 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1924e-07 - accuracy: 1.0000 - val_loss: 1.7304e-07 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1924e-07 - accuracy: 1.0000 - val_loss: 1.7358e-07 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1924e-07 - accuracy: 1.0000 - val_loss: 1.9934e-07 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.8402e-07 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.9507e-07 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 2.0289e-07 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 2.0463e-07 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1923e-07 - accuracy: 1.0000 - val_loss: 1.7480e-07 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 2.0898e-07 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.6802e-07 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 2.0884e-07 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.6201e-07 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 2.0138e-07 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.8401e-07 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 2.1337e-07 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.6897e-07 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.6299e-07 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.6810e-07 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.5242e-07 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 5s 16ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.7055e-07 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.6264e-07 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1922e-07 - accuracy: 1.0000 - val_loss: 1.7008e-07 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.7520e-07 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.7591e-07 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5349e-07 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5864e-07 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6125e-07 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5906e-07 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5013e-07 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5000e-07 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6311e-07 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5475e-07 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6440e-07 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4791e-07 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6602e-07 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5174e-07 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5713e-07 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5115e-07 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5302e-07 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6905e-07 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4862e-07 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5047e-07 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4720e-07 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6781e-07 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6739e-07 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4327e-07 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5837e-07 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5754e-07 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.7850e-07 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5537e-07 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4802e-07 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5394e-07 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5856e-07 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6715e-07 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4802e-07 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.7145e-07 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4251e-07 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5637e-07 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5668e-07 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6441e-07 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6789e-07 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6084e-07 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4497e-07 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5053e-07 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5502e-07 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5990e-07 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4635e-07 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5456e-07 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5357e-07 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5383e-07 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5415e-07 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5446e-07 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6139e-07 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6023e-07 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5717e-07 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6523e-07 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5066e-07 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5043e-07 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4954e-07 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4733e-07 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6135e-07 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5282e-07 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5362e-07 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4685e-07 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4693e-07 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5322e-07 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5200e-07 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6150e-07 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5241e-07 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4964e-07 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4809e-07 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5471e-07 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.5133e-07 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.6792e-07 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4898e-07 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.4915e-07 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ba1tcvgMSn9q",
        "outputId": "b2793ca1-de80-4cef-be0c-3c45e8390e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"bitpairs\", reverse = True)\n",
        "score_lstm_bitpairs_reverse = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bit_pairs[\"LSTM_rev\"] = score_lstm_bitpairs_reverse \n",
        "print(\"Accuracy:\", score_lstm_bitpairs_reverse[0])\n",
        "print(\"MSE:     \", score_lstm_bitpairs_reverse[1])\n",
        "print(\"MAE:     \", score_lstm_bitpairs_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9999904446030641\n",
            "MSE:      0.02056608082528052\n",
            "MAE:      0.00034303875000119444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o8wmNnT0SjQK"
      },
      "source": [
        "### Model: SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y1Su_EfWSjQL",
        "outputId": "e875849e-d69c-4543-f827-db76e66a9ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.SimpleRNN \n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_SimpleRNN_bit_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_SimpleRNN_bit_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               16768     \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 11, 128)           32896     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 11, 2)             258       \n",
            "=================================================================\n",
            "Total params: 49,922\n",
            "Trainable params: 49,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WvNc9riXSjQN"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P0EB7uIbSjQO",
        "outputId": "d44be021-f38f-41f8-b136-edc9279174bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bit_pairs[\"SimpleRNN_plain\"] = history\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 0.4818 - accuracy: 0.7155 - val_loss: 0.3596 - val_accuracy: 0.7985\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.2396 - accuracy: 0.8868 - val_loss: 0.1134 - val_accuracy: 0.9565\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 0.0616 - val_accuracy: 0.9803\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0217 - val_accuracy: 0.9929\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0136 - val_accuracy: 0.9955\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0076 - val_accuracy: 0.9974\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0077 - val_accuracy: 0.9977\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0113 - val_accuracy: 0.9963\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0233 - val_accuracy: 0.9925\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 11s 33ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0079 - val_accuracy: 0.9975\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 11s 33ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 5.2885e-04 - val_accuracy: 0.9999\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 3.8269e-04 - val_accuracy: 0.9999\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9982\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.2407e-04 - accuracy: 0.9999 - val_loss: 3.4220e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.9183e-04 - accuracy: 1.0000 - val_loss: 1.5968e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.4648e-04 - accuracy: 1.0000 - val_loss: 3.8164e-04 - val_accuracy: 0.9999\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.0250e-04 - accuracy: 1.0000 - val_loss: 1.1566e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.2428e-04 - accuracy: 1.0000 - val_loss: 1.4026e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 7.1432e-04 - val_accuracy: 0.9998\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 7.5082e-04 - val_accuracy: 0.9998\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.4849e-04 - accuracy: 0.9999 - val_loss: 1.6697e-04 - val_accuracy: 0.9999\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 8.3049e-05 - accuracy: 1.0000 - val_loss: 6.2770e-05 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 4.4205e-05 - accuracy: 1.0000 - val_loss: 4.1153e-05 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 2.6612e-05 - accuracy: 1.0000 - val_loss: 3.1970e-05 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.7157e-05 - accuracy: 1.0000 - val_loss: 4.4969e-05 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.5565e-05 - accuracy: 1.0000 - val_loss: 2.4106e-05 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0040 - val_accuracy: 0.9989\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.2107e-04 - accuracy: 1.0000 - val_loss: 1.9882e-04 - val_accuracy: 0.9999\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.3629e-05 - accuracy: 1.0000 - val_loss: 9.7269e-05 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 5.3967e-05 - accuracy: 1.0000 - val_loss: 6.6238e-05 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.2869e-05 - accuracy: 1.0000 - val_loss: 4.9964e-05 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.7293e-05 - accuracy: 1.0000 - val_loss: 4.5481e-05 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0097 - val_accuracy: 0.9972\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 2.9449e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5514e-04 - accuracy: 1.0000 - val_loss: 1.1124e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.6430e-05 - accuracy: 1.0000 - val_loss: 7.9006e-05 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.1579e-05 - accuracy: 1.0000 - val_loss: 5.7199e-05 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 4.2491e-05 - accuracy: 1.0000 - val_loss: 4.6745e-05 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.8948e-05 - accuracy: 1.0000 - val_loss: 3.9873e-05 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.1549e-05 - accuracy: 1.0000 - val_loss: 3.2592e-05 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.8751e-05 - accuracy: 1.0000 - val_loss: 2.8760e-05 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.6602e-05 - accuracy: 1.0000 - val_loss: 2.8160e-05 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.2093e-05 - accuracy: 1.0000 - val_loss: 6.3068e-05 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 0.0140 - val_accuracy: 0.9956\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 4.0864e-04 - val_accuracy: 0.9999\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.4967e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 5.8727e-04 - val_accuracy: 0.9999\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0078 - val_accuracy: 0.9977\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 4.4905e-04 - val_accuracy: 0.9999\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.7188e-04 - accuracy: 0.9999 - val_loss: 1.4642e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 8.2062e-05 - accuracy: 1.0000 - val_loss: 8.5508e-05 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.3293e-05 - accuracy: 1.0000 - val_loss: 4.6622e-05 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.9820e-05 - accuracy: 1.0000 - val_loss: 3.6584e-05 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.2522e-05 - accuracy: 1.0000 - val_loss: 2.6253e-05 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.8060e-05 - accuracy: 1.0000 - val_loss: 2.3569e-05 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.4504e-05 - accuracy: 1.0000 - val_loss: 1.7547e-05 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.2126e-05 - accuracy: 1.0000 - val_loss: 1.3810e-05 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.0050e-05 - accuracy: 1.0000 - val_loss: 1.2029e-05 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 8.0497e-06 - accuracy: 1.0000 - val_loss: 1.9150e-05 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.9305e-06 - accuracy: 1.0000 - val_loss: 2.1431e-05 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 7.4469e-06 - accuracy: 1.0000 - val_loss: 9.3192e-06 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.7329e-06 - accuracy: 1.0000 - val_loss: 1.1112e-05 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.6899e-06 - accuracy: 1.0000 - val_loss: 5.2612e-06 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 14s 39ms/step - loss: 3.1267e-06 - accuracy: 1.0000 - val_loss: 5.1227e-06 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 2.5956e-06 - accuracy: 1.0000 - val_loss: 4.6824e-06 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.2184e-06 - accuracy: 1.0000 - val_loss: 5.1222e-06 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.4203e-06 - accuracy: 1.0000 - val_loss: 8.2229e-06 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.7918e-06 - accuracy: 1.0000 - val_loss: 5.5749e-06 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 9.0987e-04 - accuracy: 0.9998 - val_loss: 2.5653e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5865e-04 - accuracy: 1.0000 - val_loss: 2.5452e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 8.0194e-05 - accuracy: 1.0000 - val_loss: 7.2387e-05 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 4.5044e-05 - accuracy: 1.0000 - val_loss: 5.9923e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.0975e-05 - accuracy: 1.0000 - val_loss: 4.6640e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.3823e-05 - accuracy: 1.0000 - val_loss: 3.9608e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.8607e-05 - accuracy: 1.0000 - val_loss: 3.7813e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5184e-05 - accuracy: 1.0000 - val_loss: 4.5728e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.2371e-05 - accuracy: 1.0000 - val_loss: 2.7151e-05 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.0148e-05 - accuracy: 1.0000 - val_loss: 2.8608e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 8.5212e-06 - accuracy: 1.0000 - val_loss: 2.0888e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.1327e-06 - accuracy: 1.0000 - val_loss: 1.1365e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.9323e-06 - accuracy: 1.0000 - val_loss: 1.0502e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.9072e-06 - accuracy: 1.0000 - val_loss: 1.0472e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.1392e-06 - accuracy: 1.0000 - val_loss: 1.5199e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.3630e-06 - accuracy: 1.0000 - val_loss: 1.0107e-05 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0268 - accuracy: 0.9930 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 4.6003e-04 - val_accuracy: 0.9999\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.2624e-04 - accuracy: 0.9999 - val_loss: 3.3554e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 9.7921e-04 - accuracy: 0.9998 - val_loss: 1.5651e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 5.9942e-04 - val_accuracy: 0.9999\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5120e-04 - accuracy: 1.0000 - val_loss: 1.1749e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 11s 33ms/step - loss: 7.2820e-05 - accuracy: 1.0000 - val_loss: 6.0305e-05 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.4494e-05 - accuracy: 1.0000 - val_loss: 4.0040e-05 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.5092e-05 - accuracy: 1.0000 - val_loss: 3.7786e-05 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.8340e-05 - accuracy: 1.0000 - val_loss: 2.4764e-05 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.4763e-05 - accuracy: 1.0000 - val_loss: 2.0691e-05 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.1538e-05 - accuracy: 1.0000 - val_loss: 1.6118e-05 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.8050e-06 - accuracy: 1.0000 - val_loss: 1.4148e-05 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 7.9014e-06 - accuracy: 1.0000 - val_loss: 1.4752e-05 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.5337e-06 - accuracy: 1.0000 - val_loss: 9.0934e-06 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.4319e-06 - accuracy: 1.0000 - val_loss: 8.1469e-06 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 4.5392e-06 - accuracy: 1.0000 - val_loss: 7.1487e-06 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.7250e-06 - accuracy: 1.0000 - val_loss: 7.6534e-06 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.1438e-06 - accuracy: 1.0000 - val_loss: 6.1810e-06 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 8.6536e-04 - accuracy: 0.9998 - val_loss: 3.1727e-04 - val_accuracy: 0.9999\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.8623e-04 - accuracy: 0.9999 - val_loss: 4.8169e-04 - val_accuracy: 0.9999\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0093 - val_accuracy: 0.9976\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.7610e-04 - accuracy: 0.9999 - val_loss: 4.2983e-04 - val_accuracy: 0.9999\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.4976e-04 - accuracy: 1.0000 - val_loss: 1.6084e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.8474e-05 - accuracy: 1.0000 - val_loss: 1.3642e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.6044e-05 - accuracy: 1.0000 - val_loss: 1.4415e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.9331e-05 - accuracy: 1.0000 - val_loss: 1.5137e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.4992e-05 - accuracy: 1.0000 - val_loss: 1.5357e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.1996e-05 - accuracy: 1.0000 - val_loss: 1.5682e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 9.5793e-06 - accuracy: 1.0000 - val_loss: 1.5817e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.6926e-06 - accuracy: 1.0000 - val_loss: 1.5967e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 6.4289e-06 - accuracy: 1.0000 - val_loss: 1.6118e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.3074e-06 - accuracy: 1.0000 - val_loss: 1.6346e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.3870e-06 - accuracy: 1.0000 - val_loss: 1.6436e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.7731e-06 - accuracy: 1.0000 - val_loss: 1.6250e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.1367e-06 - accuracy: 1.0000 - val_loss: 1.6080e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.7717e-06 - accuracy: 1.0000 - val_loss: 1.6187e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.1561e-06 - accuracy: 1.0000 - val_loss: 1.5684e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.8792 - val_accuracy: 0.9186\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0248 - accuracy: 0.9946 - val_loss: 6.1690e-04 - val_accuracy: 0.9999\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.9402e-04 - accuracy: 1.0000 - val_loss: 4.5013e-04 - val_accuracy: 0.9999\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.1782e-04 - accuracy: 1.0000 - val_loss: 2.5366e-04 - val_accuracy: 0.9999\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.2104e-04 - accuracy: 1.0000 - val_loss: 9.9378e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 8.3511e-05 - accuracy: 1.0000 - val_loss: 1.2259e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 4.3890e-04 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.2524e-04 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.9193e-04 - accuracy: 1.0000 - val_loss: 8.4627e-05 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.2896e-04 - accuracy: 0.9999 - val_loss: 2.6521e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 9.2133e-05 - accuracy: 1.0000 - val_loss: 1.7422e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.8381e-05 - accuracy: 1.0000 - val_loss: 1.5011e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.4062e-05 - accuracy: 1.0000 - val_loss: 1.3133e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.5410e-05 - accuracy: 1.0000 - val_loss: 1.1542e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.0144e-05 - accuracy: 1.0000 - val_loss: 1.0379e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5423e-05 - accuracy: 1.0000 - val_loss: 8.7259e-05 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.2368e-05 - accuracy: 1.0000 - val_loss: 7.6436e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.0138e-05 - accuracy: 1.0000 - val_loss: 6.6514e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 8.1008e-06 - accuracy: 1.0000 - val_loss: 5.5307e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 6.7792e-06 - accuracy: 1.0000 - val_loss: 4.7015e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 5.4514e-06 - accuracy: 1.0000 - val_loss: 3.8837e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.4836e-06 - accuracy: 1.0000 - val_loss: 3.1479e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.8254e-06 - accuracy: 1.0000 - val_loss: 2.4251e-05 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.0778e-06 - accuracy: 1.0000 - val_loss: 1.8377e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.5710e-06 - accuracy: 1.0000 - val_loss: 1.4642e-05 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.1469e-06 - accuracy: 1.0000 - val_loss: 1.3038e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.7790e-06 - accuracy: 1.0000 - val_loss: 9.7951e-06 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.4807e-06 - accuracy: 1.0000 - val_loss: 8.7101e-06 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.2977e-06 - accuracy: 1.0000 - val_loss: 7.1516e-06 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0918 - val_accuracy: 0.9716\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 5.4056e-04 - val_accuracy: 0.9999\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.4006e-04 - accuracy: 1.0000 - val_loss: 1.5091e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 7.9308e-05 - accuracy: 1.0000 - val_loss: 8.7517e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 4.4285e-05 - accuracy: 1.0000 - val_loss: 6.0706e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.0625e-05 - accuracy: 1.0000 - val_loss: 4.9447e-05 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.2275e-05 - accuracy: 1.0000 - val_loss: 4.2473e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.6798e-05 - accuracy: 1.0000 - val_loss: 4.0212e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.3004e-05 - accuracy: 1.0000 - val_loss: 2.9800e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.0424e-05 - accuracy: 1.0000 - val_loss: 2.6326e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 8.4326e-06 - accuracy: 1.0000 - val_loss: 2.2358e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 7.0469e-06 - accuracy: 1.0000 - val_loss: 2.1482e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 5.8034e-06 - accuracy: 1.0000 - val_loss: 1.9293e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.7903e-06 - accuracy: 1.0000 - val_loss: 1.9598e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 4.0552e-06 - accuracy: 1.0000 - val_loss: 1.7031e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.3840e-06 - accuracy: 1.0000 - val_loss: 1.6498e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.8563e-06 - accuracy: 1.0000 - val_loss: 1.9899e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.4218e-06 - accuracy: 1.0000 - val_loss: 2.0820e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.0784e-06 - accuracy: 1.0000 - val_loss: 2.3312e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.7035e-06 - accuracy: 1.0000 - val_loss: 2.8477e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.3999e-06 - accuracy: 1.0000 - val_loss: 4.1172e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0173 - accuracy: 0.9967 - val_loss: 0.0224 - val_accuracy: 0.9938\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.0536e-04 - accuracy: 0.9999 - val_loss: 1.6508e-04 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 2.3079e-04 - accuracy: 1.0000 - val_loss: 2.1977e-04 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.0223e-04 - accuracy: 1.0000 - val_loss: 5.5065e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 1.8304e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 3.6191e-04 - val_accuracy: 0.9999\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 4.5039e-04 - accuracy: 0.9999 - val_loss: 1.1659e-04 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.0887e-04 - accuracy: 0.9999 - val_loss: 1.1570e-04 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 3.7376e-04 - accuracy: 0.9999 - val_loss: 2.3329e-04 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 9.3019e-04 - accuracy: 0.9998 - val_loss: 2.2252e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uAgGUDnHSjQS",
        "outputId": "f7e1cb5d-ae33-4da5-bbea-b92bd8679170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst, y_tst = generate_complete_set(as_type = \"bitpairs\", reverse = False)\n",
        "score_simplernn_bitpairs_plain = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bit_pairs[\"SimpleRNN\"] = score_simplernn_bitpairs_plain\n",
        "print(\"Accuracy:\", score_simplernn_bitpairs_plain[0])\n",
        "print(\"MSE:     \", score_simplernn_bitpairs_plain[1])\n",
        "print(\"MAE:     \", score_simplernn_bitpairs_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9987587539380179\n",
            "MSE:      78.71668439192798\n",
            "MAE:      0.14034680357639395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kPV-Wh_YSjQU"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rq_hReU8SjQU",
        "outputId": "e7934e70-4d77-4034-839b-2d86805435f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bit_pairs[\"SimpleRNN_rev\"] = history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 0.7000 - accuracy: 0.6320 - val_loss: 0.4745 - val_accuracy: 0.7133\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.3590 - accuracy: 0.8082 - val_loss: 0.2585 - val_accuracy: 0.8770\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.1321 - accuracy: 0.9454 - val_loss: 0.0196 - val_accuracy: 0.9980\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.0041 - val_accuracy: 0.9999\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.0829e-04 - val_accuracy: 0.9999\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.0083 - val_accuracy: 0.9989\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 13s 38ms/step - loss: 9.8592e-04 - accuracy: 1.0000 - val_loss: 7.4884e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 5.7809e-04 - accuracy: 1.0000 - val_loss: 5.1729e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 3.9913e-04 - accuracy: 1.0000 - val_loss: 3.5047e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 2.8210e-04 - accuracy: 1.0000 - val_loss: 2.6862e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 3.2690e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 3.5430e-04 - accuracy: 1.0000 - val_loss: 2.0486e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.4206e-04 - accuracy: 1.0000 - val_loss: 1.2449e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 9.9655e-05 - accuracy: 1.0000 - val_loss: 8.9262e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 7.6767e-05 - accuracy: 1.0000 - val_loss: 7.0590e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.6235e-05 - accuracy: 1.0000 - val_loss: 8.1721e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 5.3904e-05 - accuracy: 1.0000 - val_loss: 4.7589e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 4.0603e-05 - accuracy: 1.0000 - val_loss: 3.9091e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 3.3207e-05 - accuracy: 1.0000 - val_loss: 3.1306e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 2.7346e-05 - accuracy: 1.0000 - val_loss: 2.6285e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 2.2470e-05 - accuracy: 1.0000 - val_loss: 2.1441e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.8548e-05 - accuracy: 1.0000 - val_loss: 1.7662e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 1.5296e-05 - accuracy: 1.0000 - val_loss: 1.4780e-05 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.2665e-05 - accuracy: 1.0000 - val_loss: 1.2072e-05 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 1.0489e-05 - accuracy: 1.0000 - val_loss: 1.0126e-05 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 8.6881e-06 - accuracy: 1.0000 - val_loss: 8.3576e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 7.2042e-06 - accuracy: 1.0000 - val_loss: 7.0576e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 6.0903e-06 - accuracy: 1.0000 - val_loss: 6.0007e-06 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 5.0200e-06 - accuracy: 1.0000 - val_loss: 4.9270e-06 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 4.1583e-06 - accuracy: 1.0000 - val_loss: 4.1460e-06 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.1474 - accuracy: 0.9274 - val_loss: 0.4264 - val_accuracy: 0.7485\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0034 - val_accuracy: 0.9999\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0019 - val_accuracy: 0.9999\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.1179 - val_accuracy: 0.9654\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 9.0493e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.8091e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.9472e-04 - accuracy: 0.9999 - val_loss: 3.6497e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.0534e-04 - accuracy: 1.0000 - val_loss: 2.5084e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.1650e-04 - accuracy: 1.0000 - val_loss: 2.0056e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.7313e-04 - accuracy: 1.0000 - val_loss: 2.2218e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.1274 - accuracy: 0.9473 - val_loss: 0.0106 - val_accuracy: 0.9995\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 8.5908e-04 - accuracy: 1.0000 - val_loss: 7.1076e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 7.1816e-04 - accuracy: 1.0000 - val_loss: 5.8812e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 5.0919e-04 - accuracy: 1.0000 - val_loss: 3.8345e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.2056e-04 - accuracy: 1.0000 - val_loss: 2.9421e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.4445e-04 - accuracy: 1.0000 - val_loss: 2.5644e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.9218e-04 - accuracy: 1.0000 - val_loss: 2.1868e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5527e-04 - accuracy: 1.0000 - val_loss: 1.4559e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.2092e-04 - accuracy: 1.0000 - val_loss: 1.4579e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.7364e-05 - accuracy: 1.0000 - val_loss: 2.2777e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0923 - accuracy: 0.9613 - val_loss: 0.0051 - val_accuracy: 0.9994\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 8.6575e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 7.3834e-04 - accuracy: 1.0000 - val_loss: 6.5416e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 4.2115e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.3806e-04 - accuracy: 1.0000 - val_loss: 2.8227e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.2216e-04 - accuracy: 1.0000 - val_loss: 1.9143e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.0542e-04 - accuracy: 1.0000 - val_loss: 1.6177e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.4091e-04 - accuracy: 1.0000 - val_loss: 1.2930e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.1753e-04 - accuracy: 1.0000 - val_loss: 1.0559e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0570 - accuracy: 0.9769 - val_loss: 0.2032 - val_accuracy: 0.9147\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 5.8039e-04 - accuracy: 1.0000 - val_loss: 4.8916e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.4198e-04 - accuracy: 1.0000 - val_loss: 3.3346e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.1256e-04 - accuracy: 1.0000 - val_loss: 1.8774e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.6323e-04 - accuracy: 1.0000 - val_loss: 1.6013e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.2983e-04 - accuracy: 1.0000 - val_loss: 1.2607e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.0594e-04 - accuracy: 1.0000 - val_loss: 1.0096e-04 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 8.8013e-05 - accuracy: 1.0000 - val_loss: 9.2063e-05 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.1610e-05 - accuracy: 1.0000 - val_loss: 6.7782e-05 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 6.0962e-05 - accuracy: 1.0000 - val_loss: 7.5072e-05 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.1563 - accuracy: 0.9239 - val_loss: 0.0462 - val_accuracy: 0.9831\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 8.1619e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 6.8148e-04 - accuracy: 0.9999 - val_loss: 3.2292e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.8571e-04 - accuracy: 1.0000 - val_loss: 1.5910e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.2882e-04 - accuracy: 1.0000 - val_loss: 1.2638e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.8638e-05 - accuracy: 1.0000 - val_loss: 9.2944e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 7.9639e-05 - accuracy: 1.0000 - val_loss: 7.7191e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.6542e-05 - accuracy: 1.0000 - val_loss: 6.3417e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.5688e-05 - accuracy: 1.0000 - val_loss: 5.3626e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 4.7261e-05 - accuracy: 1.0000 - val_loss: 4.7760e-05 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 4.0600e-05 - accuracy: 1.0000 - val_loss: 4.2335e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.5731e-05 - accuracy: 1.0000 - val_loss: 3.6441e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.0315e-05 - accuracy: 1.0000 - val_loss: 3.8893e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.5665e-05 - accuracy: 1.0000 - val_loss: 2.7086e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.2161e-05 - accuracy: 1.0000 - val_loss: 2.2831e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.9050e-05 - accuracy: 1.0000 - val_loss: 1.9417e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0537 - accuracy: 0.9789 - val_loss: 0.5641 - val_accuracy: 0.6184\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 0.3293 - accuracy: 0.8107 - val_loss: 0.1710 - val_accuracy: 0.9275\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0650 - accuracy: 0.9773 - val_loss: 0.0046 - val_accuracy: 0.9998\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 8.7119e-04 - accuracy: 1.0000 - val_loss: 6.1482e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 4.8360e-04 - accuracy: 1.0000 - val_loss: 4.0638e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.4059e-04 - accuracy: 1.0000 - val_loss: 3.0397e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.5235e-04 - accuracy: 1.0000 - val_loss: 2.4298e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.0634e-04 - accuracy: 1.0000 - val_loss: 2.1232e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5674e-04 - accuracy: 1.0000 - val_loss: 1.5262e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.2424e-04 - accuracy: 1.0000 - val_loss: 1.2897e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0757 - accuracy: 0.9627 - val_loss: 0.2937 - val_accuracy: 0.8249\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0787 - accuracy: 0.9639 - val_loss: 0.0041 - val_accuracy: 0.9999\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.6777e-04 - accuracy: 1.0000 - val_loss: 7.5634e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.1615e-04 - accuracy: 1.0000 - val_loss: 3.8460e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.0100 - val_accuracy: 0.9973\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 4.7576e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.1249e-04 - accuracy: 1.0000 - val_loss: 1.9137e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5165e-04 - accuracy: 1.0000 - val_loss: 1.2355e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.0542e-04 - accuracy: 1.0000 - val_loss: 8.9393e-05 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 7.9911e-05 - accuracy: 1.0000 - val_loss: 7.0207e-05 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.2546e-05 - accuracy: 1.0000 - val_loss: 5.6446e-05 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.9635e-05 - accuracy: 1.0000 - val_loss: 4.7099e-05 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.0267e-05 - accuracy: 1.0000 - val_loss: 3.8350e-05 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.2064e-05 - accuracy: 1.0000 - val_loss: 3.0803e-05 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.5548e-05 - accuracy: 1.0000 - val_loss: 2.5310e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.0291e-05 - accuracy: 1.0000 - val_loss: 2.2768e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.6426e-05 - accuracy: 1.0000 - val_loss: 1.5734e-05 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.3295e-05 - accuracy: 1.0000 - val_loss: 1.3246e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.1008e-05 - accuracy: 1.0000 - val_loss: 1.1135e-05 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.2741e-06 - accuracy: 1.0000 - val_loss: 9.6967e-06 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.9904e-06 - accuracy: 1.0000 - val_loss: 7.6780e-06 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.6818e-06 - accuracy: 1.0000 - val_loss: 6.5264e-06 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.7060e-06 - accuracy: 1.0000 - val_loss: 5.5001e-06 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.8425e-06 - accuracy: 1.0000 - val_loss: 4.7505e-06 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 4.0551e-06 - accuracy: 1.0000 - val_loss: 4.0440e-06 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 3.4197e-06 - accuracy: 1.0000 - val_loss: 3.5927e-06 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 2.8889e-06 - accuracy: 1.0000 - val_loss: 2.8044e-06 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 2.4091e-06 - accuracy: 1.0000 - val_loss: 2.3678e-06 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 2.0193e-06 - accuracy: 1.0000 - val_loss: 2.0833e-06 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.7641e-06 - accuracy: 1.0000 - val_loss: 1.8740e-06 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 14s 39ms/step - loss: 1.4658e-06 - accuracy: 1.0000 - val_loss: 1.5378e-06 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.2101e-06 - accuracy: 1.0000 - val_loss: 1.2073e-06 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 1.0085e-06 - accuracy: 1.0000 - val_loss: 9.9511e-07 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 8.4715e-07 - accuracy: 1.0000 - val_loss: 8.4542e-07 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 7.1510e-07 - accuracy: 1.0000 - val_loss: 7.1837e-07 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 6.0548e-07 - accuracy: 1.0000 - val_loss: 5.9842e-07 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 5.1646e-07 - accuracy: 1.0000 - val_loss: 5.1800e-07 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 4.3627e-07 - accuracy: 1.0000 - val_loss: 4.4733e-07 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 3.7040e-07 - accuracy: 1.0000 - val_loss: 4.1191e-07 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 13s 38ms/step - loss: 3.2102e-07 - accuracy: 1.0000 - val_loss: 3.3841e-07 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 13s 37ms/step - loss: 2.8449e-07 - accuracy: 1.0000 - val_loss: 2.9182e-07 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 13s 36ms/step - loss: 2.4957e-07 - accuracy: 1.0000 - val_loss: 2.6606e-07 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.2499e-07 - accuracy: 1.0000 - val_loss: 2.9808e-07 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0815 - accuracy: 0.9731 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 7.0986e-04 - accuracy: 1.0000 - val_loss: 3.8943e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.8993e-04 - accuracy: 1.0000 - val_loss: 2.1478e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.6914e-04 - accuracy: 1.0000 - val_loss: 1.5414e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.1141e-04 - accuracy: 1.0000 - val_loss: 1.0758e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 8.3690e-05 - accuracy: 1.0000 - val_loss: 8.5722e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.5842e-05 - accuracy: 1.0000 - val_loss: 6.5529e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.3842e-05 - accuracy: 1.0000 - val_loss: 5.7415e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.3693e-05 - accuracy: 1.0000 - val_loss: 4.4768e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.6447e-05 - accuracy: 1.0000 - val_loss: 3.9145e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.0564e-05 - accuracy: 1.0000 - val_loss: 3.0639e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.5531e-05 - accuracy: 1.0000 - val_loss: 2.6372e-05 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.1463e-05 - accuracy: 1.0000 - val_loss: 2.2682e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.8261e-05 - accuracy: 1.0000 - val_loss: 1.8075e-05 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.5548e-05 - accuracy: 1.0000 - val_loss: 1.5459e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.3177e-05 - accuracy: 1.0000 - val_loss: 1.4384e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.1211e-05 - accuracy: 1.0000 - val_loss: 1.1679e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.5890e-06 - accuracy: 1.0000 - val_loss: 9.5917e-06 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 8.1014e-06 - accuracy: 1.0000 - val_loss: 8.2876e-06 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.8989e-06 - accuracy: 1.0000 - val_loss: 7.8467e-06 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.9145e-06 - accuracy: 1.0000 - val_loss: 6.3162e-06 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 4.8366e-06 - accuracy: 1.0000 - val_loss: 5.0565e-06 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 4.0195e-06 - accuracy: 1.0000 - val_loss: 4.3002e-06 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 3.3293e-06 - accuracy: 1.0000 - val_loss: 3.7046e-06 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.7524e-06 - accuracy: 1.0000 - val_loss: 2.9792e-06 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.3158e-06 - accuracy: 1.0000 - val_loss: 2.7633e-06 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.9881e-06 - accuracy: 1.0000 - val_loss: 2.7145e-06 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.6712e-06 - accuracy: 1.0000 - val_loss: 2.0251e-06 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.4664e-06 - accuracy: 1.0000 - val_loss: 2.5748e-06 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.2266e-06 - accuracy: 1.0000 - val_loss: 1.5952e-06 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 1.0525e-06 - accuracy: 1.0000 - val_loss: 1.3069e-06 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.0364e-07 - accuracy: 1.0000 - val_loss: 1.1251e-06 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 7.7675e-07 - accuracy: 1.0000 - val_loss: 1.0394e-06 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.7313e-07 - accuracy: 1.0000 - val_loss: 1.9647e-06 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 5.7905e-07 - accuracy: 1.0000 - val_loss: 6.9229e-07 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 5.0209e-07 - accuracy: 1.0000 - val_loss: 5.9783e-07 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 0.0440 - accuracy: 0.9895 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 6.4318e-04 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.9737e-04 - accuracy: 1.0000 - val_loss: 3.9696e-04 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.1849e-04 - accuracy: 1.0000 - val_loss: 2.6517e-04 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 2.3987e-04 - accuracy: 1.0000 - val_loss: 1.9856e-04 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.7257e-04 - accuracy: 1.0000 - val_loss: 1.4761e-04 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.2650e-04 - accuracy: 1.0000 - val_loss: 1.0836e-04 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 9.0297e-05 - accuracy: 1.0000 - val_loss: 7.4768e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 6.0654e-05 - accuracy: 1.0000 - val_loss: 5.2221e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 4.2436e-05 - accuracy: 1.0000 - val_loss: 3.6877e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 3.3357e-05 - accuracy: 1.0000 - val_loss: 2.9935e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.6188e-05 - accuracy: 1.0000 - val_loss: 2.3514e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 12s 35ms/step - loss: 2.1633e-05 - accuracy: 1.0000 - val_loss: 2.0201e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.8507e-05 - accuracy: 1.0000 - val_loss: 1.7289e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 12s 34ms/step - loss: 1.6013e-05 - accuracy: 1.0000 - val_loss: 1.4954e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m_nB-q8oSjQY",
        "outputId": "86e276ff-36d2-4489-dedf-9ababc3d9394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"bitpairs\", reverse = True)\n",
        "score_simplernn_bitpairs_reverse = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bit_pairs[\"SimpleRNN_rev\"] = score_simplernn_bitpairs_reverse\n",
        "print(\"Accuracy:\", score_simplernn_bitpairs_reverse[0])\n",
        "print(\"MSE:     \", score_simplernn_bitpairs_reverse[1])\n",
        "print(\"MAE:     \", score_simplernn_bitpairs_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.999945534237465\n",
            "MSE:      0.02657929211708419\n",
            "MAE:      0.000888651915044877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x8t2s462TLo2"
      },
      "source": [
        "### Model: GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrAPTJTWTLo3",
        "outputId": "9958ced6-4bf3-44a2-ccbf-5b28d353acc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "RNN = layers.GRU\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "# built the model\n",
        "model = Sequential(name = \"model_GRU_bit_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_GRU_bit_pairs\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 128)               50688     \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 11, 128)           99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 11, 2)             258       \n",
            "=================================================================\n",
            "Total params: 150,018\n",
            "Trainable params: 150,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0I7hKK5cTLo7"
      },
      "source": [
        "##### Train on plain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qSocTyP6TLo7",
        "outputId": "65e5d59e-a398-49bf-e9cf-71f1fe9d355c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_plain\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_plain, y_train_plain,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_plain, y_val_plain),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")\n",
        "histories_bit_pairs[\"GRU_plain\"] = history\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.6251 - accuracy: 0.5722 - val_loss: 0.5831 - val_accuracy: 0.6086\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.5714 - accuracy: 0.6146 - val_loss: 0.5682 - val_accuracy: 0.6144\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.5601 - accuracy: 0.6243 - val_loss: 0.5572 - val_accuracy: 0.6249\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.5342 - accuracy: 0.6485 - val_loss: 0.5149 - val_accuracy: 0.6674\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.5127 - accuracy: 0.6798 - val_loss: 0.5003 - val_accuracy: 0.6894\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.4920 - accuracy: 0.7047 - val_loss: 0.4756 - val_accuracy: 0.7181\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.4393 - accuracy: 0.7309 - val_loss: 0.4115 - val_accuracy: 0.7455\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.4023 - accuracy: 0.7533 - val_loss: 0.3892 - val_accuracy: 0.7681\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.3491 - accuracy: 0.7961 - val_loss: 0.3192 - val_accuracy: 0.8197\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.2969 - accuracy: 0.8343 - val_loss: 0.2722 - val_accuracy: 0.8491\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.2675 - accuracy: 0.8550 - val_loss: 0.2468 - val_accuracy: 0.8657\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.2442 - accuracy: 0.8700 - val_loss: 0.2570 - val_accuracy: 0.8615\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.2228 - accuracy: 0.8824 - val_loss: 0.2049 - val_accuracy: 0.8930\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.2117 - accuracy: 0.8885 - val_loss: 0.2048 - val_accuracy: 0.8934\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1993 - accuracy: 0.8957 - val_loss: 0.1979 - val_accuracy: 0.8985\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1849 - accuracy: 0.9039 - val_loss: 0.1822 - val_accuracy: 0.9061\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1710 - accuracy: 0.9127 - val_loss: 0.1906 - val_accuracy: 0.9021\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1633 - accuracy: 0.9174 - val_loss: 0.1597 - val_accuracy: 0.9189\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1527 - accuracy: 0.9245 - val_loss: 0.1419 - val_accuracy: 0.9318\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1414 - accuracy: 0.9310 - val_loss: 0.1390 - val_accuracy: 0.9312\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1285 - accuracy: 0.9386 - val_loss: 0.1325 - val_accuracy: 0.9356\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1203 - accuracy: 0.9433 - val_loss: 0.1227 - val_accuracy: 0.9428\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1119 - accuracy: 0.9480 - val_loss: 0.1060 - val_accuracy: 0.9516\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1052 - accuracy: 0.9524 - val_loss: 0.0960 - val_accuracy: 0.9566\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0909 - accuracy: 0.9591 - val_loss: 0.0926 - val_accuracy: 0.9577\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0934 - accuracy: 0.9598 - val_loss: 0.0807 - val_accuracy: 0.9641\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0765 - accuracy: 0.9668 - val_loss: 0.0821 - val_accuracy: 0.9644\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0697 - accuracy: 0.9703 - val_loss: 0.0642 - val_accuracy: 0.9722\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0719 - accuracy: 0.9696 - val_loss: 0.0636 - val_accuracy: 0.9721\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0672 - accuracy: 0.9725 - val_loss: 0.0556 - val_accuracy: 0.9772\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0517 - accuracy: 0.9790 - val_loss: 0.0567 - val_accuracy: 0.9769\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0594 - accuracy: 0.9757 - val_loss: 0.0580 - val_accuracy: 0.9763\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0417 - accuracy: 0.9836 - val_loss: 0.0435 - val_accuracy: 0.9829\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0460 - accuracy: 0.9827 - val_loss: 0.0427 - val_accuracy: 0.9830\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.0388 - val_accuracy: 0.9857\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0409 - accuracy: 0.9849 - val_loss: 0.0239 - val_accuracy: 0.9911\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0299 - accuracy: 0.9889 - val_loss: 0.0401 - val_accuracy: 0.9844\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 0.0600 - val_accuracy: 0.9786\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 0.0210 - val_accuracy: 0.9927\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0152 - val_accuracy: 0.9945\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.0207 - val_accuracy: 0.9925\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0198 - val_accuracy: 0.9928\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.0162 - val_accuracy: 0.9941\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.0253 - val_accuracy: 0.9906\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0132 - val_accuracy: 0.9958\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0078 - val_accuracy: 0.9976\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0346 - val_accuracy: 0.9886\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0110 - val_accuracy: 0.9962\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0164 - val_accuracy: 0.9945\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0064 - val_accuracy: 0.9979\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0163 - val_accuracy: 0.9937\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0092 - val_accuracy: 0.9971\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0441 - val_accuracy: 0.9886\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0449 - val_accuracy: 0.9854\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0094 - val_accuracy: 0.9970\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0157 - val_accuracy: 0.9946\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0154 - val_accuracy: 0.9950\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0186 - val_accuracy: 0.9935\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.2093 - val_accuracy: 0.9435\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.0971e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.3950e-04 - accuracy: 1.0000 - val_loss: 9.3235e-04 - val_accuracy: 0.9998\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9951\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0171 - val_accuracy: 0.9947\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0074 - val_accuracy: 0.9978\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 9.6456e-04 - val_accuracy: 0.9998\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.0966e-04 - accuracy: 0.9999 - val_loss: 2.4099e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2727e-04 - accuracy: 1.0000 - val_loss: 1.9765e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.3771e-05 - accuracy: 1.0000 - val_loss: 1.4701e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.3033e-05 - accuracy: 1.0000 - val_loss: 1.3134e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.9162e-05 - accuracy: 1.0000 - val_loss: 1.1148e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.8476e-05 - accuracy: 1.0000 - val_loss: 9.6585e-05 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.0210e-05 - accuracy: 1.0000 - val_loss: 1.0527e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.3381e-05 - accuracy: 1.0000 - val_loss: 7.4315e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.7884e-05 - accuracy: 1.0000 - val_loss: 6.9747e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.3202e-05 - accuracy: 1.0000 - val_loss: 6.1201e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.9469e-05 - accuracy: 1.0000 - val_loss: 5.4200e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.6404e-05 - accuracy: 1.0000 - val_loss: 5.0964e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3683e-05 - accuracy: 1.0000 - val_loss: 4.7016e-05 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1495e-05 - accuracy: 1.0000 - val_loss: 3.9761e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.6294e-06 - accuracy: 1.0000 - val_loss: 4.1128e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 8.0542e-06 - accuracy: 1.0000 - val_loss: 3.3794e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.7928e-06 - accuracy: 1.0000 - val_loss: 3.6429e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.6048e-06 - accuracy: 1.0000 - val_loss: 3.7184e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 4.6800e-06 - accuracy: 1.0000 - val_loss: 2.8125e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.9110e-06 - accuracy: 1.0000 - val_loss: 2.6070e-05 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.2643e-06 - accuracy: 1.0000 - val_loss: 3.0698e-05 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.7236e-06 - accuracy: 1.0000 - val_loss: 3.5753e-05 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.3039e-06 - accuracy: 1.0000 - val_loss: 3.3727e-05 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.9207e-06 - accuracy: 1.0000 - val_loss: 6.5426e-05 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.5968e-06 - accuracy: 1.0000 - val_loss: 2.7778e-05 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3453e-06 - accuracy: 1.0000 - val_loss: 3.3903e-05 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1386e-06 - accuracy: 1.0000 - val_loss: 2.6853e-05 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.4914e-07 - accuracy: 1.0000 - val_loss: 3.4334e-05 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 8.0562e-07 - accuracy: 1.0000 - val_loss: 2.9086e-05 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 6.8938e-07 - accuracy: 1.0000 - val_loss: 2.4061e-05 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.9381e-07 - accuracy: 1.0000 - val_loss: 3.3568e-05 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.0793e-07 - accuracy: 1.0000 - val_loss: 3.4030e-05 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.3788e-07 - accuracy: 1.0000 - val_loss: 3.1042e-05 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.8320e-07 - accuracy: 1.0000 - val_loss: 2.8891e-05 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.3611e-07 - accuracy: 1.0000 - val_loss: 4.3395e-05 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.0090e-07 - accuracy: 1.0000 - val_loss: 3.4904e-05 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.6807e-07 - accuracy: 1.0000 - val_loss: 3.1828e-05 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.4365e-07 - accuracy: 1.0000 - val_loss: 3.4508e-05 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.2279e-07 - accuracy: 1.0000 - val_loss: 2.5334e-05 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.0539e-07 - accuracy: 1.0000 - val_loss: 3.3450e-05 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.9008e-07 - accuracy: 1.0000 - val_loss: 2.9881e-05 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.7762e-07 - accuracy: 1.0000 - val_loss: 2.3813e-05 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.6890e-07 - accuracy: 1.0000 - val_loss: 2.0678e-05 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.6005e-07 - accuracy: 1.0000 - val_loss: 4.5613e-05 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.5399e-07 - accuracy: 1.0000 - val_loss: 2.9173e-05 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.4779e-07 - accuracy: 1.0000 - val_loss: 3.2834e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.4342e-07 - accuracy: 1.0000 - val_loss: 4.0006e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3987e-07 - accuracy: 1.0000 - val_loss: 3.5409e-05 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3677e-07 - accuracy: 1.0000 - val_loss: 3.0350e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3431e-07 - accuracy: 1.0000 - val_loss: 2.7194e-05 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3167e-07 - accuracy: 1.0000 - val_loss: 2.1035e-05 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2997e-07 - accuracy: 1.0000 - val_loss: 2.6274e-05 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2848e-07 - accuracy: 1.0000 - val_loss: 1.8823e-05 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2713e-07 - accuracy: 1.0000 - val_loss: 2.7591e-05 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2619e-07 - accuracy: 1.0000 - val_loss: 4.1946e-05 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2530e-07 - accuracy: 1.0000 - val_loss: 3.8002e-05 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2441e-07 - accuracy: 1.0000 - val_loss: 2.0120e-05 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2395e-07 - accuracy: 1.0000 - val_loss: 2.2260e-05 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2332e-07 - accuracy: 1.0000 - val_loss: 3.3525e-05 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2294e-07 - accuracy: 1.0000 - val_loss: 2.8667e-05 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2249e-07 - accuracy: 1.0000 - val_loss: 1.6878e-05 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2223e-07 - accuracy: 1.0000 - val_loss: 2.6058e-05 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2181e-07 - accuracy: 1.0000 - val_loss: 2.6261e-05 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2155e-07 - accuracy: 1.0000 - val_loss: 2.9089e-05 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2135e-07 - accuracy: 1.0000 - val_loss: 2.2522e-05 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2117e-07 - accuracy: 1.0000 - val_loss: 2.5199e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2107e-07 - accuracy: 1.0000 - val_loss: 3.5767e-05 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2088e-07 - accuracy: 1.0000 - val_loss: 1.2733e-05 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2081e-07 - accuracy: 1.0000 - val_loss: 1.8614e-05 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2061e-07 - accuracy: 1.0000 - val_loss: 1.5964e-05 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2048e-07 - accuracy: 1.0000 - val_loss: 1.8462e-05 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2039e-07 - accuracy: 1.0000 - val_loss: 1.4599e-05 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2027e-07 - accuracy: 1.0000 - val_loss: 1.3260e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2027e-07 - accuracy: 1.0000 - val_loss: 1.6632e-05 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2015e-07 - accuracy: 1.0000 - val_loss: 2.0977e-05 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2011e-07 - accuracy: 1.0000 - val_loss: 1.4762e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.2004e-07 - accuracy: 1.0000 - val_loss: 1.1532e-05 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1998e-07 - accuracy: 1.0000 - val_loss: 2.4143e-05 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1992e-07 - accuracy: 1.0000 - val_loss: 1.8281e-05 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1988e-07 - accuracy: 1.0000 - val_loss: 1.1341e-05 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1989e-07 - accuracy: 1.0000 - val_loss: 2.0867e-05 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1983e-07 - accuracy: 1.0000 - val_loss: 1.5205e-05 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1978e-07 - accuracy: 1.0000 - val_loss: 1.3636e-05 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1974e-07 - accuracy: 1.0000 - val_loss: 1.1579e-05 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1970e-07 - accuracy: 1.0000 - val_loss: 1.1171e-05 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1970e-07 - accuracy: 1.0000 - val_loss: 1.5095e-05 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1966e-07 - accuracy: 1.0000 - val_loss: 1.2374e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1964e-07 - accuracy: 1.0000 - val_loss: 1.1503e-05 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1962e-07 - accuracy: 1.0000 - val_loss: 1.2577e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 1.1960e-07 - accuracy: 1.0000 - val_loss: 1.1081e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1958e-07 - accuracy: 1.0000 - val_loss: 1.2411e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1955e-07 - accuracy: 1.0000 - val_loss: 1.1370e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1954e-07 - accuracy: 1.0000 - val_loss: 1.1879e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1952e-07 - accuracy: 1.0000 - val_loss: 1.1270e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1951e-07 - accuracy: 1.0000 - val_loss: 9.2820e-06 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1950e-07 - accuracy: 1.0000 - val_loss: 1.1730e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1947e-07 - accuracy: 1.0000 - val_loss: 1.2860e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1947e-07 - accuracy: 1.0000 - val_loss: 9.9868e-06 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1945e-07 - accuracy: 1.0000 - val_loss: 1.1616e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1944e-07 - accuracy: 1.0000 - val_loss: 9.9063e-06 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1943e-07 - accuracy: 1.0000 - val_loss: 1.1116e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1944e-07 - accuracy: 1.0000 - val_loss: 1.0318e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1942e-07 - accuracy: 1.0000 - val_loss: 1.0175e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1941e-07 - accuracy: 1.0000 - val_loss: 9.5873e-06 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1940e-07 - accuracy: 1.0000 - val_loss: 8.5419e-06 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1940e-07 - accuracy: 1.0000 - val_loss: 9.9041e-06 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1938e-07 - accuracy: 1.0000 - val_loss: 9.9995e-06 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1937e-07 - accuracy: 1.0000 - val_loss: 1.0485e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1937e-07 - accuracy: 1.0000 - val_loss: 8.7412e-06 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1937e-07 - accuracy: 1.0000 - val_loss: 1.0070e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1936e-07 - accuracy: 1.0000 - val_loss: 8.5157e-06 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1935e-07 - accuracy: 1.0000 - val_loss: 8.6438e-06 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.1935e-07 - accuracy: 1.0000 - val_loss: 7.8985e-06 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1935e-07 - accuracy: 1.0000 - val_loss: 7.6114e-06 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1934e-07 - accuracy: 1.0000 - val_loss: 7.9593e-06 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1933e-07 - accuracy: 1.0000 - val_loss: 9.4439e-06 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1933e-07 - accuracy: 1.0000 - val_loss: 1.0541e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1932e-07 - accuracy: 1.0000 - val_loss: 8.3967e-06 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1932e-07 - accuracy: 1.0000 - val_loss: 8.0996e-06 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1932e-07 - accuracy: 1.0000 - val_loss: 7.9554e-06 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1932e-07 - accuracy: 1.0000 - val_loss: 8.1581e-06 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1931e-07 - accuracy: 1.0000 - val_loss: 7.8038e-06 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1932e-07 - accuracy: 1.0000 - val_loss: 8.2240e-06 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1930e-07 - accuracy: 1.0000 - val_loss: 7.8377e-06 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1930e-07 - accuracy: 1.0000 - val_loss: 9.3424e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-9KrBXWhTLo_",
        "outputId": "21868e13-f55f-46ce-b1bc-4143e0116b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"bitpairs\", reverse = False)\n",
        "score_gru_bitpairs_plain = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bit_pairs[\"GRU_plain\"] = score_gru_bitpairs_plain\n",
        "print(\"Accuracy:\", score_gru_bitpairs_plain[0])\n",
        "print(\"MSE:     \", score_gru_bitpairs_plain[1])\n",
        "print(\"MAE:     \", score_gru_bitpairs_plain[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9986708442862071\n",
            "MSE:      1.5233338015477833\n",
            "MAE:      0.03330533602031095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rCB75AQITLpB"
      },
      "source": [
        "##### Train on reverse data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMZXRQfHda-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rebuilt the model\n",
        "model = Sequential(name = \"model_GRU_bit_pairs\")\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(BITS + 1))\n",
        "for _ in range(LAYERS):\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3W478u7TLpC",
        "outputId": "5367210e-e04a-4cf2-d8d4-d7cc8a8f6e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model \n",
        "save_name = model.name + \"_reverse\"\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path + save_name + \".h5\",\n",
        "                                                            save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train_rev, y_train_rev,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=200,\n",
        "              validation_data=(x_val_rev, y_val_rev),\n",
        "              callbacks = [checkpoint_cb])\n",
        "\n",
        "model.save(model_path + save_name + \".h5\")\n",
        "\n",
        "histories_bit_pairs[\"GRU_rev\"] = history\n",
        "        \n",
        "# write history to file\n",
        "pd.DataFrame(history.history).to_csv(history_path + save_name + \".csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.5115 - accuracy: 0.5996 - val_loss: 0.5733 - val_accuracy: 0.6588\n",
            "Epoch 2/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.5238 - accuracy: 0.6958 - val_loss: 0.4683 - val_accuracy: 0.7399\n",
            "Epoch 3/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.4198 - accuracy: 0.7748 - val_loss: 0.3842 - val_accuracy: 0.7941\n",
            "Epoch 4/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.3128 - accuracy: 0.8460 - val_loss: 0.2570 - val_accuracy: 0.8809\n",
            "Epoch 5/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.3320 - accuracy: 0.8337 - val_loss: 0.2458 - val_accuracy: 0.8869\n",
            "Epoch 6/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1916 - accuracy: 0.9121 - val_loss: 0.1382 - val_accuracy: 0.9388\n",
            "Epoch 7/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.2154 - accuracy: 0.8989 - val_loss: 0.2819 - val_accuracy: 0.8597\n",
            "Epoch 8/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1467 - accuracy: 0.9400 - val_loss: 0.0871 - val_accuracy: 0.9662\n",
            "Epoch 9/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0575 - accuracy: 0.9799 - val_loss: 0.0423 - val_accuracy: 0.9859\n",
            "Epoch 10/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.0203 - val_accuracy: 0.9935\n",
            "Epoch 11/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0114 - val_accuracy: 0.9968\n",
            "Epoch 12/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.0074 - val_accuracy: 0.9978\n",
            "Epoch 13/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
            "Epoch 14/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
            "Epoch 15/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
            "Epoch 16/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
            "Epoch 17/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
            "Epoch 18/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 19/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.0050 - val_accuracy: 0.9989\n",
            "Epoch 20/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 21/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 22/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 23/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 24/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 25/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 8.4759e-04 - accuracy: 0.9999 - val_loss: 6.7183e-04 - val_accuracy: 0.9999\n",
            "Epoch 26/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.6577e-04 - accuracy: 1.0000 - val_loss: 6.1346e-04 - val_accuracy: 0.9999\n",
            "Epoch 27/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 5.5709e-04 - val_accuracy: 0.9999\n",
            "Epoch 28/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0208 - val_accuracy: 0.9938\n",
            "Epoch 29/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 5.8211e-04 - val_accuracy: 0.9999\n",
            "Epoch 30/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.6474e-04 - accuracy: 1.0000 - val_loss: 2.1680e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.7368e-04 - accuracy: 1.0000 - val_loss: 2.4900e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.4421e-04 - accuracy: 1.0000 - val_loss: 2.5777e-04 - val_accuracy: 0.9999\n",
            "Epoch 33/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.0628e-04 - accuracy: 1.0000 - val_loss: 1.2969e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 35/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.5615e-04 - accuracy: 0.9999 - val_loss: 6.6943e-04 - val_accuracy: 0.9999\n",
            "Epoch 36/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.6473e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.7777e-04 - accuracy: 1.0000 - val_loss: 1.9123e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2477e-04 - accuracy: 1.0000 - val_loss: 1.4339e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 9.9487e-05 - accuracy: 1.0000 - val_loss: 1.1226e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 8.0229e-05 - accuracy: 1.0000 - val_loss: 9.4373e-05 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.6548e-05 - accuracy: 1.0000 - val_loss: 7.6914e-05 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.4852e-05 - accuracy: 1.0000 - val_loss: 6.7707e-05 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.5124e-05 - accuracy: 1.0000 - val_loss: 6.3231e-05 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.7556e-05 - accuracy: 1.0000 - val_loss: 4.9946e-05 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.0751e-05 - accuracy: 1.0000 - val_loss: 4.3097e-05 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.5593e-05 - accuracy: 1.0000 - val_loss: 5.0000e-05 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 2.0613e-05 - accuracy: 1.0000 - val_loss: 3.4439e-05 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.5337e-05 - accuracy: 1.0000 - val_loss: 2.6309e-05 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2133e-05 - accuracy: 1.0000 - val_loss: 1.7119e-05 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.5705e-06 - accuracy: 1.0000 - val_loss: 1.8409e-05 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.4729e-06 - accuracy: 1.0000 - val_loss: 1.9000e-05 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.2268e-06 - accuracy: 1.0000 - val_loss: 2.6556e-05 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 5.1916e-06 - accuracy: 1.0000 - val_loss: 1.1073e-05 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.1500e-06 - accuracy: 1.0000 - val_loss: 3.3438e-05 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.5942e-06 - accuracy: 1.0000 - val_loss: 9.7763e-06 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.9604e-06 - accuracy: 1.0000 - val_loss: 4.9215e-06 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.4248e-06 - accuracy: 1.0000 - val_loss: 1.6004e-05 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0928 - accuracy: 0.9629 - val_loss: 0.2038 - val_accuracy: 0.9139\n",
            "Epoch 59/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0690 - accuracy: 0.9758 - val_loss: 0.0143 - val_accuracy: 0.9968\n",
            "Epoch 60/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
            "Epoch 61/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
            "Epoch 62/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 63/200\n",
            "352/352 [==============================] - 5s 13ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 64/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 6.2494e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
            "Epoch 66/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 8.2141e-04 - val_accuracy: 0.9999\n",
            "Epoch 67/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 68/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 6.8100e-04 - val_accuracy: 0.9999\n",
            "Epoch 69/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.9160e-04 - accuracy: 1.0000 - val_loss: 2.4000e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.7052e-04 - accuracy: 1.0000 - val_loss: 5.4287e-04 - val_accuracy: 0.9999\n",
            "Epoch 71/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.1826e-04 - accuracy: 0.9999 - val_loss: 1.8474e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3828e-04 - accuracy: 1.0000 - val_loss: 1.4558e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0414 - accuracy: 0.9867 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 74/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 3.9184e-04 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.5653e-04 - accuracy: 0.9999 - val_loss: 8.6414e-04 - val_accuracy: 0.9998\n",
            "Epoch 76/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 3.8005e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.5088e-04 - accuracy: 1.0000 - val_loss: 1.3301e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.7510e-05 - accuracy: 1.0000 - val_loss: 8.5272e-05 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.6774e-05 - accuracy: 1.0000 - val_loss: 5.9823e-05 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.9457e-05 - accuracy: 1.0000 - val_loss: 4.6946e-05 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.8939e-05 - accuracy: 1.0000 - val_loss: 3.7442e-05 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.0844e-05 - accuracy: 1.0000 - val_loss: 2.9547e-05 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.4799e-05 - accuracy: 1.0000 - val_loss: 2.4121e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.0229e-05 - accuracy: 1.0000 - val_loss: 2.0234e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.6608e-05 - accuracy: 1.0000 - val_loss: 1.6137e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3704e-05 - accuracy: 1.0000 - val_loss: 1.3324e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1321e-05 - accuracy: 1.0000 - val_loss: 1.1172e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.3889e-06 - accuracy: 1.0000 - val_loss: 9.4061e-06 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.8129e-06 - accuracy: 1.0000 - val_loss: 8.0836e-06 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.5204e-06 - accuracy: 1.0000 - val_loss: 6.4701e-06 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.4197e-06 - accuracy: 1.0000 - val_loss: 5.6181e-06 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.5170e-06 - accuracy: 1.0000 - val_loss: 5.2087e-06 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 3.8620e-06 - accuracy: 1.0000 - val_loss: 4.0645e-06 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.1331e-06 - accuracy: 1.0000 - val_loss: 3.7322e-06 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.6245e-06 - accuracy: 1.0000 - val_loss: 3.3835e-06 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.2000e-06 - accuracy: 1.0000 - val_loss: 3.3924e-06 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 1.8346e-06 - accuracy: 1.0000 - val_loss: 2.9754e-06 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.5391e-06 - accuracy: 1.0000 - val_loss: 2.3221e-06 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2799e-06 - accuracy: 1.0000 - val_loss: 1.9727e-06 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.1243 - accuracy: 0.9551 - val_loss: 0.0127 - val_accuracy: 0.9965\n",
            "Epoch 101/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 102/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 9.4746e-04 - val_accuracy: 0.9999\n",
            "Epoch 103/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.3080e-04 - accuracy: 1.0000 - val_loss: 2.3384e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.7370e-04 - accuracy: 1.0000 - val_loss: 1.5169e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2116e-04 - accuracy: 1.0000 - val_loss: 1.1650e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.2384e-05 - accuracy: 1.0000 - val_loss: 8.7214e-05 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.1739e-05 - accuracy: 1.0000 - val_loss: 7.2287e-05 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.5377e-05 - accuracy: 1.0000 - val_loss: 5.7926e-05 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.4378e-05 - accuracy: 1.0000 - val_loss: 4.6553e-05 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.6033e-05 - accuracy: 1.0000 - val_loss: 3.9242e-05 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.8637e-05 - accuracy: 1.0000 - val_loss: 3.0218e-05 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.4444e-05 - accuracy: 1.0000 - val_loss: 2.6046e-05 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.8967e-05 - accuracy: 1.0000 - val_loss: 2.1733e-05 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 0.0107 - val_accuracy: 0.9971\n",
            "Epoch 115/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 8.4887e-04 - val_accuracy: 0.9999\n",
            "Epoch 116/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.8451e-04 - accuracy: 1.0000 - val_loss: 2.6188e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.9263e-04 - accuracy: 1.0000 - val_loss: 1.6089e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.0670e-04 - accuracy: 1.0000 - val_loss: 1.0243e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.9216e-05 - accuracy: 1.0000 - val_loss: 8.4522e-05 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.1623e-05 - accuracy: 1.0000 - val_loss: 6.4943e-05 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.7531e-05 - accuracy: 1.0000 - val_loss: 4.9404e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.9902e-05 - accuracy: 1.0000 - val_loss: 4.1681e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.4806e-05 - accuracy: 1.0000 - val_loss: 3.0538e-05 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.0908e-05 - accuracy: 1.0000 - val_loss: 2.6981e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.7835e-05 - accuracy: 1.0000 - val_loss: 2.1987e-05 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.5409e-05 - accuracy: 1.0000 - val_loss: 2.1514e-05 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3078e-05 - accuracy: 1.0000 - val_loss: 1.7009e-05 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1120e-05 - accuracy: 1.0000 - val_loss: 1.3829e-05 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.5675e-06 - accuracy: 1.0000 - val_loss: 1.5089e-05 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 8.1316e-06 - accuracy: 1.0000 - val_loss: 1.0565e-05 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0597 - accuracy: 0.9800 - val_loss: 0.0448 - val_accuracy: 0.9872\n",
            "Epoch 132/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
            "Epoch 133/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.1277e-04 - accuracy: 1.0000 - val_loss: 6.6242e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 6.7965e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.6282e-04 - accuracy: 1.0000 - val_loss: 4.4002e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.1219e-04 - accuracy: 1.0000 - val_loss: 2.5303e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.4187e-04 - accuracy: 1.0000 - val_loss: 1.3879e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.8615e-05 - accuracy: 1.0000 - val_loss: 1.4950e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.1586e-05 - accuracy: 1.0000 - val_loss: 1.1938e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.6492e-05 - accuracy: 1.0000 - val_loss: 8.0655e-05 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.5144e-05 - accuracy: 1.0000 - val_loss: 6.0556e-05 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.6968e-05 - accuracy: 1.0000 - val_loss: 4.6117e-05 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.0327e-05 - accuracy: 1.0000 - val_loss: 4.5833e-05 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.5026e-05 - accuracy: 1.0000 - val_loss: 4.1491e-05 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.0820e-05 - accuracy: 1.0000 - val_loss: 3.0789e-05 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.6985e-05 - accuracy: 1.0000 - val_loss: 4.7766e-05 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.3867e-05 - accuracy: 1.0000 - val_loss: 3.1455e-05 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1319e-05 - accuracy: 1.0000 - val_loss: 3.2334e-05 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.1345e-06 - accuracy: 1.0000 - val_loss: 3.8257e-05 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.1445e-06 - accuracy: 1.0000 - val_loss: 1.7807e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.5327e-06 - accuracy: 1.0000 - val_loss: 4.2730e-05 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.2236 - val_accuracy: 0.8927\n",
            "Epoch 153/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 7.4829e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.1369e-04 - accuracy: 1.0000 - val_loss: 2.8582e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.8873e-04 - accuracy: 1.0000 - val_loss: 1.8054e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2027e-04 - accuracy: 1.0000 - val_loss: 1.2424e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 158/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 3.2689e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.9888e-04 - accuracy: 1.0000 - val_loss: 1.9944e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2002e-04 - accuracy: 1.0000 - val_loss: 1.3836e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 8.0854e-05 - accuracy: 1.0000 - val_loss: 1.0497e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.7280e-05 - accuracy: 1.0000 - val_loss: 8.3079e-05 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.2810e-05 - accuracy: 1.0000 - val_loss: 6.1600e-05 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.1960e-05 - accuracy: 1.0000 - val_loss: 5.4129e-05 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.4813e-05 - accuracy: 1.0000 - val_loss: 4.4637e-05 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.9603e-05 - accuracy: 1.0000 - val_loss: 4.0571e-05 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.5868e-05 - accuracy: 1.0000 - val_loss: 3.5230e-05 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.2980e-05 - accuracy: 1.0000 - val_loss: 3.1393e-05 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.0739e-05 - accuracy: 1.0000 - val_loss: 3.4935e-05 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 8.9022e-06 - accuracy: 1.0000 - val_loss: 3.8835e-05 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.4514e-06 - accuracy: 1.0000 - val_loss: 3.4429e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.2672e-06 - accuracy: 1.0000 - val_loss: 4.2601e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.2752e-06 - accuracy: 1.0000 - val_loss: 3.4055e-05 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.4302e-06 - accuracy: 1.0000 - val_loss: 3.6396e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.7231e-06 - accuracy: 1.0000 - val_loss: 4.2107e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.1419e-06 - accuracy: 1.0000 - val_loss: 3.1237e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.6638e-06 - accuracy: 1.0000 - val_loss: 3.5485e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.2109e-06 - accuracy: 1.0000 - val_loss: 3.4359e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.8268e-06 - accuracy: 1.0000 - val_loss: 3.5361e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.4724e-06 - accuracy: 1.0000 - val_loss: 3.4808e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.1822e-06 - accuracy: 1.0000 - val_loss: 4.7826e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 9.4188e-07 - accuracy: 1.0000 - val_loss: 4.3470e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 7.8752e-07 - accuracy: 1.0000 - val_loss: 6.0857e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 6.4309e-07 - accuracy: 1.0000 - val_loss: 5.9552e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 5.3010e-07 - accuracy: 1.0000 - val_loss: 4.3589e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 4.4921e-07 - accuracy: 1.0000 - val_loss: 4.6296e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.8718e-07 - accuracy: 1.0000 - val_loss: 4.2524e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.3917e-07 - accuracy: 1.0000 - val_loss: 5.0513e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 3.0088e-07 - accuracy: 1.0000 - val_loss: 6.5427e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.7023e-07 - accuracy: 1.0000 - val_loss: 5.0723e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.4522e-07 - accuracy: 1.0000 - val_loss: 6.3821e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.2354e-07 - accuracy: 1.0000 - val_loss: 6.2075e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 2.0672e-07 - accuracy: 1.0000 - val_loss: 7.9000e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.9226e-07 - accuracy: 1.0000 - val_loss: 9.2688e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.8041e-07 - accuracy: 1.0000 - val_loss: 5.1029e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.7059e-07 - accuracy: 1.0000 - val_loss: 9.0519e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.6227e-07 - accuracy: 1.0000 - val_loss: 8.0556e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.5570e-07 - accuracy: 1.0000 - val_loss: 5.8225e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.4973e-07 - accuracy: 1.0000 - val_loss: 9.0822e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "352/352 [==============================] - 5s 14ms/step - loss: 1.4483e-07 - accuracy: 1.0000 - val_loss: 8.6273e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V6EDLt9ITLpG",
        "outputId": "dd2b1ec7-0f08-4080-fb37-f821d0828bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# calculate ultimate errors\n",
        "x_tst,y_tst = generate_complete_set(as_type = \"bitpairs\", reverse = True)\n",
        "score_gru_bitpairs_reverse = ultimate_errors(model, x_tst, y_tst, as_bit = True)\n",
        "results_bit_pairs[\"GRU_rev\"] = score_gru_bitpairs_reverse\n",
        "print(\"Accuracy:\", score_gru_bitpairs_reverse[0])\n",
        "print(\"MSE:     \", score_gru_bitpairs_reverse[1])\n",
        "print(\"MAE:     \", score_gru_bitpairs_reverse[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total addition questions: 1046529\n",
            "Accuracy: 0.9998585801253477\n",
            "MSE:      0.11682141632004464\n",
            "MAE:      0.003008994495135825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtA-9zTzJwl",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Hbr0cZ4vih",
        "colab_type": "code",
        "outputId": "225b2d07-d9f8-436e-a29f-1b9af6005bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#Show Results\n",
        "results_df = pd.DataFrame(results_bit_pairs,\n",
        "                          index = [\"ACC\", \"MSE\", \"MAE\"])\n",
        "print(results_df.to_latex(float_format=\"%.3f\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrrr}\n",
            "\\toprule\n",
            "{} &  LSTM\\_plain &  LSTM\\_rev &  SimpleRNN &  SimpleRNN\\_rev &  GRU\\_plain &  GRU\\_rev \\\\\n",
            "\\midrule\n",
            "ACC &       0.987 &     1.000 &      0.999 &          1.000 &      0.999 &    1.000 \\\\\n",
            "MSE &      15.382 &     0.021 &     78.717 &          0.027 &      1.523 &    0.117 \\\\\n",
            "MAE &       0.268 &     0.000 &      0.140 &          0.001 &      0.033 &    0.003 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cri_zLvS4xqZ",
        "colab_type": "code",
        "outputId": "ca7194a7-8694-4b29-a677-a857348f678a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "#Plot Training\n",
        "fig, ax = plt.subplots()\n",
        "for key, item in histories_bit_pairs.items():\n",
        "    plt.plot(pd.DataFrame(item.history[\"val_accuracy\"]))\n",
        "\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.legend(histories_bit_pairs.keys())\n",
        "plt.title(\"Validation Accuracy while training \\n on the Representation of Bits as Pairs\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}